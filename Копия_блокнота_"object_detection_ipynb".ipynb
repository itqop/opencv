{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"object_detection.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itqop/opencv/blob/master/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22object_detection_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGxO2uqH-KpC"
      },
      "source": [
        "Устанавливаем версию 1.x по умолчанию    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMdQtVl-JOf9",
        "outputId": "8dce1477-e4b4-4c09-d857-d60dcd463059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKFRM7KyiR2b"
      },
      "source": [
        "\n",
        "Клонируем репозиторий TensorFlow Models:    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbox8emXldKq",
        "outputId": "4e732ac6-9a29-4947-baf4-0fbcdc5d0ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git                                                 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 45403 (delta 40), reused 53 (delta 5), pack-reused 45315\u001b[K\n",
            "Receiving objects: 100% (45403/45403), 550.88 MiB | 38.10 MiB/s, done.\n",
            "Resolving deltas: 100% (31056/31056), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySUiXGgFio8K"
      },
      "source": [
        "Устанавливаем protobuf и компилируем необходимые файлы  в object_detection:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKr21FxlFV8X",
        "outputId": "4270b202-d33f-42d3-b559-2d3bb5f5c9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!apt-get -qq install libprotobuf-java protobuf-compiler                                                \n",
        "%cd ./models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "%cd ../.. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxiYmINti85j"
      },
      "source": [
        " Добавляем необходимые пути в переменную окружения PYTHONPATH:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-tSg17YoPNX"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research/\"\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research/slim\"\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research/object_detection\"\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research/object_detection/utils\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PSLOrFvjcWD"
      },
      "source": [
        " Для получения файла из Google Drive устанавливаем PyDrive и авторизируемся:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m8_5K0PjV8_"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRzzE_6_xj7K",
        "outputId": "826d0f76-81b2-4413-9f21-29be444acb13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmsSnYnEjf4G"
      },
      "source": [
        " Скачиваем архив (для drive_file_id нужно указать id вашего файла) и разархивируем его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aItGb4eHefcW"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM5QXdHA0RV1",
        "outputId": "d3e29845-5454-4d05-ab71-17d5b14f3ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        }
      },
      "source": [
        "drive_file_id=\"1xm_oGFRw5mitG48IKimv50J7O0Eetiia\"\n",
        "\n",
        "training_demo_zip = drive.CreateFile({'id': drive_file_id})\n",
        "training_demo_zip.GetContentFile('training_demo.zip')\n",
        "\n",
        "!unzip training_demo.zip\n",
        "!rm training_demo.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  training_demo.zip\n",
            "   creating: training_demo/\n",
            "   creating: training_demo/annotations/\n",
            "  inflating: training_demo/annotations/label_map.pbtxt  \n",
            "  inflating: training_demo/annotations/test.record  \n",
            "  inflating: training_demo/annotations/test_labels.csv  \n",
            "  inflating: training_demo/annotations/train.record  \n",
            "  inflating: training_demo/annotations/train_labels.csv  \n",
            " extracting: training_demo/annotations/Новый текстовый документ.txt  \n",
            "   creating: training_demo/images/\n",
            "   creating: training_demo/images/test/\n",
            "  inflating: training_demo/images/test/00009.jpg  \n",
            "  inflating: training_demo/images/test/00009.xml  \n",
            "  inflating: training_demo/images/test/00010.jpg  \n",
            "  inflating: training_demo/images/test/00010.xml  \n",
            "   creating: training_demo/images/train/\n",
            "  inflating: training_demo/images/train/00001.jpg  \n",
            "  inflating: training_demo/images/train/00001.xml  \n",
            "  inflating: training_demo/images/train/00002.jpg  \n",
            "  inflating: training_demo/images/train/00002.xml  \n",
            "  inflating: training_demo/images/train/00003.jpg  \n",
            "  inflating: training_demo/images/train/00003.xml  \n",
            "  inflating: training_demo/images/train/00004.jpg  \n",
            "  inflating: training_demo/images/train/00004.xml  \n",
            "  inflating: training_demo/images/train/00005.jpg  \n",
            "  inflating: training_demo/images/train/00005.xml  \n",
            "  inflating: training_demo/images/train/00006.jpg  \n",
            "  inflating: training_demo/images/train/00006.xml  \n",
            "  inflating: training_demo/images/train/00007.jpg  \n",
            "  inflating: training_demo/images/train/00007.xml  \n",
            "  inflating: training_demo/images/train/00008.jpg  \n",
            "  inflating: training_demo/images/train/00008.xml  \n",
            "   creating: training_demo/pre-trained-model/\n",
            "   creating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/\n",
            "  inflating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/checkpoint  \n",
            "  inflating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb  \n",
            "  inflating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.data-00000-of-00001  \n",
            "  inflating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.index  \n",
            "  inflating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.meta  \n",
            "  inflating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config  \n",
            "   creating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/saved_model/\n",
            "  inflating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/saved_model/saved_model.pb  \n",
            "   creating: training_demo/pre-trained-model/ssd_mobilenet_v2_coco_2018_03_29/saved_model/variables/\n",
            "   creating: training_demo/training/\n",
            "  inflating: training_demo/training/ssdlite_mobilenet_v2_coco.config  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFFS-9kRj8OM"
      },
      "source": [
        " Запускаем процесс обучение, где:\n",
        " \n",
        " ```\n",
        "--train_dir=./training_demo/training #путь к директории где будут лежать результаты обучение\n",
        "--pipeline_config_path=./training_demo/training/ssdlite_mobilenet_v2_coco.config # путь к конфигу\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcZ3P9L_zkw5",
        "outputId": "e288f1e2-65b3-4335-ee6a-2e09445e8116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 28.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4dD1WAl0wiZ",
        "outputId": "d57536ff-f4c2-427b-b4a9-0847c2d77453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./models/research/object_detection/legacy/train.py --logtostderr --train_dir=./training_demo/training --pipeline_config_path=./training_demo/training/ssdlite_mobilenet_v2_coco.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "I1003 00:59:14.902492 139845451286400 learning.py:512] global step 17506: loss = 8.8352 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17507: loss = 1.7788 (0.092 sec/step)\n",
            "I1003 00:59:14.996294 139845451286400 learning.py:512] global step 17507: loss = 1.7788 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17508: loss = 3.4357 (0.103 sec/step)\n",
            "I1003 00:59:15.100805 139845451286400 learning.py:512] global step 17508: loss = 3.4357 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17509: loss = 4.2703 (0.105 sec/step)\n",
            "I1003 00:59:15.207649 139845451286400 learning.py:512] global step 17509: loss = 4.2703 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17510: loss = 3.4644 (0.102 sec/step)\n",
            "I1003 00:59:15.311594 139845451286400 learning.py:512] global step 17510: loss = 3.4644 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17511: loss = 4.2396 (0.112 sec/step)\n",
            "I1003 00:59:15.425462 139845451286400 learning.py:512] global step 17511: loss = 4.2396 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 17512: loss = 8.6985 (0.130 sec/step)\n",
            "I1003 00:59:15.556861 139845451286400 learning.py:512] global step 17512: loss = 8.6985 (0.130 sec/step)\n",
            "INFO:tensorflow:global step 17513: loss = 4.4839 (0.128 sec/step)\n",
            "I1003 00:59:15.685955 139845451286400 learning.py:512] global step 17513: loss = 4.4839 (0.128 sec/step)\n",
            "INFO:tensorflow:global step 17514: loss = 4.6902 (0.125 sec/step)\n",
            "I1003 00:59:15.812731 139845451286400 learning.py:512] global step 17514: loss = 4.6902 (0.125 sec/step)\n",
            "INFO:tensorflow:global step 17515: loss = 7.8019 (0.128 sec/step)\n",
            "I1003 00:59:15.942018 139845451286400 learning.py:512] global step 17515: loss = 7.8019 (0.128 sec/step)\n",
            "INFO:tensorflow:global step 17516: loss = 2.2079 (0.119 sec/step)\n",
            "I1003 00:59:16.062017 139845451286400 learning.py:512] global step 17516: loss = 2.2079 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 17517: loss = 4.3116 (0.124 sec/step)\n",
            "I1003 00:59:16.187049 139845451286400 learning.py:512] global step 17517: loss = 4.3116 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 17518: loss = 6.0773 (0.101 sec/step)\n",
            "I1003 00:59:16.289839 139845451286400 learning.py:512] global step 17518: loss = 6.0773 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17519: loss = 3.6922 (0.099 sec/step)\n",
            "I1003 00:59:16.390293 139845451286400 learning.py:512] global step 17519: loss = 3.6922 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17520: loss = 4.1891 (0.111 sec/step)\n",
            "I1003 00:59:16.502740 139845451286400 learning.py:512] global step 17520: loss = 4.1891 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17521: loss = 8.9330 (0.099 sec/step)\n",
            "I1003 00:59:16.603355 139845451286400 learning.py:512] global step 17521: loss = 8.9330 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17522: loss = 6.4585 (0.107 sec/step)\n",
            "I1003 00:59:16.712066 139845451286400 learning.py:512] global step 17522: loss = 6.4585 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17523: loss = 3.6478 (0.091 sec/step)\n",
            "I1003 00:59:16.804780 139845451286400 learning.py:512] global step 17523: loss = 3.6478 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 17524: loss = 2.8294 (0.098 sec/step)\n",
            "I1003 00:59:16.904283 139845451286400 learning.py:512] global step 17524: loss = 2.8294 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17525: loss = 6.1055 (0.096 sec/step)\n",
            "I1003 00:59:17.001336 139845451286400 learning.py:512] global step 17525: loss = 6.1055 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17526: loss = 3.4022 (0.097 sec/step)\n",
            "I1003 00:59:17.100057 139845451286400 learning.py:512] global step 17526: loss = 3.4022 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17527: loss = 3.8683 (0.103 sec/step)\n",
            "I1003 00:59:17.204965 139845451286400 learning.py:512] global step 17527: loss = 3.8683 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17528: loss = 4.6036 (0.094 sec/step)\n",
            "I1003 00:59:17.299947 139845451286400 learning.py:512] global step 17528: loss = 4.6036 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17529: loss = 5.9784 (0.096 sec/step)\n",
            "I1003 00:59:17.396992 139845451286400 learning.py:512] global step 17529: loss = 5.9784 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17530: loss = 2.6600 (0.108 sec/step)\n",
            "I1003 00:59:17.506123 139845451286400 learning.py:512] global step 17530: loss = 2.6600 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 17531: loss = 5.0560 (0.103 sec/step)\n",
            "I1003 00:59:17.610887 139845451286400 learning.py:512] global step 17531: loss = 5.0560 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17532: loss = 3.5647 (0.109 sec/step)\n",
            "I1003 00:59:17.721458 139845451286400 learning.py:512] global step 17532: loss = 3.5647 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17533: loss = 9.7212 (0.094 sec/step)\n",
            "I1003 00:59:17.816426 139845451286400 learning.py:512] global step 17533: loss = 9.7212 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17534: loss = 3.3465 (0.102 sec/step)\n",
            "I1003 00:59:17.920148 139845451286400 learning.py:512] global step 17534: loss = 3.3465 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17535: loss = 3.9229 (0.106 sec/step)\n",
            "I1003 00:59:18.027281 139845451286400 learning.py:512] global step 17535: loss = 3.9229 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17536: loss = 2.7511 (0.104 sec/step)\n",
            "I1003 00:59:18.133155 139845451286400 learning.py:512] global step 17536: loss = 2.7511 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17537: loss = 3.0815 (0.102 sec/step)\n",
            "I1003 00:59:18.236026 139845451286400 learning.py:512] global step 17537: loss = 3.0815 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17538: loss = 2.5931 (0.102 sec/step)\n",
            "I1003 00:59:18.339909 139845451286400 learning.py:512] global step 17538: loss = 2.5931 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17539: loss = 3.2307 (0.113 sec/step)\n",
            "I1003 00:59:18.454375 139845451286400 learning.py:512] global step 17539: loss = 3.2307 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17540: loss = 2.6614 (0.114 sec/step)\n",
            "I1003 00:59:18.570027 139845451286400 learning.py:512] global step 17540: loss = 2.6614 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 17541: loss = 5.6953 (0.120 sec/step)\n",
            "I1003 00:59:18.691691 139845451286400 learning.py:512] global step 17541: loss = 5.6953 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 17542: loss = 2.9466 (0.097 sec/step)\n",
            "I1003 00:59:18.790309 139845451286400 learning.py:512] global step 17542: loss = 2.9466 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17543: loss = 5.1013 (0.096 sec/step)\n",
            "I1003 00:59:18.888172 139845451286400 learning.py:512] global step 17543: loss = 5.1013 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17544: loss = 4.0220 (0.100 sec/step)\n",
            "I1003 00:59:18.989722 139845451286400 learning.py:512] global step 17544: loss = 4.0220 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17545: loss = 6.6365 (0.096 sec/step)\n",
            "I1003 00:59:19.087653 139845451286400 learning.py:512] global step 17545: loss = 6.6365 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17546: loss = 6.8116 (0.087 sec/step)\n",
            "I1003 00:59:19.175843 139845451286400 learning.py:512] global step 17546: loss = 6.8116 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 17547: loss = 3.0459 (0.095 sec/step)\n",
            "I1003 00:59:19.272102 139845451286400 learning.py:512] global step 17547: loss = 3.0459 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17548: loss = 3.8906 (0.097 sec/step)\n",
            "I1003 00:59:19.370677 139845451286400 learning.py:512] global step 17548: loss = 3.8906 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17549: loss = 6.8633 (0.096 sec/step)\n",
            "I1003 00:59:19.468015 139845451286400 learning.py:512] global step 17549: loss = 6.8633 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17550: loss = 4.2178 (0.098 sec/step)\n",
            "I1003 00:59:19.567377 139845451286400 learning.py:512] global step 17550: loss = 4.2178 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17551: loss = 6.4041 (0.099 sec/step)\n",
            "I1003 00:59:19.667313 139845451286400 learning.py:512] global step 17551: loss = 6.4041 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17552: loss = 6.1372 (0.111 sec/step)\n",
            "I1003 00:59:19.779207 139845451286400 learning.py:512] global step 17552: loss = 6.1372 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17553: loss = 6.6531 (0.108 sec/step)\n",
            "I1003 00:59:19.888966 139845451286400 learning.py:512] global step 17553: loss = 6.6531 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 17554: loss = 3.8186 (0.096 sec/step)\n",
            "I1003 00:59:19.986321 139845451286400 learning.py:512] global step 17554: loss = 3.8186 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17555: loss = 3.5248 (0.097 sec/step)\n",
            "I1003 00:59:20.084770 139845451286400 learning.py:512] global step 17555: loss = 3.5248 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17556: loss = 3.5108 (0.095 sec/step)\n",
            "I1003 00:59:20.181340 139845451286400 learning.py:512] global step 17556: loss = 3.5108 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17557: loss = 4.1461 (0.089 sec/step)\n",
            "I1003 00:59:20.271425 139845451286400 learning.py:512] global step 17557: loss = 4.1461 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 17558: loss = 7.6186 (0.103 sec/step)\n",
            "I1003 00:59:20.375704 139845451286400 learning.py:512] global step 17558: loss = 7.6186 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17559: loss = 4.7324 (0.095 sec/step)\n",
            "I1003 00:59:20.472553 139845451286400 learning.py:512] global step 17559: loss = 4.7324 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17560: loss = 4.5877 (0.102 sec/step)\n",
            "I1003 00:59:20.575911 139845451286400 learning.py:512] global step 17560: loss = 4.5877 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17561: loss = 3.2041 (0.106 sec/step)\n",
            "I1003 00:59:20.682995 139845451286400 learning.py:512] global step 17561: loss = 3.2041 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17562: loss = 5.8025 (0.113 sec/step)\n",
            "I1003 00:59:20.797709 139845451286400 learning.py:512] global step 17562: loss = 5.8025 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17563: loss = 4.5291 (0.105 sec/step)\n",
            "I1003 00:59:20.903662 139845451286400 learning.py:512] global step 17563: loss = 4.5291 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17564: loss = 4.7186 (0.106 sec/step)\n",
            "I1003 00:59:21.011187 139845451286400 learning.py:512] global step 17564: loss = 4.7186 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17565: loss = 6.4860 (0.115 sec/step)\n",
            "I1003 00:59:21.127899 139845451286400 learning.py:512] global step 17565: loss = 6.4860 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 17566: loss = 1.7794 (0.106 sec/step)\n",
            "I1003 00:59:21.235782 139845451286400 learning.py:512] global step 17566: loss = 1.7794 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17567: loss = 3.4482 (0.107 sec/step)\n",
            "I1003 00:59:21.344726 139845451286400 learning.py:512] global step 17567: loss = 3.4482 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17568: loss = 7.0747 (0.116 sec/step)\n",
            "I1003 00:59:21.462377 139845451286400 learning.py:512] global step 17568: loss = 7.0747 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 17569: loss = 6.7880 (0.109 sec/step)\n",
            "I1003 00:59:21.572391 139845451286400 learning.py:512] global step 17569: loss = 6.7880 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17570: loss = 2.8869 (0.110 sec/step)\n",
            "I1003 00:59:21.683611 139845451286400 learning.py:512] global step 17570: loss = 2.8869 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17571: loss = 6.5322 (0.106 sec/step)\n",
            "I1003 00:59:21.791400 139845451286400 learning.py:512] global step 17571: loss = 6.5322 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17572: loss = 6.6798 (0.109 sec/step)\n",
            "I1003 00:59:21.902137 139845451286400 learning.py:512] global step 17572: loss = 6.6798 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17573: loss = 3.6501 (0.100 sec/step)\n",
            "I1003 00:59:22.003683 139845451286400 learning.py:512] global step 17573: loss = 3.6501 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17574: loss = 3.3495 (0.105 sec/step)\n",
            "I1003 00:59:22.109650 139845451286400 learning.py:512] global step 17574: loss = 3.3495 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17575: loss = 5.1698 (0.098 sec/step)\n",
            "I1003 00:59:22.209351 139845451286400 learning.py:512] global step 17575: loss = 5.1698 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17576: loss = 1.8068 (0.093 sec/step)\n",
            "I1003 00:59:22.304142 139845451286400 learning.py:512] global step 17576: loss = 1.8068 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17577: loss = 3.6164 (0.100 sec/step)\n",
            "I1003 00:59:22.405362 139845451286400 learning.py:512] global step 17577: loss = 3.6164 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17578: loss = 5.7729 (0.102 sec/step)\n",
            "I1003 00:59:22.508405 139845451286400 learning.py:512] global step 17578: loss = 5.7729 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17579: loss = 4.2067 (0.103 sec/step)\n",
            "I1003 00:59:22.613083 139845451286400 learning.py:512] global step 17579: loss = 4.2067 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17580: loss = 4.6492 (0.101 sec/step)\n",
            "I1003 00:59:22.715422 139845451286400 learning.py:512] global step 17580: loss = 4.6492 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17581: loss = 5.1203 (0.105 sec/step)\n",
            "I1003 00:59:22.821668 139845451286400 learning.py:512] global step 17581: loss = 5.1203 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17582: loss = 4.7719 (0.096 sec/step)\n",
            "I1003 00:59:22.919076 139845451286400 learning.py:512] global step 17582: loss = 4.7719 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17583: loss = 3.2931 (0.111 sec/step)\n",
            "I1003 00:59:23.031434 139845451286400 learning.py:512] global step 17583: loss = 3.2931 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17584: loss = 4.4554 (0.097 sec/step)\n",
            "I1003 00:59:23.129594 139845451286400 learning.py:512] global step 17584: loss = 4.4554 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17585: loss = 5.0743 (0.104 sec/step)\n",
            "I1003 00:59:23.234966 139845451286400 learning.py:512] global step 17585: loss = 5.0743 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17586: loss = 6.0664 (0.099 sec/step)\n",
            "I1003 00:59:23.335889 139845451286400 learning.py:512] global step 17586: loss = 6.0664 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17587: loss = 4.4979 (0.110 sec/step)\n",
            "I1003 00:59:23.447183 139845451286400 learning.py:512] global step 17587: loss = 4.4979 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17588: loss = 10.8873 (0.101 sec/step)\n",
            "I1003 00:59:23.549491 139845451286400 learning.py:512] global step 17588: loss = 10.8873 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17589: loss = 6.2699 (0.098 sec/step)\n",
            "I1003 00:59:23.649006 139845451286400 learning.py:512] global step 17589: loss = 6.2699 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17590: loss = 5.8522 (0.092 sec/step)\n",
            "I1003 00:59:23.742661 139845451286400 learning.py:512] global step 17590: loss = 5.8522 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17591: loss = 3.1669 (0.116 sec/step)\n",
            "I1003 00:59:23.859777 139845451286400 learning.py:512] global step 17591: loss = 3.1669 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 17592: loss = 7.5658 (0.103 sec/step)\n",
            "I1003 00:59:23.963879 139845451286400 learning.py:512] global step 17592: loss = 7.5658 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17593: loss = 4.6933 (0.096 sec/step)\n",
            "I1003 00:59:24.061109 139845451286400 learning.py:512] global step 17593: loss = 4.6933 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17594: loss = 3.3373 (0.093 sec/step)\n",
            "I1003 00:59:24.155785 139845451286400 learning.py:512] global step 17594: loss = 3.3373 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17595: loss = 3.6158 (0.099 sec/step)\n",
            "I1003 00:59:24.255914 139845451286400 learning.py:512] global step 17595: loss = 3.6158 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17596: loss = 4.9401 (0.098 sec/step)\n",
            "I1003 00:59:24.355628 139845451286400 learning.py:512] global step 17596: loss = 4.9401 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17597: loss = 6.7060 (0.095 sec/step)\n",
            "I1003 00:59:24.451747 139845451286400 learning.py:512] global step 17597: loss = 6.7060 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17598: loss = 6.3798 (0.089 sec/step)\n",
            "I1003 00:59:24.542020 139845451286400 learning.py:512] global step 17598: loss = 6.3798 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 17599: loss = 2.8376 (0.090 sec/step)\n",
            "I1003 00:59:24.633354 139845451286400 learning.py:512] global step 17599: loss = 2.8376 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 17600: loss = 7.0581 (0.100 sec/step)\n",
            "I1003 00:59:24.734547 139845451286400 learning.py:512] global step 17600: loss = 7.0581 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17601: loss = 7.4883 (0.106 sec/step)\n",
            "I1003 00:59:24.841427 139845451286400 learning.py:512] global step 17601: loss = 7.4883 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17602: loss = 5.1095 (0.104 sec/step)\n",
            "I1003 00:59:24.948291 139845451286400 learning.py:512] global step 17602: loss = 5.1095 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17603: loss = 4.6074 (0.099 sec/step)\n",
            "I1003 00:59:25.048192 139845451286400 learning.py:512] global step 17603: loss = 4.6074 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17604: loss = 3.6708 (0.090 sec/step)\n",
            "I1003 00:59:25.139383 139845451286400 learning.py:512] global step 17604: loss = 3.6708 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 17605: loss = 4.6320 (0.095 sec/step)\n",
            "I1003 00:59:25.235795 139845451286400 learning.py:512] global step 17605: loss = 4.6320 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17606: loss = 3.2352 (0.096 sec/step)\n",
            "I1003 00:59:25.333148 139845451286400 learning.py:512] global step 17606: loss = 3.2352 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17607: loss = 3.0980 (0.099 sec/step)\n",
            "I1003 00:59:25.433495 139845451286400 learning.py:512] global step 17607: loss = 3.0980 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17608: loss = 2.4740 (0.105 sec/step)\n",
            "I1003 00:59:25.539985 139845451286400 learning.py:512] global step 17608: loss = 2.4740 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17609: loss = 3.9393 (0.096 sec/step)\n",
            "I1003 00:59:25.637132 139845451286400 learning.py:512] global step 17609: loss = 3.9393 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17610: loss = 4.8257 (0.095 sec/step)\n",
            "I1003 00:59:25.733145 139845451286400 learning.py:512] global step 17610: loss = 4.8257 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17611: loss = 7.4867 (0.110 sec/step)\n",
            "I1003 00:59:25.844247 139845451286400 learning.py:512] global step 17611: loss = 7.4867 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17612: loss = 3.2416 (0.095 sec/step)\n",
            "I1003 00:59:25.940910 139845451286400 learning.py:512] global step 17612: loss = 3.2416 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17613: loss = 3.0660 (0.118 sec/step)\n",
            "I1003 00:59:26.060514 139845451286400 learning.py:512] global step 17613: loss = 3.0660 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 17614: loss = 4.9477 (0.095 sec/step)\n",
            "I1003 00:59:26.156453 139845451286400 learning.py:512] global step 17614: loss = 4.9477 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17615: loss = 3.8021 (0.101 sec/step)\n",
            "I1003 00:59:26.259442 139845451286400 learning.py:512] global step 17615: loss = 3.8021 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17616: loss = 4.0660 (0.103 sec/step)\n",
            "I1003 00:59:26.363608 139845451286400 learning.py:512] global step 17616: loss = 4.0660 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17617: loss = 3.4978 (0.100 sec/step)\n",
            "I1003 00:59:26.465387 139845451286400 learning.py:512] global step 17617: loss = 3.4978 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17618: loss = 3.8600 (0.107 sec/step)\n",
            "I1003 00:59:26.574346 139845451286400 learning.py:512] global step 17618: loss = 3.8600 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17619: loss = 4.2944 (0.110 sec/step)\n",
            "I1003 00:59:26.686471 139845451286400 learning.py:512] global step 17619: loss = 4.2944 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17620: loss = 4.6261 (0.104 sec/step)\n",
            "I1003 00:59:26.791853 139845451286400 learning.py:512] global step 17620: loss = 4.6261 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17621: loss = 3.2834 (0.094 sec/step)\n",
            "I1003 00:59:26.887483 139845451286400 learning.py:512] global step 17621: loss = 3.2834 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17622: loss = 3.1901 (0.095 sec/step)\n",
            "I1003 00:59:26.983589 139845451286400 learning.py:512] global step 17622: loss = 3.1901 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17623: loss = 3.3554 (0.099 sec/step)\n",
            "I1003 00:59:27.083705 139845451286400 learning.py:512] global step 17623: loss = 3.3554 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17624: loss = 3.1575 (0.110 sec/step)\n",
            "I1003 00:59:27.194524 139845451286400 learning.py:512] global step 17624: loss = 3.1575 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17625: loss = 2.8807 (0.118 sec/step)\n",
            "I1003 00:59:27.313941 139845451286400 learning.py:512] global step 17625: loss = 2.8807 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 17626: loss = 2.4839 (0.109 sec/step)\n",
            "I1003 00:59:27.423966 139845451286400 learning.py:512] global step 17626: loss = 2.4839 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17627: loss = 9.6314 (0.102 sec/step)\n",
            "I1003 00:59:27.527295 139845451286400 learning.py:512] global step 17627: loss = 9.6314 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17628: loss = 4.5325 (0.119 sec/step)\n",
            "I1003 00:59:27.648258 139845451286400 learning.py:512] global step 17628: loss = 4.5325 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 17629: loss = 3.2178 (0.114 sec/step)\n",
            "I1003 00:59:27.763980 139845451286400 learning.py:512] global step 17629: loss = 3.2178 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 17630: loss = 3.4854 (0.101 sec/step)\n",
            "I1003 00:59:27.865892 139845451286400 learning.py:512] global step 17630: loss = 3.4854 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17631: loss = 4.5944 (0.090 sec/step)\n",
            "I1003 00:59:27.957758 139845451286400 learning.py:512] global step 17631: loss = 4.5944 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 17632: loss = 12.8705 (0.101 sec/step)\n",
            "I1003 00:59:28.060470 139845451286400 learning.py:512] global step 17632: loss = 12.8705 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17633: loss = 3.4237 (0.085 sec/step)\n",
            "I1003 00:59:28.147186 139845451286400 learning.py:512] global step 17633: loss = 3.4237 (0.085 sec/step)\n",
            "INFO:tensorflow:global step 17634: loss = 3.1596 (0.089 sec/step)\n",
            "I1003 00:59:28.237148 139845451286400 learning.py:512] global step 17634: loss = 3.1596 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 17635: loss = 6.2118 (0.096 sec/step)\n",
            "I1003 00:59:28.334109 139845451286400 learning.py:512] global step 17635: loss = 6.2118 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17636: loss = 6.9197 (0.104 sec/step)\n",
            "I1003 00:59:28.439848 139845451286400 learning.py:512] global step 17636: loss = 6.9197 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17637: loss = 4.0644 (0.103 sec/step)\n",
            "I1003 00:59:28.544431 139845451286400 learning.py:512] global step 17637: loss = 4.0644 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17638: loss = 3.5366 (0.091 sec/step)\n",
            "I1003 00:59:28.636609 139845451286400 learning.py:512] global step 17638: loss = 3.5366 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 17639: loss = 11.5411 (0.102 sec/step)\n",
            "I1003 00:59:28.739906 139845451286400 learning.py:512] global step 17639: loss = 11.5411 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17640: loss = 4.0601 (0.103 sec/step)\n",
            "I1003 00:59:28.844134 139845451286400 learning.py:512] global step 17640: loss = 4.0601 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17641: loss = 4.4248 (0.099 sec/step)\n",
            "I1003 00:59:28.944859 139845451286400 learning.py:512] global step 17641: loss = 4.4248 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17642: loss = 5.2745 (0.098 sec/step)\n",
            "I1003 00:59:29.044065 139845451286400 learning.py:512] global step 17642: loss = 5.2745 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17643: loss = 5.2408 (0.101 sec/step)\n",
            "I1003 00:59:29.146786 139845451286400 learning.py:512] global step 17643: loss = 5.2408 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17644: loss = 3.9349 (0.096 sec/step)\n",
            "I1003 00:59:29.243876 139845451286400 learning.py:512] global step 17644: loss = 3.9349 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17645: loss = 3.2201 (0.099 sec/step)\n",
            "I1003 00:59:29.344656 139845451286400 learning.py:512] global step 17645: loss = 3.2201 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17646: loss = 6.8061 (0.096 sec/step)\n",
            "I1003 00:59:29.442138 139845451286400 learning.py:512] global step 17646: loss = 6.8061 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17647: loss = 3.1264 (0.092 sec/step)\n",
            "I1003 00:59:29.535433 139845451286400 learning.py:512] global step 17647: loss = 3.1264 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17648: loss = 3.7155 (0.107 sec/step)\n",
            "I1003 00:59:29.643439 139845451286400 learning.py:512] global step 17648: loss = 3.7155 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17649: loss = 3.3961 (0.100 sec/step)\n",
            "I1003 00:59:29.744614 139845451286400 learning.py:512] global step 17649: loss = 3.3961 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17650: loss = 3.6858 (0.095 sec/step)\n",
            "I1003 00:59:29.840629 139845451286400 learning.py:512] global step 17650: loss = 3.6858 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17651: loss = 3.6733 (0.109 sec/step)\n",
            "I1003 00:59:29.951114 139845451286400 learning.py:512] global step 17651: loss = 3.6733 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17652: loss = 5.8884 (0.104 sec/step)\n",
            "I1003 00:59:30.056788 139845451286400 learning.py:512] global step 17652: loss = 5.8884 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17653: loss = 3.6155 (0.105 sec/step)\n",
            "I1003 00:59:30.163471 139845451286400 learning.py:512] global step 17653: loss = 3.6155 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17654: loss = 2.4323 (0.107 sec/step)\n",
            "I1003 00:59:30.271886 139845451286400 learning.py:512] global step 17654: loss = 2.4323 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17655: loss = 3.4192 (0.099 sec/step)\n",
            "I1003 00:59:30.371939 139845451286400 learning.py:512] global step 17655: loss = 3.4192 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17656: loss = 4.6505 (0.103 sec/step)\n",
            "I1003 00:59:30.476563 139845451286400 learning.py:512] global step 17656: loss = 4.6505 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17657: loss = 3.7011 (0.105 sec/step)\n",
            "I1003 00:59:30.583057 139845451286400 learning.py:512] global step 17657: loss = 3.7011 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17658: loss = 9.0755 (0.093 sec/step)\n",
            "I1003 00:59:30.677682 139845451286400 learning.py:512] global step 17658: loss = 9.0755 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17659: loss = 2.5536 (0.095 sec/step)\n",
            "I1003 00:59:30.773643 139845451286400 learning.py:512] global step 17659: loss = 2.5536 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17660: loss = 7.5331 (0.097 sec/step)\n",
            "I1003 00:59:30.872336 139845451286400 learning.py:512] global step 17660: loss = 7.5331 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17661: loss = 5.7845 (0.117 sec/step)\n",
            "I1003 00:59:30.990524 139845451286400 learning.py:512] global step 17661: loss = 5.7845 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 17662: loss = 3.4464 (0.106 sec/step)\n",
            "I1003 00:59:31.097984 139845451286400 learning.py:512] global step 17662: loss = 3.4464 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17663: loss = 4.1956 (0.089 sec/step)\n",
            "I1003 00:59:31.188126 139845451286400 learning.py:512] global step 17663: loss = 4.1956 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 17664: loss = 2.3612 (0.097 sec/step)\n",
            "I1003 00:59:31.286404 139845451286400 learning.py:512] global step 17664: loss = 2.3612 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17665: loss = 5.3769 (0.094 sec/step)\n",
            "I1003 00:59:31.381939 139845451286400 learning.py:512] global step 17665: loss = 5.3769 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17666: loss = 4.3680 (0.097 sec/step)\n",
            "I1003 00:59:31.479950 139845451286400 learning.py:512] global step 17666: loss = 4.3680 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17667: loss = 2.7145 (0.093 sec/step)\n",
            "I1003 00:59:31.573953 139845451286400 learning.py:512] global step 17667: loss = 2.7145 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17668: loss = 3.8321 (0.100 sec/step)\n",
            "I1003 00:59:31.675579 139845451286400 learning.py:512] global step 17668: loss = 3.8321 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17669: loss = 3.5020 (0.101 sec/step)\n",
            "I1003 00:59:31.778537 139845451286400 learning.py:512] global step 17669: loss = 3.5020 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17670: loss = 3.2862 (0.113 sec/step)\n",
            "I1003 00:59:31.893182 139845451286400 learning.py:512] global step 17670: loss = 3.2862 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17671: loss = 3.6915 (0.099 sec/step)\n",
            "I1003 00:59:31.993261 139845451286400 learning.py:512] global step 17671: loss = 3.6915 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17672: loss = 2.3721 (0.104 sec/step)\n",
            "I1003 00:59:32.098194 139845451286400 learning.py:512] global step 17672: loss = 2.3721 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17673: loss = 5.9233 (0.093 sec/step)\n",
            "I1003 00:59:32.192797 139845451286400 learning.py:512] global step 17673: loss = 5.9233 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17674: loss = 2.6523 (0.100 sec/step)\n",
            "I1003 00:59:32.293899 139845451286400 learning.py:512] global step 17674: loss = 2.6523 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17675: loss = 5.6071 (0.091 sec/step)\n",
            "I1003 00:59:32.386273 139845451286400 learning.py:512] global step 17675: loss = 5.6071 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 17676: loss = 4.7799 (0.096 sec/step)\n",
            "I1003 00:59:32.483259 139845451286400 learning.py:512] global step 17676: loss = 4.7799 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17677: loss = 2.9334 (0.094 sec/step)\n",
            "I1003 00:59:32.579166 139845451286400 learning.py:512] global step 17677: loss = 2.9334 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17678: loss = 3.9248 (0.101 sec/step)\n",
            "I1003 00:59:32.681009 139845451286400 learning.py:512] global step 17678: loss = 3.9248 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17679: loss = 2.2190 (0.099 sec/step)\n",
            "I1003 00:59:32.781911 139845451286400 learning.py:512] global step 17679: loss = 2.2190 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17680: loss = 2.1395 (0.100 sec/step)\n",
            "I1003 00:59:32.882869 139845451286400 learning.py:512] global step 17680: loss = 2.1395 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17681: loss = 3.2622 (0.120 sec/step)\n",
            "I1003 00:59:33.004622 139845451286400 learning.py:512] global step 17681: loss = 3.2622 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 17682: loss = 2.6694 (0.100 sec/step)\n",
            "I1003 00:59:33.106241 139845451286400 learning.py:512] global step 17682: loss = 2.6694 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17683: loss = 4.6207 (0.107 sec/step)\n",
            "I1003 00:59:33.214178 139845451286400 learning.py:512] global step 17683: loss = 4.6207 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17684: loss = 8.6132 (0.103 sec/step)\n",
            "I1003 00:59:33.318028 139845451286400 learning.py:512] global step 17684: loss = 8.6132 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17685: loss = 2.7700 (0.101 sec/step)\n",
            "I1003 00:59:33.420100 139845451286400 learning.py:512] global step 17685: loss = 2.7700 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17686: loss = 4.5140 (0.097 sec/step)\n",
            "I1003 00:59:33.518202 139845451286400 learning.py:512] global step 17686: loss = 4.5140 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17687: loss = 4.3873 (0.098 sec/step)\n",
            "I1003 00:59:33.617673 139845451286400 learning.py:512] global step 17687: loss = 4.3873 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17688: loss = 4.7991 (0.098 sec/step)\n",
            "I1003 00:59:33.717499 139845451286400 learning.py:512] global step 17688: loss = 4.7991 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17689: loss = 2.9469 (0.093 sec/step)\n",
            "I1003 00:59:33.811471 139845451286400 learning.py:512] global step 17689: loss = 2.9469 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17690: loss = 1.9613 (0.102 sec/step)\n",
            "I1003 00:59:33.915696 139845451286400 learning.py:512] global step 17690: loss = 1.9613 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17691: loss = 4.8966 (0.095 sec/step)\n",
            "I1003 00:59:34.011723 139845451286400 learning.py:512] global step 17691: loss = 4.8966 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17692: loss = 3.6311 (0.104 sec/step)\n",
            "I1003 00:59:34.116691 139845451286400 learning.py:512] global step 17692: loss = 3.6311 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17693: loss = 3.2527 (0.105 sec/step)\n",
            "I1003 00:59:34.223364 139845451286400 learning.py:512] global step 17693: loss = 3.2527 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17694: loss = 4.2728 (0.104 sec/step)\n",
            "I1003 00:59:34.328421 139845451286400 learning.py:512] global step 17694: loss = 4.2728 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17695: loss = 3.2914 (0.095 sec/step)\n",
            "I1003 00:59:34.425128 139845451286400 learning.py:512] global step 17695: loss = 3.2914 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17696: loss = 4.2144 (0.097 sec/step)\n",
            "I1003 00:59:34.522929 139845451286400 learning.py:512] global step 17696: loss = 4.2144 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17697: loss = 3.5974 (0.102 sec/step)\n",
            "I1003 00:59:34.626534 139845451286400 learning.py:512] global step 17697: loss = 3.5974 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17698: loss = 2.8467 (0.099 sec/step)\n",
            "I1003 00:59:34.727055 139845451286400 learning.py:512] global step 17698: loss = 2.8467 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17699: loss = 3.3180 (0.093 sec/step)\n",
            "I1003 00:59:34.822251 139845451286400 learning.py:512] global step 17699: loss = 3.3180 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17700: loss = 3.1598 (0.100 sec/step)\n",
            "I1003 00:59:34.923515 139845451286400 learning.py:512] global step 17700: loss = 3.1598 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17701: loss = 2.3476 (0.103 sec/step)\n",
            "I1003 00:59:35.027907 139845451286400 learning.py:512] global step 17701: loss = 2.3476 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17702: loss = 2.2143 (0.110 sec/step)\n",
            "I1003 00:59:35.139134 139845451286400 learning.py:512] global step 17702: loss = 2.2143 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17703: loss = 4.1398 (0.090 sec/step)\n",
            "I1003 00:59:35.230599 139845451286400 learning.py:512] global step 17703: loss = 4.1398 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 17704: loss = 4.8499 (0.108 sec/step)\n",
            "I1003 00:59:35.340314 139845451286400 learning.py:512] global step 17704: loss = 4.8499 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 17705: loss = 11.3103 (0.102 sec/step)\n",
            "I1003 00:59:35.443751 139845451286400 learning.py:512] global step 17705: loss = 11.3103 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17706: loss = 6.3121 (0.104 sec/step)\n",
            "I1003 00:59:35.548693 139845451286400 learning.py:512] global step 17706: loss = 6.3121 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17707: loss = 3.1834 (0.088 sec/step)\n",
            "I1003 00:59:35.638376 139845451286400 learning.py:512] global step 17707: loss = 3.1834 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 17708: loss = 5.9480 (0.099 sec/step)\n",
            "I1003 00:59:35.738581 139845451286400 learning.py:512] global step 17708: loss = 5.9480 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17709: loss = 6.9533 (0.099 sec/step)\n",
            "I1003 00:59:35.839011 139845451286400 learning.py:512] global step 17709: loss = 6.9533 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17710: loss = 2.4238 (0.103 sec/step)\n",
            "I1003 00:59:35.943301 139845451286400 learning.py:512] global step 17710: loss = 2.4238 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17711: loss = 3.1752 (0.110 sec/step)\n",
            "I1003 00:59:36.054456 139845451286400 learning.py:512] global step 17711: loss = 3.1752 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17712: loss = 2.8647 (0.111 sec/step)\n",
            "I1003 00:59:36.166923 139845451286400 learning.py:512] global step 17712: loss = 2.8647 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17713: loss = 7.4430 (0.095 sec/step)\n",
            "I1003 00:59:36.263583 139845451286400 learning.py:512] global step 17713: loss = 7.4430 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17714: loss = 3.1196 (0.096 sec/step)\n",
            "I1003 00:59:36.361351 139845451286400 learning.py:512] global step 17714: loss = 3.1196 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17715: loss = 5.2878 (0.097 sec/step)\n",
            "I1003 00:59:36.459634 139845451286400 learning.py:512] global step 17715: loss = 5.2878 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17716: loss = 5.0936 (0.101 sec/step)\n",
            "I1003 00:59:36.562140 139845451286400 learning.py:512] global step 17716: loss = 5.0936 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17717: loss = 3.7392 (0.102 sec/step)\n",
            "I1003 00:59:36.665667 139845451286400 learning.py:512] global step 17717: loss = 3.7392 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17718: loss = 2.1799 (0.094 sec/step)\n",
            "I1003 00:59:36.761544 139845451286400 learning.py:512] global step 17718: loss = 2.1799 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17719: loss = 4.2460 (0.102 sec/step)\n",
            "I1003 00:59:36.865225 139845451286400 learning.py:512] global step 17719: loss = 4.2460 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17720: loss = 2.7964 (0.103 sec/step)\n",
            "I1003 00:59:36.970001 139845451286400 learning.py:512] global step 17720: loss = 2.7964 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17721: loss = 8.1907 (0.109 sec/step)\n",
            "I1003 00:59:37.080227 139845451286400 learning.py:512] global step 17721: loss = 8.1907 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17722: loss = 4.3299 (0.104 sec/step)\n",
            "I1003 00:59:37.185194 139845451286400 learning.py:512] global step 17722: loss = 4.3299 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17723: loss = 2.7827 (0.099 sec/step)\n",
            "I1003 00:59:37.285286 139845451286400 learning.py:512] global step 17723: loss = 2.7827 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17724: loss = 2.7690 (0.097 sec/step)\n",
            "I1003 00:59:37.383359 139845451286400 learning.py:512] global step 17724: loss = 2.7690 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17725: loss = 2.6005 (0.086 sec/step)\n",
            "I1003 00:59:37.470190 139845451286400 learning.py:512] global step 17725: loss = 2.6005 (0.086 sec/step)\n",
            "INFO:tensorflow:global step 17726: loss = 13.5698 (0.096 sec/step)\n",
            "I1003 00:59:37.567333 139845451286400 learning.py:512] global step 17726: loss = 13.5698 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17727: loss = 3.1537 (0.113 sec/step)\n",
            "I1003 00:59:37.682301 139845451286400 learning.py:512] global step 17727: loss = 3.1537 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17728: loss = 2.1345 (0.106 sec/step)\n",
            "I1003 00:59:37.789671 139845451286400 learning.py:512] global step 17728: loss = 2.1345 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17729: loss = 3.0306 (0.090 sec/step)\n",
            "I1003 00:59:37.881067 139845451286400 learning.py:512] global step 17729: loss = 3.0306 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 17730: loss = 2.4648 (0.103 sec/step)\n",
            "I1003 00:59:37.985082 139845451286400 learning.py:512] global step 17730: loss = 2.4648 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17731: loss = 3.4691 (0.098 sec/step)\n",
            "I1003 00:59:38.084996 139845451286400 learning.py:512] global step 17731: loss = 3.4691 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17732: loss = 4.7316 (0.114 sec/step)\n",
            "I1003 00:59:38.200661 139845451286400 learning.py:512] global step 17732: loss = 4.7316 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 17733: loss = 10.1954 (0.087 sec/step)\n",
            "I1003 00:59:38.288776 139845451286400 learning.py:512] global step 17733: loss = 10.1954 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 17734: loss = 5.2496 (0.109 sec/step)\n",
            "I1003 00:59:38.399598 139845451286400 learning.py:512] global step 17734: loss = 5.2496 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17735: loss = 3.2285 (0.089 sec/step)\n",
            "I1003 00:59:38.490644 139845451286400 learning.py:512] global step 17735: loss = 3.2285 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 17736: loss = 2.4576 (0.102 sec/step)\n",
            "I1003 00:59:38.594134 139845451286400 learning.py:512] global step 17736: loss = 2.4576 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17737: loss = 4.5811 (0.093 sec/step)\n",
            "I1003 00:59:38.688551 139845451286400 learning.py:512] global step 17737: loss = 4.5811 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17738: loss = 4.2389 (0.106 sec/step)\n",
            "I1003 00:59:38.795521 139845451286400 learning.py:512] global step 17738: loss = 4.2389 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17739: loss = 3.7987 (0.093 sec/step)\n",
            "I1003 00:59:38.890052 139845451286400 learning.py:512] global step 17739: loss = 3.7987 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17740: loss = 8.7336 (0.103 sec/step)\n",
            "I1003 00:59:38.993992 139845451286400 learning.py:512] global step 17740: loss = 8.7336 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17741: loss = 9.3456 (0.103 sec/step)\n",
            "I1003 00:59:39.100532 139845451286400 learning.py:512] global step 17741: loss = 9.3456 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17742: loss = 3.1733 (0.108 sec/step)\n",
            "I1003 00:59:39.210670 139845451286400 learning.py:512] global step 17742: loss = 3.1733 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 17743: loss = 7.5416 (0.095 sec/step)\n",
            "I1003 00:59:39.307442 139845451286400 learning.py:512] global step 17743: loss = 7.5416 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17744: loss = 3.6682 (0.100 sec/step)\n",
            "I1003 00:59:39.408487 139845451286400 learning.py:512] global step 17744: loss = 3.6682 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17745: loss = 3.5154 (0.101 sec/step)\n",
            "I1003 00:59:39.510727 139845451286400 learning.py:512] global step 17745: loss = 3.5154 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17746: loss = 4.0195 (0.100 sec/step)\n",
            "I1003 00:59:39.611992 139845451286400 learning.py:512] global step 17746: loss = 4.0195 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17747: loss = 4.9341 (0.104 sec/step)\n",
            "I1003 00:59:39.717506 139845451286400 learning.py:512] global step 17747: loss = 4.9341 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17748: loss = 4.6422 (0.112 sec/step)\n",
            "I1003 00:59:39.831458 139845451286400 learning.py:512] global step 17748: loss = 4.6422 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 17749: loss = 3.3026 (0.102 sec/step)\n",
            "I1003 00:59:39.935461 139845451286400 learning.py:512] global step 17749: loss = 3.3026 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17750: loss = 3.3334 (0.120 sec/step)\n",
            "I1003 00:59:40.056696 139845451286400 learning.py:512] global step 17750: loss = 3.3334 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 17751: loss = 3.5527 (0.113 sec/step)\n",
            "I1003 00:59:40.170875 139845451286400 learning.py:512] global step 17751: loss = 3.5527 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17752: loss = 4.8543 (0.096 sec/step)\n",
            "I1003 00:59:40.268533 139845451286400 learning.py:512] global step 17752: loss = 4.8543 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17753: loss = 5.4950 (0.100 sec/step)\n",
            "I1003 00:59:40.369586 139845451286400 learning.py:512] global step 17753: loss = 5.4950 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17754: loss = 10.6480 (0.103 sec/step)\n",
            "I1003 00:59:40.474410 139845451286400 learning.py:512] global step 17754: loss = 10.6480 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17755: loss = 6.9310 (0.107 sec/step)\n",
            "I1003 00:59:40.584751 139845451286400 learning.py:512] global step 17755: loss = 6.9310 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17756: loss = 4.3601 (0.094 sec/step)\n",
            "I1003 00:59:40.680591 139845451286400 learning.py:512] global step 17756: loss = 4.3601 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17757: loss = 3.9910 (0.099 sec/step)\n",
            "I1003 00:59:40.780745 139845451286400 learning.py:512] global step 17757: loss = 3.9910 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17758: loss = 6.0507 (0.092 sec/step)\n",
            "I1003 00:59:40.874145 139845451286400 learning.py:512] global step 17758: loss = 6.0507 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17759: loss = 3.3894 (0.109 sec/step)\n",
            "I1003 00:59:40.984353 139845451286400 learning.py:512] global step 17759: loss = 3.3894 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17760: loss = 5.4557 (0.106 sec/step)\n",
            "I1003 00:59:41.091686 139845451286400 learning.py:512] global step 17760: loss = 5.4557 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17761: loss = 6.8160 (0.096 sec/step)\n",
            "I1003 00:59:41.189051 139845451286400 learning.py:512] global step 17761: loss = 6.8160 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17762: loss = 3.0443 (0.098 sec/step)\n",
            "I1003 00:59:41.288218 139845451286400 learning.py:512] global step 17762: loss = 3.0443 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17763: loss = 4.6878 (0.093 sec/step)\n",
            "I1003 00:59:41.382674 139845451286400 learning.py:512] global step 17763: loss = 4.6878 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17764: loss = 7.2717 (0.105 sec/step)\n",
            "I1003 00:59:41.488894 139845451286400 learning.py:512] global step 17764: loss = 7.2717 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17765: loss = 2.6881 (0.095 sec/step)\n",
            "I1003 00:59:41.585494 139845451286400 learning.py:512] global step 17765: loss = 2.6881 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17766: loss = 3.9659 (0.102 sec/step)\n",
            "I1003 00:59:41.689473 139845451286400 learning.py:512] global step 17766: loss = 3.9659 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17767: loss = 3.9765 (0.104 sec/step)\n",
            "I1003 00:59:41.795009 139845451286400 learning.py:512] global step 17767: loss = 3.9765 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17768: loss = 2.7548 (0.096 sec/step)\n",
            "I1003 00:59:41.892344 139845451286400 learning.py:512] global step 17768: loss = 2.7548 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17769: loss = 2.1672 (0.093 sec/step)\n",
            "I1003 00:59:41.986689 139845451286400 learning.py:512] global step 17769: loss = 2.1672 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17770: loss = 2.9057 (0.102 sec/step)\n",
            "I1003 00:59:42.089968 139845451286400 learning.py:512] global step 17770: loss = 2.9057 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17771: loss = 2.8799 (0.111 sec/step)\n",
            "I1003 00:59:42.202547 139845451286400 learning.py:512] global step 17771: loss = 2.8799 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17772: loss = 4.4656 (0.104 sec/step)\n",
            "I1003 00:59:42.308283 139845451286400 learning.py:512] global step 17772: loss = 4.4656 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17773: loss = 4.4534 (0.099 sec/step)\n",
            "I1003 00:59:42.408480 139845451286400 learning.py:512] global step 17773: loss = 4.4534 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17774: loss = 2.2547 (0.098 sec/step)\n",
            "I1003 00:59:42.508041 139845451286400 learning.py:512] global step 17774: loss = 2.2547 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17775: loss = 3.9279 (0.101 sec/step)\n",
            "I1003 00:59:42.610229 139845451286400 learning.py:512] global step 17775: loss = 3.9279 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17776: loss = 4.0763 (0.105 sec/step)\n",
            "I1003 00:59:42.716603 139845451286400 learning.py:512] global step 17776: loss = 4.0763 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17777: loss = 4.4742 (0.092 sec/step)\n",
            "I1003 00:59:42.809746 139845451286400 learning.py:512] global step 17777: loss = 4.4742 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17778: loss = 3.4564 (0.100 sec/step)\n",
            "I1003 00:59:42.911396 139845451286400 learning.py:512] global step 17778: loss = 3.4564 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17779: loss = 4.9453 (0.102 sec/step)\n",
            "I1003 00:59:43.014909 139845451286400 learning.py:512] global step 17779: loss = 4.9453 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17780: loss = 3.2002 (0.123 sec/step)\n",
            "I1003 00:59:43.139083 139845451286400 learning.py:512] global step 17780: loss = 3.2002 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 17781: loss = 2.5910 (0.107 sec/step)\n",
            "I1003 00:59:43.247550 139845451286400 learning.py:512] global step 17781: loss = 2.5910 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17782: loss = 9.4211 (0.097 sec/step)\n",
            "I1003 00:59:43.346181 139845451286400 learning.py:512] global step 17782: loss = 9.4211 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17783: loss = 3.8914 (0.100 sec/step)\n",
            "I1003 00:59:43.447660 139845451286400 learning.py:512] global step 17783: loss = 3.8914 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17784: loss = 10.9130 (0.103 sec/step)\n",
            "I1003 00:59:43.552058 139845451286400 learning.py:512] global step 17784: loss = 10.9130 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17785: loss = 3.5287 (0.105 sec/step)\n",
            "I1003 00:59:43.658745 139845451286400 learning.py:512] global step 17785: loss = 3.5287 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17786: loss = 2.6006 (0.096 sec/step)\n",
            "I1003 00:59:43.755803 139845451286400 learning.py:512] global step 17786: loss = 2.6006 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17787: loss = 6.4786 (0.099 sec/step)\n",
            "I1003 00:59:43.856067 139845451286400 learning.py:512] global step 17787: loss = 6.4786 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17788: loss = 3.9964 (0.106 sec/step)\n",
            "I1003 00:59:43.963424 139845451286400 learning.py:512] global step 17788: loss = 3.9964 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17789: loss = 5.3256 (0.107 sec/step)\n",
            "I1003 00:59:44.071624 139845451286400 learning.py:512] global step 17789: loss = 5.3256 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17790: loss = 2.8819 (0.099 sec/step)\n",
            "I1003 00:59:44.172490 139845451286400 learning.py:512] global step 17790: loss = 2.8819 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17791: loss = 4.6780 (0.114 sec/step)\n",
            "I1003 00:59:44.288221 139845451286400 learning.py:512] global step 17791: loss = 4.6780 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 17792: loss = 3.6661 (0.094 sec/step)\n",
            "I1003 00:59:44.383699 139845451286400 learning.py:512] global step 17792: loss = 3.6661 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17793: loss = 6.1952 (0.092 sec/step)\n",
            "I1003 00:59:44.477021 139845451286400 learning.py:512] global step 17793: loss = 6.1952 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17794: loss = 3.4920 (0.095 sec/step)\n",
            "I1003 00:59:44.573670 139845451286400 learning.py:512] global step 17794: loss = 3.4920 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17795: loss = 3.9726 (0.106 sec/step)\n",
            "I1003 00:59:44.681917 139845451286400 learning.py:512] global step 17795: loss = 3.9726 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17796: loss = 3.1906 (0.092 sec/step)\n",
            "I1003 00:59:44.775903 139845451286400 learning.py:512] global step 17796: loss = 3.1906 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17797: loss = 4.2508 (0.098 sec/step)\n",
            "I1003 00:59:44.874835 139845451286400 learning.py:512] global step 17797: loss = 4.2508 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17798: loss = 2.3794 (0.095 sec/step)\n",
            "I1003 00:59:44.970902 139845451286400 learning.py:512] global step 17798: loss = 2.3794 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17799: loss = 3.5064 (0.102 sec/step)\n",
            "I1003 00:59:45.074481 139845451286400 learning.py:512] global step 17799: loss = 3.5064 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17800: loss = 2.3521 (0.104 sec/step)\n",
            "I1003 00:59:45.179315 139845451286400 learning.py:512] global step 17800: loss = 2.3521 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17801: loss = 2.6715 (0.115 sec/step)\n",
            "I1003 00:59:45.295707 139845451286400 learning.py:512] global step 17801: loss = 2.6715 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 17802: loss = 3.7244 (0.104 sec/step)\n",
            "I1003 00:59:45.401399 139845451286400 learning.py:512] global step 17802: loss = 3.7244 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17803: loss = 6.0418 (0.103 sec/step)\n",
            "I1003 00:59:45.505648 139845451286400 learning.py:512] global step 17803: loss = 6.0418 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17804: loss = 7.0711 (0.097 sec/step)\n",
            "I1003 00:59:45.603557 139845451286400 learning.py:512] global step 17804: loss = 7.0711 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17805: loss = 2.1844 (0.096 sec/step)\n",
            "I1003 00:59:45.700469 139845451286400 learning.py:512] global step 17805: loss = 2.1844 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17806: loss = 3.0005 (0.103 sec/step)\n",
            "I1003 00:59:45.804749 139845451286400 learning.py:512] global step 17806: loss = 3.0005 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17807: loss = 3.9960 (0.097 sec/step)\n",
            "I1003 00:59:45.902670 139845451286400 learning.py:512] global step 17807: loss = 3.9960 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17808: loss = 4.6529 (0.094 sec/step)\n",
            "I1003 00:59:45.998321 139845451286400 learning.py:512] global step 17808: loss = 4.6529 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17809: loss = 5.2614 (0.102 sec/step)\n",
            "I1003 00:59:46.101496 139845451286400 learning.py:512] global step 17809: loss = 5.2614 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17810: loss = 3.5975 (0.101 sec/step)\n",
            "I1003 00:59:46.203945 139845451286400 learning.py:512] global step 17810: loss = 3.5975 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17811: loss = 2.9295 (0.119 sec/step)\n",
            "I1003 00:59:46.324698 139845451286400 learning.py:512] global step 17811: loss = 2.9295 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 17812: loss = 2.5700 (0.095 sec/step)\n",
            "I1003 00:59:46.420753 139845451286400 learning.py:512] global step 17812: loss = 2.5700 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17813: loss = 8.4808 (0.103 sec/step)\n",
            "I1003 00:59:46.524859 139845451286400 learning.py:512] global step 17813: loss = 8.4808 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17814: loss = 2.6896 (0.099 sec/step)\n",
            "I1003 00:59:46.624847 139845451286400 learning.py:512] global step 17814: loss = 2.6896 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17815: loss = 2.3558 (0.102 sec/step)\n",
            "I1003 00:59:46.727647 139845451286400 learning.py:512] global step 17815: loss = 2.3558 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17816: loss = 2.7121 (0.097 sec/step)\n",
            "I1003 00:59:46.826121 139845451286400 learning.py:512] global step 17816: loss = 2.7121 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17817: loss = 2.9465 (0.100 sec/step)\n",
            "I1003 00:59:46.927974 139845451286400 learning.py:512] global step 17817: loss = 2.9465 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17818: loss = 4.5534 (0.100 sec/step)\n",
            "I1003 00:59:47.029133 139845451286400 learning.py:512] global step 17818: loss = 4.5534 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17819: loss = 4.2340 (0.105 sec/step)\n",
            "I1003 00:59:47.135918 139845451286400 learning.py:512] global step 17819: loss = 4.2340 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17820: loss = 4.1970 (0.117 sec/step)\n",
            "I1003 00:59:47.254602 139845451286400 learning.py:512] global step 17820: loss = 4.1970 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 17821: loss = 3.4880 (0.131 sec/step)\n",
            "I1003 00:59:47.386966 139845451286400 learning.py:512] global step 17821: loss = 3.4880 (0.131 sec/step)\n",
            "INFO:tensorflow:global step 17822: loss = 4.1939 (0.116 sec/step)\n",
            "I1003 00:59:47.504890 139845451286400 learning.py:512] global step 17822: loss = 4.1939 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 17823: loss = 3.7588 (0.138 sec/step)\n",
            "I1003 00:59:47.644630 139845451286400 learning.py:512] global step 17823: loss = 3.7588 (0.138 sec/step)\n",
            "INFO:tensorflow:global step 17824: loss = 5.8231 (0.129 sec/step)\n",
            "I1003 00:59:47.775068 139845451286400 learning.py:512] global step 17824: loss = 5.8231 (0.129 sec/step)\n",
            "INFO:tensorflow:global step 17825: loss = 7.7055 (0.096 sec/step)\n",
            "I1003 00:59:47.872560 139845451286400 learning.py:512] global step 17825: loss = 7.7055 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17826: loss = 6.7665 (0.104 sec/step)\n",
            "I1003 00:59:47.977980 139845451286400 learning.py:512] global step 17826: loss = 6.7665 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17827: loss = 4.2558 (0.107 sec/step)\n",
            "I1003 00:59:48.087141 139845451286400 learning.py:512] global step 17827: loss = 4.2558 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17828: loss = 6.1559 (0.103 sec/step)\n",
            "I1003 00:59:48.191504 139845451286400 learning.py:512] global step 17828: loss = 6.1559 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17829: loss = 4.1547 (0.113 sec/step)\n",
            "I1003 00:59:48.309105 139845451286400 learning.py:512] global step 17829: loss = 4.1547 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17830: loss = 4.5473 (0.109 sec/step)\n",
            "I1003 00:59:48.419857 139845451286400 learning.py:512] global step 17830: loss = 4.5473 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17831: loss = 5.7433 (0.111 sec/step)\n",
            "I1003 00:59:48.531952 139845451286400 learning.py:512] global step 17831: loss = 5.7433 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17832: loss = 3.1023 (0.114 sec/step)\n",
            "I1003 00:59:48.647784 139845451286400 learning.py:512] global step 17832: loss = 3.1023 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 17833: loss = 3.1929 (0.091 sec/step)\n",
            "I1003 00:59:48.740386 139845451286400 learning.py:512] global step 17833: loss = 3.1929 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 17834: loss = 2.8339 (0.092 sec/step)\n",
            "I1003 00:59:48.834381 139845451286400 learning.py:512] global step 17834: loss = 2.8339 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17835: loss = 4.6612 (0.099 sec/step)\n",
            "I1003 00:59:48.935028 139845451286400 learning.py:512] global step 17835: loss = 4.6612 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17836: loss = 5.7006 (0.099 sec/step)\n",
            "I1003 00:59:49.036048 139845451286400 learning.py:512] global step 17836: loss = 5.7006 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17837: loss = 2.7634 (0.096 sec/step)\n",
            "I1003 00:59:49.133566 139845451286400 learning.py:512] global step 17837: loss = 2.7634 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17838: loss = 3.5121 (0.114 sec/step)\n",
            "I1003 00:59:49.249255 139845451286400 learning.py:512] global step 17838: loss = 3.5121 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 17839: loss = 2.8651 (0.106 sec/step)\n",
            "I1003 00:59:49.357040 139845451286400 learning.py:512] global step 17839: loss = 2.8651 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17840: loss = 3.7973 (0.101 sec/step)\n",
            "I1003 00:59:49.459156 139845451286400 learning.py:512] global step 17840: loss = 3.7973 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17841: loss = 3.6008 (0.100 sec/step)\n",
            "I1003 00:59:49.560665 139845451286400 learning.py:512] global step 17841: loss = 3.6008 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17842: loss = 5.2226 (0.094 sec/step)\n",
            "I1003 00:59:49.656454 139845451286400 learning.py:512] global step 17842: loss = 5.2226 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17843: loss = 8.2209 (0.099 sec/step)\n",
            "I1003 00:59:49.757135 139845451286400 learning.py:512] global step 17843: loss = 8.2209 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17844: loss = 2.6546 (0.093 sec/step)\n",
            "I1003 00:59:49.852051 139845451286400 learning.py:512] global step 17844: loss = 2.6546 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17845: loss = 3.1292 (0.093 sec/step)\n",
            "I1003 00:59:49.946961 139845451286400 learning.py:512] global step 17845: loss = 3.1292 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17846: loss = 2.7521 (0.096 sec/step)\n",
            "I1003 00:59:50.044875 139845451286400 learning.py:512] global step 17846: loss = 2.7521 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17847: loss = 2.4215 (0.093 sec/step)\n",
            "I1003 00:59:50.139656 139845451286400 learning.py:512] global step 17847: loss = 2.4215 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17848: loss = 3.1565 (0.102 sec/step)\n",
            "I1003 00:59:50.242928 139845451286400 learning.py:512] global step 17848: loss = 3.1565 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17849: loss = 2.3819 (0.098 sec/step)\n",
            "I1003 00:59:50.342198 139845451286400 learning.py:512] global step 17849: loss = 2.3819 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17850: loss = 3.8595 (0.109 sec/step)\n",
            "I1003 00:59:50.452545 139845451286400 learning.py:512] global step 17850: loss = 3.8595 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17851: loss = 2.9596 (0.093 sec/step)\n",
            "I1003 00:59:50.546751 139845451286400 learning.py:512] global step 17851: loss = 2.9596 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17852: loss = 3.2628 (0.099 sec/step)\n",
            "I1003 00:59:50.647621 139845451286400 learning.py:512] global step 17852: loss = 3.2628 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17853: loss = 2.3183 (0.096 sec/step)\n",
            "I1003 00:59:50.744958 139845451286400 learning.py:512] global step 17853: loss = 2.3183 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17854: loss = 11.9150 (0.093 sec/step)\n",
            "I1003 00:59:50.839592 139845451286400 learning.py:512] global step 17854: loss = 11.9150 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17855: loss = 3.2220 (0.098 sec/step)\n",
            "I1003 00:59:50.939938 139845451286400 learning.py:512] global step 17855: loss = 3.2220 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17856: loss = 2.6243 (0.111 sec/step)\n",
            "I1003 00:59:51.052218 139845451286400 learning.py:512] global step 17856: loss = 2.6243 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17857: loss = 5.2689 (0.096 sec/step)\n",
            "I1003 00:59:51.149759 139845451286400 learning.py:512] global step 17857: loss = 5.2689 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17858: loss = 2.8312 (0.112 sec/step)\n",
            "I1003 00:59:51.263231 139845451286400 learning.py:512] global step 17858: loss = 2.8312 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 17859: loss = 3.4946 (0.133 sec/step)\n",
            "I1003 00:59:51.402631 139845451286400 learning.py:512] global step 17859: loss = 3.4946 (0.133 sec/step)\n",
            "INFO:tensorflow:global step 17860: loss = 5.5585 (0.113 sec/step)\n",
            "I1003 00:59:51.517803 139845451286400 learning.py:512] global step 17860: loss = 5.5585 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17861: loss = 2.8446 (0.109 sec/step)\n",
            "I1003 00:59:51.628204 139845451286400 learning.py:512] global step 17861: loss = 2.8446 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17862: loss = 3.9364 (0.113 sec/step)\n",
            "I1003 00:59:51.742367 139845451286400 learning.py:512] global step 17862: loss = 3.9364 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17863: loss = 2.6879 (0.103 sec/step)\n",
            "I1003 00:59:51.847082 139845451286400 learning.py:512] global step 17863: loss = 2.6879 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17864: loss = 5.3224 (0.100 sec/step)\n",
            "I1003 00:59:51.948877 139845451286400 learning.py:512] global step 17864: loss = 5.3224 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17865: loss = 2.4167 (0.113 sec/step)\n",
            "I1003 00:59:52.063151 139845451286400 learning.py:512] global step 17865: loss = 2.4167 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17866: loss = 5.6986 (0.109 sec/step)\n",
            "I1003 00:59:52.173228 139845451286400 learning.py:512] global step 17866: loss = 5.6986 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17867: loss = 5.1083 (0.105 sec/step)\n",
            "I1003 00:59:52.280254 139845451286400 learning.py:512] global step 17867: loss = 5.1083 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17868: loss = 2.8065 (0.106 sec/step)\n",
            "I1003 00:59:52.388075 139845451286400 learning.py:512] global step 17868: loss = 2.8065 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17869: loss = 5.5194 (0.113 sec/step)\n",
            "I1003 00:59:52.503086 139845451286400 learning.py:512] global step 17869: loss = 5.5194 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17870: loss = 3.6828 (0.097 sec/step)\n",
            "I1003 00:59:52.603615 139845451286400 learning.py:512] global step 17870: loss = 3.6828 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17871: loss = 2.7265 (0.095 sec/step)\n",
            "I1003 00:59:52.700253 139845451286400 learning.py:512] global step 17871: loss = 2.7265 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17872: loss = 4.6681 (0.105 sec/step)\n",
            "I1003 00:59:52.808286 139845451286400 learning.py:512] global step 17872: loss = 4.6681 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17873: loss = 6.6884 (0.096 sec/step)\n",
            "I1003 00:59:52.905589 139845451286400 learning.py:512] global step 17873: loss = 6.6884 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17874: loss = 4.5231 (0.092 sec/step)\n",
            "I1003 00:59:53.000891 139845451286400 learning.py:512] global step 17874: loss = 4.5231 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17875: loss = 3.1953 (0.093 sec/step)\n",
            "I1003 00:59:53.095441 139845451286400 learning.py:512] global step 17875: loss = 3.1953 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17876: loss = 2.7525 (0.105 sec/step)\n",
            "I1003 00:59:53.201836 139845451286400 learning.py:512] global step 17876: loss = 2.7525 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17877: loss = 3.1795 (0.109 sec/step)\n",
            "I1003 00:59:53.312222 139845451286400 learning.py:512] global step 17877: loss = 3.1795 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17878: loss = 5.2197 (0.111 sec/step)\n",
            "I1003 00:59:53.425664 139845451286400 learning.py:512] global step 17878: loss = 5.2197 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17879: loss = 5.3637 (0.120 sec/step)\n",
            "I1003 00:59:53.550516 139845451286400 learning.py:512] global step 17879: loss = 5.3637 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 17880: loss = 4.3208 (0.098 sec/step)\n",
            "I1003 00:59:53.649695 139845451286400 learning.py:512] global step 17880: loss = 4.3208 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17881: loss = 3.5779 (0.108 sec/step)\n",
            "I1003 00:59:53.758600 139845451286400 learning.py:512] global step 17881: loss = 3.5779 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 17882: loss = 4.1115 (0.098 sec/step)\n",
            "I1003 00:59:53.859275 139845451286400 learning.py:512] global step 17882: loss = 4.1115 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17883: loss = 4.0177 (0.095 sec/step)\n",
            "I1003 00:59:53.955270 139845451286400 learning.py:512] global step 17883: loss = 4.0177 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17884: loss = 3.6083 (0.093 sec/step)\n",
            "I1003 00:59:54.049685 139845451286400 learning.py:512] global step 17884: loss = 3.6083 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17885: loss = 3.6114 (0.105 sec/step)\n",
            "I1003 00:59:54.156568 139845451286400 learning.py:512] global step 17885: loss = 3.6114 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17886: loss = 4.2679 (0.105 sec/step)\n",
            "I1003 00:59:54.262860 139845451286400 learning.py:512] global step 17886: loss = 4.2679 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17887: loss = 2.5354 (0.111 sec/step)\n",
            "I1003 00:59:54.375833 139845451286400 learning.py:512] global step 17887: loss = 2.5354 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17888: loss = 8.7498 (0.133 sec/step)\n",
            "I1003 00:59:54.510125 139845451286400 learning.py:512] global step 17888: loss = 8.7498 (0.133 sec/step)\n",
            "INFO:tensorflow:global step 17889: loss = 3.6073 (0.116 sec/step)\n",
            "I1003 00:59:54.627956 139845451286400 learning.py:512] global step 17889: loss = 3.6073 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 17890: loss = 6.9152 (0.114 sec/step)\n",
            "I1003 00:59:54.743192 139845451286400 learning.py:512] global step 17890: loss = 6.9152 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 17891: loss = 2.7088 (0.109 sec/step)\n",
            "I1003 00:59:54.853747 139845451286400 learning.py:512] global step 17891: loss = 2.7088 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17892: loss = 2.8397 (0.123 sec/step)\n",
            "I1003 00:59:54.978803 139845451286400 learning.py:512] global step 17892: loss = 2.8397 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 17893: loss = 3.3900 (0.106 sec/step)\n",
            "I1003 00:59:55.086963 139845451286400 learning.py:512] global step 17893: loss = 3.3900 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17894: loss = 1.9403 (0.095 sec/step)\n",
            "I1003 00:59:55.183775 139845451286400 learning.py:512] global step 17894: loss = 1.9403 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17895: loss = 2.8460 (0.093 sec/step)\n",
            "I1003 00:59:55.278530 139845451286400 learning.py:512] global step 17895: loss = 2.8460 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17896: loss = 3.1030 (0.106 sec/step)\n",
            "I1003 00:59:55.386465 139845451286400 learning.py:512] global step 17896: loss = 3.1030 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17897: loss = 2.9660 (0.127 sec/step)\n",
            "I1003 00:59:55.514542 139845451286400 learning.py:512] global step 17897: loss = 2.9660 (0.127 sec/step)\n",
            "INFO:tensorflow:global step 17898: loss = 6.6809 (0.095 sec/step)\n",
            "I1003 00:59:55.611040 139845451286400 learning.py:512] global step 17898: loss = 6.6809 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17899: loss = 4.1597 (0.099 sec/step)\n",
            "I1003 00:59:55.711289 139845451286400 learning.py:512] global step 17899: loss = 4.1597 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17900: loss = 3.4079 (0.105 sec/step)\n",
            "I1003 00:59:55.817265 139845451286400 learning.py:512] global step 17900: loss = 3.4079 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17901: loss = 6.3186 (0.102 sec/step)\n",
            "I1003 00:59:55.920237 139845451286400 learning.py:512] global step 17901: loss = 6.3186 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17902: loss = 2.3151 (0.118 sec/step)\n",
            "I1003 00:59:56.039514 139845451286400 learning.py:512] global step 17902: loss = 2.3151 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 17903: loss = 3.1831 (0.111 sec/step)\n",
            "I1003 00:59:56.151659 139845451286400 learning.py:512] global step 17903: loss = 3.1831 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17904: loss = 3.2435 (0.104 sec/step)\n",
            "I1003 00:59:56.256976 139845451286400 learning.py:512] global step 17904: loss = 3.2435 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 17905: loss = 4.0446 (0.103 sec/step)\n",
            "I1003 00:59:56.361596 139845451286400 learning.py:512] global step 17905: loss = 4.0446 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17906: loss = 3.3728 (0.115 sec/step)\n",
            "I1003 00:59:56.477843 139845451286400 learning.py:512] global step 17906: loss = 3.3728 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 17907: loss = 5.1025 (0.108 sec/step)\n",
            "I1003 00:59:56.587698 139845451286400 learning.py:512] global step 17907: loss = 5.1025 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 17908: loss = 5.6131 (0.111 sec/step)\n",
            "I1003 00:59:56.700783 139845451286400 learning.py:512] global step 17908: loss = 5.6131 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17909: loss = 3.3829 (0.099 sec/step)\n",
            "I1003 00:59:56.801050 139845451286400 learning.py:512] global step 17909: loss = 3.3829 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17910: loss = 2.7343 (0.105 sec/step)\n",
            "I1003 00:59:56.907495 139845451286400 learning.py:512] global step 17910: loss = 2.7343 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17911: loss = 4.1845 (0.105 sec/step)\n",
            "I1003 00:59:57.014091 139845451286400 learning.py:512] global step 17911: loss = 4.1845 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17912: loss = 2.9429 (0.114 sec/step)\n",
            "I1003 00:59:57.129868 139845451286400 learning.py:512] global step 17912: loss = 2.9429 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 17913: loss = 3.1977 (0.092 sec/step)\n",
            "I1003 00:59:57.223452 139845451286400 learning.py:512] global step 17913: loss = 3.1977 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17914: loss = 4.4433 (0.097 sec/step)\n",
            "I1003 00:59:57.321583 139845451286400 learning.py:512] global step 17914: loss = 4.4433 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17915: loss = 2.0719 (0.100 sec/step)\n",
            "I1003 00:59:57.423210 139845451286400 learning.py:512] global step 17915: loss = 2.0719 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17916: loss = 4.6366 (0.118 sec/step)\n",
            "I1003 00:59:57.543060 139845451286400 learning.py:512] global step 17916: loss = 4.6366 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 17917: loss = 3.3672 (0.100 sec/step)\n",
            "I1003 00:59:57.644896 139845451286400 learning.py:512] global step 17917: loss = 3.3672 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17918: loss = 2.7586 (0.100 sec/step)\n",
            "I1003 00:59:57.746629 139845451286400 learning.py:512] global step 17918: loss = 2.7586 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17919: loss = 3.7848 (0.113 sec/step)\n",
            "I1003 00:59:57.860704 139845451286400 learning.py:512] global step 17919: loss = 3.7848 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17920: loss = 3.8992 (0.110 sec/step)\n",
            "I1003 00:59:57.972326 139845451286400 learning.py:512] global step 17920: loss = 3.8992 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17921: loss = 2.5782 (0.124 sec/step)\n",
            "I1003 00:59:58.097576 139845451286400 learning.py:512] global step 17921: loss = 2.5782 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 17922: loss = 9.8792 (0.107 sec/step)\n",
            "I1003 00:59:58.206526 139845451286400 learning.py:512] global step 17922: loss = 9.8792 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17923: loss = 4.5235 (0.100 sec/step)\n",
            "I1003 00:59:58.307353 139845451286400 learning.py:512] global step 17923: loss = 4.5235 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17924: loss = 7.7678 (0.089 sec/step)\n",
            "I1003 00:59:58.397271 139845451286400 learning.py:512] global step 17924: loss = 7.7678 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 17925: loss = 3.2967 (0.108 sec/step)\n",
            "I1003 00:59:58.508409 139845451286400 learning.py:512] global step 17925: loss = 3.2967 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 17926: loss = 5.8976 (0.095 sec/step)\n",
            "I1003 00:59:58.605670 139845451286400 learning.py:512] global step 17926: loss = 5.8976 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17927: loss = 4.1389 (0.108 sec/step)\n",
            "I1003 00:59:58.714685 139845451286400 learning.py:512] global step 17927: loss = 4.1389 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 17928: loss = 3.8914 (0.107 sec/step)\n",
            "I1003 00:59:58.822484 139845451286400 learning.py:512] global step 17928: loss = 3.8914 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17929: loss = 3.1052 (0.100 sec/step)\n",
            "I1003 00:59:58.924237 139845451286400 learning.py:512] global step 17929: loss = 3.1052 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17930: loss = 3.3685 (0.109 sec/step)\n",
            "I1003 00:59:59.034795 139845451286400 learning.py:512] global step 17930: loss = 3.3685 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 17931: loss = 4.3120 (0.100 sec/step)\n",
            "I1003 00:59:59.135890 139845451286400 learning.py:512] global step 17931: loss = 4.3120 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17932: loss = 4.7877 (0.101 sec/step)\n",
            "I1003 00:59:59.238440 139845451286400 learning.py:512] global step 17932: loss = 4.7877 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17933: loss = 1.9287 (0.089 sec/step)\n",
            "I1003 00:59:59.328466 139845451286400 learning.py:512] global step 17933: loss = 1.9287 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 17934: loss = 3.3332 (0.090 sec/step)\n",
            "I1003 00:59:59.419600 139845451286400 learning.py:512] global step 17934: loss = 3.3332 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 17935: loss = 5.3676 (0.110 sec/step)\n",
            "I1003 00:59:59.530579 139845451286400 learning.py:512] global step 17935: loss = 5.3676 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17936: loss = 2.3650 (0.098 sec/step)\n",
            "I1003 00:59:59.632641 139845451286400 learning.py:512] global step 17936: loss = 2.3650 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17937: loss = 11.7738 (0.086 sec/step)\n",
            "I1003 00:59:59.720054 139845451286400 learning.py:512] global step 17937: loss = 11.7738 (0.086 sec/step)\n",
            "INFO:tensorflow:global step 17938: loss = 2.9932 (0.096 sec/step)\n",
            "I1003 00:59:59.817305 139845451286400 learning.py:512] global step 17938: loss = 2.9932 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17939: loss = 3.2744 (0.095 sec/step)\n",
            "I1003 00:59:59.914117 139845451286400 learning.py:512] global step 17939: loss = 3.2744 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17940: loss = 2.8275 (0.098 sec/step)\n",
            "I1003 01:00:00.014055 139845451286400 learning.py:512] global step 17940: loss = 2.8275 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17941: loss = 1.6669 (0.094 sec/step)\n",
            "I1003 01:00:00.109416 139845451286400 learning.py:512] global step 17941: loss = 1.6669 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17942: loss = 5.8805 (0.096 sec/step)\n",
            "I1003 01:00:00.207165 139845451286400 learning.py:512] global step 17942: loss = 5.8805 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17943: loss = 4.3797 (0.111 sec/step)\n",
            "I1003 01:00:00.319778 139845451286400 learning.py:512] global step 17943: loss = 4.3797 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 17944: loss = 2.5821 (0.110 sec/step)\n",
            "I1003 01:00:00.431102 139845451286400 learning.py:512] global step 17944: loss = 2.5821 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17945: loss = 7.8526 (0.100 sec/step)\n",
            "I1003 01:00:00.532109 139845451286400 learning.py:512] global step 17945: loss = 7.8526 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17946: loss = 7.2392 (0.102 sec/step)\n",
            "I1003 01:00:00.635908 139845451286400 learning.py:512] global step 17946: loss = 7.2392 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17947: loss = 3.1970 (0.103 sec/step)\n",
            "I1003 01:00:00.739973 139845451286400 learning.py:512] global step 17947: loss = 3.1970 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17948: loss = 4.5311 (0.100 sec/step)\n",
            "I1003 01:00:00.840935 139845451286400 learning.py:512] global step 17948: loss = 4.5311 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 17949: loss = 3.3357 (0.105 sec/step)\n",
            "I1003 01:00:00.947604 139845451286400 learning.py:512] global step 17949: loss = 3.3357 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17950: loss = 3.4037 (0.096 sec/step)\n",
            "I1003 01:00:01.045436 139845451286400 learning.py:512] global step 17950: loss = 3.4037 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17951: loss = 9.1236 (0.102 sec/step)\n",
            "I1003 01:00:01.149160 139845451286400 learning.py:512] global step 17951: loss = 9.1236 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17952: loss = 3.3955 (0.099 sec/step)\n",
            "I1003 01:00:01.249675 139845451286400 learning.py:512] global step 17952: loss = 3.3955 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17953: loss = 8.5693 (0.089 sec/step)\n",
            "I1003 01:00:01.339570 139845451286400 learning.py:512] global step 17953: loss = 8.5693 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 17954: loss = 3.7035 (0.103 sec/step)\n",
            "I1003 01:00:01.443595 139845451286400 learning.py:512] global step 17954: loss = 3.7035 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 17955: loss = 5.8332 (0.101 sec/step)\n",
            "I1003 01:00:01.545589 139845451286400 learning.py:512] global step 17955: loss = 5.8332 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17956: loss = 6.0098 (0.105 sec/step)\n",
            "I1003 01:00:01.652225 139845451286400 learning.py:512] global step 17956: loss = 6.0098 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17957: loss = 4.2361 (0.090 sec/step)\n",
            "I1003 01:00:01.743901 139845451286400 learning.py:512] global step 17957: loss = 4.2361 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 17958: loss = 3.5770 (0.096 sec/step)\n",
            "I1003 01:00:01.841778 139845451286400 learning.py:512] global step 17958: loss = 3.5770 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17959: loss = 7.7158 (0.093 sec/step)\n",
            "I1003 01:00:01.935742 139845451286400 learning.py:512] global step 17959: loss = 7.7158 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17960: loss = 3.5978 (0.115 sec/step)\n",
            "I1003 01:00:02.052550 139845451286400 learning.py:512] global step 17960: loss = 3.5978 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 17961: loss = 3.9765 (0.108 sec/step)\n",
            "I1003 01:00:02.162045 139845451286400 learning.py:512] global step 17961: loss = 3.9765 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 17962: loss = 3.5482 (0.113 sec/step)\n",
            "I1003 01:00:02.279759 139845451286400 learning.py:512] global step 17962: loss = 3.5482 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17963: loss = 9.6841 (0.117 sec/step)\n",
            "I1003 01:00:02.398165 139845451286400 learning.py:512] global step 17963: loss = 9.6841 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 17964: loss = 7.2475 (0.117 sec/step)\n",
            "I1003 01:00:02.516552 139845451286400 learning.py:512] global step 17964: loss = 7.2475 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 17965: loss = 7.0140 (0.123 sec/step)\n",
            "I1003 01:00:02.641151 139845451286400 learning.py:512] global step 17965: loss = 7.0140 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 17966: loss = 6.9804 (0.110 sec/step)\n",
            "I1003 01:00:02.753148 139845451286400 learning.py:512] global step 17966: loss = 6.9804 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 17967: loss = 2.7775 (0.120 sec/step)\n",
            "I1003 01:00:02.874363 139845451286400 learning.py:512] global step 17967: loss = 2.7775 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 17968: loss = 5.9724 (0.120 sec/step)\n",
            "I1003 01:00:02.995666 139845451286400 learning.py:512] global step 17968: loss = 5.9724 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 17969: loss = 5.0557 (0.094 sec/step)\n",
            "I1003 01:00:03.091336 139845451286400 learning.py:512] global step 17969: loss = 5.0557 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17970: loss = 6.4602 (0.099 sec/step)\n",
            "I1003 01:00:03.191505 139845451286400 learning.py:512] global step 17970: loss = 6.4602 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17971: loss = 3.5573 (0.102 sec/step)\n",
            "I1003 01:00:03.294642 139845451286400 learning.py:512] global step 17971: loss = 3.5573 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17972: loss = 9.2391 (0.092 sec/step)\n",
            "I1003 01:00:03.388006 139845451286400 learning.py:512] global step 17972: loss = 9.2391 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 17973: loss = 2.9072 (0.094 sec/step)\n",
            "I1003 01:00:03.483647 139845451286400 learning.py:512] global step 17973: loss = 2.9072 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 17974: loss = 3.8124 (0.113 sec/step)\n",
            "I1003 01:00:03.597899 139845451286400 learning.py:512] global step 17974: loss = 3.8124 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 17975: loss = 2.6909 (0.106 sec/step)\n",
            "I1003 01:00:03.705530 139845451286400 learning.py:512] global step 17975: loss = 2.6909 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17976: loss = 3.4435 (0.098 sec/step)\n",
            "I1003 01:00:03.805178 139845451286400 learning.py:512] global step 17976: loss = 3.4435 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17977: loss = 8.1395 (0.102 sec/step)\n",
            "I1003 01:00:03.908473 139845451286400 learning.py:512] global step 17977: loss = 8.1395 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17978: loss = 5.7215 (0.093 sec/step)\n",
            "I1003 01:00:04.002621 139845451286400 learning.py:512] global step 17978: loss = 5.7215 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 17979: loss = 8.1170 (0.107 sec/step)\n",
            "I1003 01:00:04.111026 139845451286400 learning.py:512] global step 17979: loss = 8.1170 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17980: loss = 3.8916 (0.105 sec/step)\n",
            "I1003 01:00:04.217060 139845451286400 learning.py:512] global step 17980: loss = 3.8916 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 17981: loss = 4.0116 (0.096 sec/step)\n",
            "I1003 01:00:04.314252 139845451286400 learning.py:512] global step 17981: loss = 4.0116 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17982: loss = 3.9677 (0.097 sec/step)\n",
            "I1003 01:00:04.412706 139845451286400 learning.py:512] global step 17982: loss = 3.9677 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 17983: loss = 9.6657 (0.107 sec/step)\n",
            "I1003 01:00:04.520846 139845451286400 learning.py:512] global step 17983: loss = 9.6657 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17984: loss = 8.8637 (0.107 sec/step)\n",
            "I1003 01:00:04.628700 139845451286400 learning.py:512] global step 17984: loss = 8.8637 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 17985: loss = 5.3018 (0.106 sec/step)\n",
            "I1003 01:00:04.735577 139845451286400 learning.py:512] global step 17985: loss = 5.3018 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17986: loss = 4.6128 (0.096 sec/step)\n",
            "I1003 01:00:04.832839 139845451286400 learning.py:512] global step 17986: loss = 4.6128 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17987: loss = 9.8253 (0.099 sec/step)\n",
            "I1003 01:00:04.932956 139845451286400 learning.py:512] global step 17987: loss = 9.8253 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17988: loss = 8.7212 (0.096 sec/step)\n",
            "I1003 01:00:05.030865 139845451286400 learning.py:512] global step 17988: loss = 8.7212 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17989: loss = 4.8516 (0.095 sec/step)\n",
            "I1003 01:00:05.127297 139845451286400 learning.py:512] global step 17989: loss = 4.8516 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 17990: loss = 7.1699 (0.101 sec/step)\n",
            "I1003 01:00:05.229303 139845451286400 learning.py:512] global step 17990: loss = 7.1699 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17991: loss = 4.8968 (0.098 sec/step)\n",
            "I1003 01:00:05.328878 139845451286400 learning.py:512] global step 17991: loss = 4.8968 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17992: loss = 4.9963 (0.101 sec/step)\n",
            "I1003 01:00:05.430845 139845451286400 learning.py:512] global step 17992: loss = 4.9963 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 17993: loss = 8.4119 (0.096 sec/step)\n",
            "I1003 01:00:05.528279 139845451286400 learning.py:512] global step 17993: loss = 8.4119 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 17994: loss = 3.8485 (0.102 sec/step)\n",
            "I1003 01:00:05.631349 139845451286400 learning.py:512] global step 17994: loss = 3.8485 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 17995: loss = 3.6641 (0.106 sec/step)\n",
            "I1003 01:00:05.739221 139845451286400 learning.py:512] global step 17995: loss = 3.6641 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 17996: loss = 4.4611 (0.098 sec/step)\n",
            "I1003 01:00:05.838531 139845451286400 learning.py:512] global step 17996: loss = 4.4611 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 17997: loss = 4.5137 (0.099 sec/step)\n",
            "I1003 01:00:05.938777 139845451286400 learning.py:512] global step 17997: loss = 4.5137 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 17998: loss = 6.8828 (0.118 sec/step)\n",
            "I1003 01:00:06.058871 139845451286400 learning.py:512] global step 17998: loss = 6.8828 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 17999: loss = 5.1519 (0.107 sec/step)\n",
            "I1003 01:00:06.166950 139845451286400 learning.py:512] global step 17999: loss = 5.1519 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18000: loss = 4.0432 (0.096 sec/step)\n",
            "I1003 01:00:06.264569 139845451286400 learning.py:512] global step 18000: loss = 4.0432 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18001: loss = 2.2504 (0.097 sec/step)\n",
            "I1003 01:00:06.362474 139845451286400 learning.py:512] global step 18001: loss = 2.2504 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18002: loss = 3.3963 (0.106 sec/step)\n",
            "I1003 01:00:06.469801 139845451286400 learning.py:512] global step 18002: loss = 3.3963 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18003: loss = 10.3488 (0.090 sec/step)\n",
            "I1003 01:00:06.565040 139845451286400 learning.py:512] global step 18003: loss = 10.3488 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18004: loss = 3.8686 (0.099 sec/step)\n",
            "I1003 01:00:06.668726 139845451286400 learning.py:512] global step 18004: loss = 3.8686 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18005: loss = 4.4821 (0.111 sec/step)\n",
            "I1003 01:00:06.781509 139845451286400 learning.py:512] global step 18005: loss = 4.4821 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18006: loss = 10.7926 (0.096 sec/step)\n",
            "I1003 01:00:06.878567 139845451286400 learning.py:512] global step 18006: loss = 10.7926 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18007: loss = 7.8249 (0.109 sec/step)\n",
            "I1003 01:00:06.988965 139845451286400 learning.py:512] global step 18007: loss = 7.8249 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18008: loss = 3.8327 (0.093 sec/step)\n",
            "I1003 01:00:07.083435 139845451286400 learning.py:512] global step 18008: loss = 3.8327 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18009: loss = 5.1069 (0.095 sec/step)\n",
            "I1003 01:00:07.180057 139845451286400 learning.py:512] global step 18009: loss = 5.1069 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18010: loss = 3.7332 (0.120 sec/step)\n",
            "I1003 01:00:07.301767 139845451286400 learning.py:512] global step 18010: loss = 3.7332 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 18011: loss = 3.6365 (0.113 sec/step)\n",
            "I1003 01:00:07.416601 139845451286400 learning.py:512] global step 18011: loss = 3.6365 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18012: loss = 5.0753 (0.113 sec/step)\n",
            "I1003 01:00:07.530688 139845451286400 learning.py:512] global step 18012: loss = 5.0753 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18013: loss = 4.8973 (0.118 sec/step)\n",
            "I1003 01:00:07.650512 139845451286400 learning.py:512] global step 18013: loss = 4.8973 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18014: loss = 5.1120 (0.126 sec/step)\n",
            "I1003 01:00:07.778368 139845451286400 learning.py:512] global step 18014: loss = 5.1120 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 18015: loss = 7.7691 (0.123 sec/step)\n",
            "I1003 01:00:07.902347 139845451286400 learning.py:512] global step 18015: loss = 7.7691 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 18016: loss = 6.3655 (0.111 sec/step)\n",
            "I1003 01:00:08.014876 139845451286400 learning.py:512] global step 18016: loss = 6.3655 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18017: loss = 6.9576 (0.117 sec/step)\n",
            "I1003 01:00:08.133310 139845451286400 learning.py:512] global step 18017: loss = 6.9576 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 18018: loss = 4.1061 (0.100 sec/step)\n",
            "I1003 01:00:08.235761 139845451286400 learning.py:512] global step 18018: loss = 4.1061 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18019: loss = 3.4196 (0.104 sec/step)\n",
            "I1003 01:00:08.341651 139845451286400 learning.py:512] global step 18019: loss = 3.4196 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18020: loss = 4.9843 (0.098 sec/step)\n",
            "I1003 01:00:08.441473 139845451286400 learning.py:512] global step 18020: loss = 4.9843 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18021: loss = 3.2535 (0.096 sec/step)\n",
            "I1003 01:00:08.539127 139845451286400 learning.py:512] global step 18021: loss = 3.2535 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18022: loss = 3.1564 (0.106 sec/step)\n",
            "I1003 01:00:08.646631 139845451286400 learning.py:512] global step 18022: loss = 3.1564 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18023: loss = 3.2773 (0.092 sec/step)\n",
            "I1003 01:00:08.740195 139845451286400 learning.py:512] global step 18023: loss = 3.2773 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18024: loss = 7.4934 (0.109 sec/step)\n",
            "I1003 01:00:08.850889 139845451286400 learning.py:512] global step 18024: loss = 7.4934 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18025: loss = 2.6885 (0.110 sec/step)\n",
            "I1003 01:00:08.962131 139845451286400 learning.py:512] global step 18025: loss = 2.6885 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18026: loss = 5.3774 (0.097 sec/step)\n",
            "I1003 01:00:09.060004 139845451286400 learning.py:512] global step 18026: loss = 5.3774 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18027: loss = 3.3406 (0.104 sec/step)\n",
            "I1003 01:00:09.165599 139845451286400 learning.py:512] global step 18027: loss = 3.3406 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18028: loss = 3.7040 (0.101 sec/step)\n",
            "I1003 01:00:09.268096 139845451286400 learning.py:512] global step 18028: loss = 3.7040 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18029: loss = 7.9949 (0.104 sec/step)\n",
            "I1003 01:00:09.373098 139845451286400 learning.py:512] global step 18029: loss = 7.9949 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18030: loss = 3.7560 (0.101 sec/step)\n",
            "I1003 01:00:09.476066 139845451286400 learning.py:512] global step 18030: loss = 3.7560 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18031: loss = 3.9746 (0.104 sec/step)\n",
            "I1003 01:00:09.581589 139845451286400 learning.py:512] global step 18031: loss = 3.9746 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18032: loss = 8.2997 (0.112 sec/step)\n",
            "I1003 01:00:09.695211 139845451286400 learning.py:512] global step 18032: loss = 8.2997 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18033: loss = 3.0643 (0.103 sec/step)\n",
            "I1003 01:00:09.799518 139845451286400 learning.py:512] global step 18033: loss = 3.0643 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18034: loss = 3.7753 (0.104 sec/step)\n",
            "I1003 01:00:09.905481 139845451286400 learning.py:512] global step 18034: loss = 3.7753 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18035: loss = 3.3685 (0.095 sec/step)\n",
            "I1003 01:00:10.001794 139845451286400 learning.py:512] global step 18035: loss = 3.3685 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18036: loss = 3.5363 (0.095 sec/step)\n",
            "I1003 01:00:10.098218 139845451286400 learning.py:512] global step 18036: loss = 3.5363 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18037: loss = 3.2497 (0.111 sec/step)\n",
            "I1003 01:00:10.210496 139845451286400 learning.py:512] global step 18037: loss = 3.2497 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18038: loss = 3.8968 (0.100 sec/step)\n",
            "I1003 01:00:10.312272 139845451286400 learning.py:512] global step 18038: loss = 3.8968 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18039: loss = 5.2670 (0.094 sec/step)\n",
            "I1003 01:00:10.407333 139845451286400 learning.py:512] global step 18039: loss = 5.2670 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18040: loss = 7.7517 (0.105 sec/step)\n",
            "I1003 01:00:10.514090 139845451286400 learning.py:512] global step 18040: loss = 7.7517 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18041: loss = 7.1011 (0.110 sec/step)\n",
            "I1003 01:00:10.625388 139845451286400 learning.py:512] global step 18041: loss = 7.1011 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18042: loss = 5.6467 (0.101 sec/step)\n",
            "I1003 01:00:10.727556 139845451286400 learning.py:512] global step 18042: loss = 5.6467 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18043: loss = 3.1861 (0.101 sec/step)\n",
            "I1003 01:00:10.829669 139845451286400 learning.py:512] global step 18043: loss = 3.1861 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18044: loss = 3.9549 (0.099 sec/step)\n",
            "I1003 01:00:10.930032 139845451286400 learning.py:512] global step 18044: loss = 3.9549 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18045: loss = 2.9440 (0.110 sec/step)\n",
            "I1003 01:00:11.041551 139845451286400 learning.py:512] global step 18045: loss = 2.9440 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18046: loss = 4.4343 (0.106 sec/step)\n",
            "I1003 01:00:11.148865 139845451286400 learning.py:512] global step 18046: loss = 4.4343 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18047: loss = 3.8188 (0.099 sec/step)\n",
            "I1003 01:00:11.249589 139845451286400 learning.py:512] global step 18047: loss = 3.8188 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18048: loss = 3.2613 (0.105 sec/step)\n",
            "I1003 01:00:11.356331 139845451286400 learning.py:512] global step 18048: loss = 3.2613 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18049: loss = 2.8283 (0.109 sec/step)\n",
            "I1003 01:00:11.466645 139845451286400 learning.py:512] global step 18049: loss = 2.8283 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18050: loss = 3.8425 (0.101 sec/step)\n",
            "I1003 01:00:11.569077 139845451286400 learning.py:512] global step 18050: loss = 3.8425 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18051: loss = 3.9873 (0.108 sec/step)\n",
            "I1003 01:00:11.678135 139845451286400 learning.py:512] global step 18051: loss = 3.9873 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18052: loss = 3.1157 (0.101 sec/step)\n",
            "I1003 01:00:11.780059 139845451286400 learning.py:512] global step 18052: loss = 3.1157 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18053: loss = 3.3237 (0.099 sec/step)\n",
            "I1003 01:00:11.880529 139845451286400 learning.py:512] global step 18053: loss = 3.3237 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18054: loss = 3.4671 (0.097 sec/step)\n",
            "I1003 01:00:11.978945 139845451286400 learning.py:512] global step 18054: loss = 3.4671 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18055: loss = 3.1435 (0.103 sec/step)\n",
            "I1003 01:00:12.083740 139845451286400 learning.py:512] global step 18055: loss = 3.1435 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18056: loss = 5.8516 (0.098 sec/step)\n",
            "I1003 01:00:12.183164 139845451286400 learning.py:512] global step 18056: loss = 5.8516 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18057: loss = 3.6250 (0.088 sec/step)\n",
            "I1003 01:00:12.272956 139845451286400 learning.py:512] global step 18057: loss = 3.6250 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18058: loss = 3.2306 (0.099 sec/step)\n",
            "I1003 01:00:12.373656 139845451286400 learning.py:512] global step 18058: loss = 3.2306 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18059: loss = 4.0859 (0.112 sec/step)\n",
            "I1003 01:00:12.486706 139845451286400 learning.py:512] global step 18059: loss = 4.0859 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18060: loss = 2.9896 (0.103 sec/step)\n",
            "I1003 01:00:12.590796 139845451286400 learning.py:512] global step 18060: loss = 2.9896 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18061: loss = 5.6407 (0.103 sec/step)\n",
            "I1003 01:00:12.695221 139845451286400 learning.py:512] global step 18061: loss = 5.6407 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18062: loss = 3.4608 (0.096 sec/step)\n",
            "I1003 01:00:12.792439 139845451286400 learning.py:512] global step 18062: loss = 3.4608 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18063: loss = 2.8684 (0.111 sec/step)\n",
            "I1003 01:00:12.905265 139845451286400 learning.py:512] global step 18063: loss = 2.8684 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18064: loss = 3.0729 (0.121 sec/step)\n",
            "I1003 01:00:13.027242 139845451286400 learning.py:512] global step 18064: loss = 3.0729 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 18065: loss = 9.6139 (0.108 sec/step)\n",
            "I1003 01:00:13.136687 139845451286400 learning.py:512] global step 18065: loss = 9.6139 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18066: loss = 4.9177 (0.101 sec/step)\n",
            "I1003 01:00:13.238684 139845451286400 learning.py:512] global step 18066: loss = 4.9177 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18067: loss = 3.7257 (0.114 sec/step)\n",
            "I1003 01:00:13.354259 139845451286400 learning.py:512] global step 18067: loss = 3.7257 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18068: loss = 3.5984 (0.103 sec/step)\n",
            "I1003 01:00:13.459044 139845451286400 learning.py:512] global step 18068: loss = 3.5984 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18069: loss = 3.9383 (0.094 sec/step)\n",
            "I1003 01:00:13.554701 139845451286400 learning.py:512] global step 18069: loss = 3.9383 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18070: loss = 3.3739 (0.093 sec/step)\n",
            "I1003 01:00:13.648941 139845451286400 learning.py:512] global step 18070: loss = 3.3739 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18071: loss = 2.3687 (0.088 sec/step)\n",
            "I1003 01:00:13.738660 139845451286400 learning.py:512] global step 18071: loss = 2.3687 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18072: loss = 3.4769 (0.122 sec/step)\n",
            "I1003 01:00:13.862348 139845451286400 learning.py:512] global step 18072: loss = 3.4769 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 18073: loss = 5.3191 (0.104 sec/step)\n",
            "I1003 01:00:13.968043 139845451286400 learning.py:512] global step 18073: loss = 5.3191 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18074: loss = 8.0435 (0.120 sec/step)\n",
            "I1003 01:00:14.089157 139845451286400 learning.py:512] global step 18074: loss = 8.0435 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 18075: loss = 3.7748 (0.103 sec/step)\n",
            "I1003 01:00:14.193224 139845451286400 learning.py:512] global step 18075: loss = 3.7748 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18076: loss = 3.2413 (0.102 sec/step)\n",
            "I1003 01:00:14.296937 139845451286400 learning.py:512] global step 18076: loss = 3.2413 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18077: loss = 4.1118 (0.096 sec/step)\n",
            "I1003 01:00:14.393784 139845451286400 learning.py:512] global step 18077: loss = 4.1118 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18078: loss = 2.6929 (0.101 sec/step)\n",
            "I1003 01:00:14.496020 139845451286400 learning.py:512] global step 18078: loss = 2.6929 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18079: loss = 11.9132 (0.095 sec/step)\n",
            "I1003 01:00:14.592375 139845451286400 learning.py:512] global step 18079: loss = 11.9132 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18080: loss = 4.7695 (0.104 sec/step)\n",
            "I1003 01:00:14.697706 139845451286400 learning.py:512] global step 18080: loss = 4.7695 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18081: loss = 3.1599 (0.099 sec/step)\n",
            "I1003 01:00:14.797605 139845451286400 learning.py:512] global step 18081: loss = 3.1599 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18082: loss = 9.7728 (0.097 sec/step)\n",
            "I1003 01:00:14.895936 139845451286400 learning.py:512] global step 18082: loss = 9.7728 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18083: loss = 4.1575 (0.109 sec/step)\n",
            "I1003 01:00:15.007979 139845451286400 learning.py:512] global step 18083: loss = 4.1575 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18084: loss = 7.0149 (0.090 sec/step)\n",
            "I1003 01:00:15.100414 139845451286400 learning.py:512] global step 18084: loss = 7.0149 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18085: loss = 14.0204 (0.090 sec/step)\n",
            "I1003 01:00:15.192178 139845451286400 learning.py:512] global step 18085: loss = 14.0204 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18086: loss = 2.9088 (0.111 sec/step)\n",
            "I1003 01:00:15.304611 139845451286400 learning.py:512] global step 18086: loss = 2.9088 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18087: loss = 3.6120 (0.102 sec/step)\n",
            "I1003 01:00:15.408521 139845451286400 learning.py:512] global step 18087: loss = 3.6120 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18088: loss = 3.3305 (0.101 sec/step)\n",
            "I1003 01:00:15.510896 139845451286400 learning.py:512] global step 18088: loss = 3.3305 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18089: loss = 3.8248 (0.103 sec/step)\n",
            "I1003 01:00:15.615068 139845451286400 learning.py:512] global step 18089: loss = 3.8248 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18090: loss = 4.0872 (0.095 sec/step)\n",
            "I1003 01:00:15.711033 139845451286400 learning.py:512] global step 18090: loss = 4.0872 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18091: loss = 5.3306 (0.097 sec/step)\n",
            "I1003 01:00:15.809587 139845451286400 learning.py:512] global step 18091: loss = 5.3306 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18092: loss = 4.6552 (0.100 sec/step)\n",
            "I1003 01:00:15.911252 139845451286400 learning.py:512] global step 18092: loss = 4.6552 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18093: loss = 3.1399 (0.111 sec/step)\n",
            "I1003 01:00:16.023550 139845451286400 learning.py:512] global step 18093: loss = 3.1399 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18094: loss = 2.4855 (0.093 sec/step)\n",
            "I1003 01:00:16.117843 139845451286400 learning.py:512] global step 18094: loss = 2.4855 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18095: loss = 4.8863 (0.104 sec/step)\n",
            "I1003 01:00:16.223704 139845451286400 learning.py:512] global step 18095: loss = 4.8863 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18096: loss = 3.4518 (0.120 sec/step)\n",
            "I1003 01:00:16.344781 139845451286400 learning.py:512] global step 18096: loss = 3.4518 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 18097: loss = 4.8071 (0.115 sec/step)\n",
            "I1003 01:00:16.461016 139845451286400 learning.py:512] global step 18097: loss = 4.8071 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18098: loss = 13.2538 (0.114 sec/step)\n",
            "I1003 01:00:16.576045 139845451286400 learning.py:512] global step 18098: loss = 13.2538 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18099: loss = 2.1003 (0.113 sec/step)\n",
            "I1003 01:00:16.690438 139845451286400 learning.py:512] global step 18099: loss = 2.1003 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18100: loss = 3.4271 (0.141 sec/step)\n",
            "I1003 01:00:16.833056 139845451286400 learning.py:512] global step 18100: loss = 3.4271 (0.141 sec/step)\n",
            "INFO:tensorflow:global step 18101: loss = 5.5407 (0.119 sec/step)\n",
            "I1003 01:00:16.953589 139845451286400 learning.py:512] global step 18101: loss = 5.5407 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18102: loss = 5.8059 (0.123 sec/step)\n",
            "I1003 01:00:17.078585 139845451286400 learning.py:512] global step 18102: loss = 5.8059 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 18103: loss = 3.7880 (0.122 sec/step)\n",
            "I1003 01:00:17.202194 139845451286400 learning.py:512] global step 18103: loss = 3.7880 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 18104: loss = 3.0917 (0.126 sec/step)\n",
            "I1003 01:00:17.329401 139845451286400 learning.py:512] global step 18104: loss = 3.0917 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 18105: loss = 4.2345 (0.116 sec/step)\n",
            "I1003 01:00:17.448080 139845451286400 learning.py:512] global step 18105: loss = 4.2345 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18106: loss = 2.0692 (0.119 sec/step)\n",
            "I1003 01:00:17.568935 139845451286400 learning.py:512] global step 18106: loss = 2.0692 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18107: loss = 3.6745 (0.121 sec/step)\n",
            "I1003 01:00:17.691113 139845451286400 learning.py:512] global step 18107: loss = 3.6745 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 18108: loss = 3.8274 (0.117 sec/step)\n",
            "I1003 01:00:17.809093 139845451286400 learning.py:512] global step 18108: loss = 3.8274 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 18109: loss = 3.4044 (0.105 sec/step)\n",
            "I1003 01:00:17.916040 139845451286400 learning.py:512] global step 18109: loss = 3.4044 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18110: loss = 5.1048 (0.105 sec/step)\n",
            "I1003 01:00:18.022724 139845451286400 learning.py:512] global step 18110: loss = 5.1048 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18111: loss = 4.8350 (0.097 sec/step)\n",
            "I1003 01:00:18.121387 139845451286400 learning.py:512] global step 18111: loss = 4.8350 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18112: loss = 2.8939 (0.098 sec/step)\n",
            "I1003 01:00:18.221070 139845451286400 learning.py:512] global step 18112: loss = 2.8939 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18113: loss = 9.2538 (0.105 sec/step)\n",
            "I1003 01:00:18.327156 139845451286400 learning.py:512] global step 18113: loss = 9.2538 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18114: loss = 7.1291 (0.094 sec/step)\n",
            "I1003 01:00:18.422244 139845451286400 learning.py:512] global step 18114: loss = 7.1291 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18115: loss = 6.8526 (0.098 sec/step)\n",
            "I1003 01:00:18.521675 139845451286400 learning.py:512] global step 18115: loss = 6.8526 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18116: loss = 4.2141 (0.096 sec/step)\n",
            "I1003 01:00:18.619067 139845451286400 learning.py:512] global step 18116: loss = 4.2141 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18117: loss = 3.9045 (0.091 sec/step)\n",
            "I1003 01:00:18.711385 139845451286400 learning.py:512] global step 18117: loss = 3.9045 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18118: loss = 3.1281 (0.090 sec/step)\n",
            "I1003 01:00:18.803140 139845451286400 learning.py:512] global step 18118: loss = 3.1281 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18119: loss = 1.7016 (0.099 sec/step)\n",
            "I1003 01:00:18.903719 139845451286400 learning.py:512] global step 18119: loss = 1.7016 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18120: loss = 3.1158 (0.117 sec/step)\n",
            "I1003 01:00:19.022093 139845451286400 learning.py:512] global step 18120: loss = 3.1158 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 18121: loss = 4.2648 (0.112 sec/step)\n",
            "I1003 01:00:19.135149 139845451286400 learning.py:512] global step 18121: loss = 4.2648 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18122: loss = 3.5372 (0.102 sec/step)\n",
            "I1003 01:00:19.239030 139845451286400 learning.py:512] global step 18122: loss = 3.5372 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18123: loss = 5.9940 (0.092 sec/step)\n",
            "I1003 01:00:19.332753 139845451286400 learning.py:512] global step 18123: loss = 5.9940 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18124: loss = 3.8194 (0.089 sec/step)\n",
            "I1003 01:00:19.423244 139845451286400 learning.py:512] global step 18124: loss = 3.8194 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18125: loss = 2.7399 (0.115 sec/step)\n",
            "I1003 01:00:19.540044 139845451286400 learning.py:512] global step 18125: loss = 2.7399 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18126: loss = 5.1315 (0.096 sec/step)\n",
            "I1003 01:00:19.637355 139845451286400 learning.py:512] global step 18126: loss = 5.1315 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18127: loss = 5.9327 (0.098 sec/step)\n",
            "I1003 01:00:19.736428 139845451286400 learning.py:512] global step 18127: loss = 5.9327 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18128: loss = 2.2753 (0.094 sec/step)\n",
            "I1003 01:00:19.831502 139845451286400 learning.py:512] global step 18128: loss = 2.2753 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18129: loss = 2.1705 (0.197 sec/step)\n",
            "I1003 01:00:20.029999 139845451286400 learning.py:512] global step 18129: loss = 2.1705 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 18130: loss = 5.5464 (0.143 sec/step)\n",
            "I1003 01:00:20.176128 139845451286400 learning.py:512] global step 18130: loss = 5.5464 (0.143 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 18130.\n",
            "I1003 01:00:20.184555 139841898313472 supervisor.py:1050] Recording summary at step 18130.\n",
            "INFO:tensorflow:global step 18131: loss = 1.7149 (0.123 sec/step)\n",
            "I1003 01:00:20.305077 139845451286400 learning.py:512] global step 18131: loss = 1.7149 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 18132: loss = 5.6703 (0.121 sec/step)\n",
            "I1003 01:00:20.427929 139845451286400 learning.py:512] global step 18132: loss = 5.6703 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 18133: loss = 6.9762 (0.134 sec/step)\n",
            "I1003 01:00:20.563610 139845451286400 learning.py:512] global step 18133: loss = 6.9762 (0.134 sec/step)\n",
            "INFO:tensorflow:global step 18134: loss = 4.8617 (0.114 sec/step)\n",
            "I1003 01:00:20.678822 139845451286400 learning.py:512] global step 18134: loss = 4.8617 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18135: loss = 2.4999 (0.104 sec/step)\n",
            "I1003 01:00:20.784338 139845451286400 learning.py:512] global step 18135: loss = 2.4999 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18136: loss = 4.8165 (0.095 sec/step)\n",
            "I1003 01:00:20.881473 139845451286400 learning.py:512] global step 18136: loss = 4.8165 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18137: loss = 10.7973 (0.102 sec/step)\n",
            "I1003 01:00:20.984628 139845451286400 learning.py:512] global step 18137: loss = 10.7973 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18138: loss = 3.8640 (0.107 sec/step)\n",
            "I1003 01:00:21.093841 139845451286400 learning.py:512] global step 18138: loss = 3.8640 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18139: loss = 4.4016 (0.099 sec/step)\n",
            "I1003 01:00:21.195705 139845451286400 learning.py:512] global step 18139: loss = 4.4016 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18140: loss = 2.1616 (0.107 sec/step)\n",
            "I1003 01:00:21.303599 139845451286400 learning.py:512] global step 18140: loss = 2.1616 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18141: loss = 5.1631 (0.098 sec/step)\n",
            "I1003 01:00:21.404213 139845451286400 learning.py:512] global step 18141: loss = 5.1631 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18142: loss = 3.7604 (0.099 sec/step)\n",
            "I1003 01:00:21.504538 139845451286400 learning.py:512] global step 18142: loss = 3.7604 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18143: loss = 6.2315 (0.102 sec/step)\n",
            "I1003 01:00:21.608271 139845451286400 learning.py:512] global step 18143: loss = 6.2315 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18144: loss = 6.8971 (0.102 sec/step)\n",
            "I1003 01:00:21.711399 139845451286400 learning.py:512] global step 18144: loss = 6.8971 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18145: loss = 3.1481 (0.102 sec/step)\n",
            "I1003 01:00:21.814610 139845451286400 learning.py:512] global step 18145: loss = 3.1481 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18146: loss = 4.3827 (0.104 sec/step)\n",
            "I1003 01:00:21.920700 139845451286400 learning.py:512] global step 18146: loss = 4.3827 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18147: loss = 4.8098 (0.100 sec/step)\n",
            "I1003 01:00:22.022035 139845451286400 learning.py:512] global step 18147: loss = 4.8098 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18148: loss = 3.4257 (0.117 sec/step)\n",
            "I1003 01:00:22.140617 139845451286400 learning.py:512] global step 18148: loss = 3.4257 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 18149: loss = 3.3227 (0.101 sec/step)\n",
            "I1003 01:00:22.243255 139845451286400 learning.py:512] global step 18149: loss = 3.3227 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18150: loss = 8.7290 (0.096 sec/step)\n",
            "I1003 01:00:22.340952 139845451286400 learning.py:512] global step 18150: loss = 8.7290 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18151: loss = 4.8242 (0.108 sec/step)\n",
            "I1003 01:00:22.450440 139845451286400 learning.py:512] global step 18151: loss = 4.8242 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18152: loss = 3.5119 (0.097 sec/step)\n",
            "I1003 01:00:22.549053 139845451286400 learning.py:512] global step 18152: loss = 3.5119 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18153: loss = 5.4717 (0.099 sec/step)\n",
            "I1003 01:00:22.649712 139845451286400 learning.py:512] global step 18153: loss = 5.4717 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18154: loss = 6.0264 (0.089 sec/step)\n",
            "I1003 01:00:22.740247 139845451286400 learning.py:512] global step 18154: loss = 6.0264 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18155: loss = 7.0929 (0.098 sec/step)\n",
            "I1003 01:00:22.840036 139845451286400 learning.py:512] global step 18155: loss = 7.0929 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18156: loss = 4.5630 (0.097 sec/step)\n",
            "I1003 01:00:22.938791 139845451286400 learning.py:512] global step 18156: loss = 4.5630 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18157: loss = 4.5259 (0.113 sec/step)\n",
            "I1003 01:00:23.052994 139845451286400 learning.py:512] global step 18157: loss = 4.5259 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18158: loss = 6.9727 (0.126 sec/step)\n",
            "I1003 01:00:23.180217 139845451286400 learning.py:512] global step 18158: loss = 6.9727 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 18159: loss = 3.9479 (0.119 sec/step)\n",
            "I1003 01:00:23.300741 139845451286400 learning.py:512] global step 18159: loss = 3.9479 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18160: loss = 5.4605 (0.109 sec/step)\n",
            "I1003 01:00:23.411651 139845451286400 learning.py:512] global step 18160: loss = 5.4605 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18161: loss = 8.2197 (0.109 sec/step)\n",
            "I1003 01:00:23.522099 139845451286400 learning.py:512] global step 18161: loss = 8.2197 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18162: loss = 4.3086 (0.107 sec/step)\n",
            "I1003 01:00:23.631146 139845451286400 learning.py:512] global step 18162: loss = 4.3086 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18163: loss = 5.0496 (0.115 sec/step)\n",
            "I1003 01:00:23.748563 139845451286400 learning.py:512] global step 18163: loss = 5.0496 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18164: loss = 3.2494 (0.088 sec/step)\n",
            "I1003 01:00:23.837912 139845451286400 learning.py:512] global step 18164: loss = 3.2494 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18165: loss = 3.5305 (0.089 sec/step)\n",
            "I1003 01:00:23.928473 139845451286400 learning.py:512] global step 18165: loss = 3.5305 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18166: loss = 3.1923 (0.094 sec/step)\n",
            "I1003 01:00:24.023701 139845451286400 learning.py:512] global step 18166: loss = 3.1923 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18167: loss = 6.1407 (0.099 sec/step)\n",
            "I1003 01:00:24.123835 139845451286400 learning.py:512] global step 18167: loss = 6.1407 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18168: loss = 3.5251 (0.099 sec/step)\n",
            "I1003 01:00:24.224386 139845451286400 learning.py:512] global step 18168: loss = 3.5251 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18169: loss = 6.8635 (0.107 sec/step)\n",
            "I1003 01:00:24.332436 139845451286400 learning.py:512] global step 18169: loss = 6.8635 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18170: loss = 6.0332 (0.091 sec/step)\n",
            "I1003 01:00:24.424642 139845451286400 learning.py:512] global step 18170: loss = 6.0332 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18171: loss = 7.8637 (0.089 sec/step)\n",
            "I1003 01:00:24.514799 139845451286400 learning.py:512] global step 18171: loss = 7.8637 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18172: loss = 2.4666 (0.099 sec/step)\n",
            "I1003 01:00:24.614791 139845451286400 learning.py:512] global step 18172: loss = 2.4666 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18173: loss = 3.6371 (0.094 sec/step)\n",
            "I1003 01:00:24.709764 139845451286400 learning.py:512] global step 18173: loss = 3.6371 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18174: loss = 3.1027 (0.095 sec/step)\n",
            "I1003 01:00:24.805943 139845451286400 learning.py:512] global step 18174: loss = 3.1027 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18175: loss = 2.1241 (0.114 sec/step)\n",
            "I1003 01:00:24.920914 139845451286400 learning.py:512] global step 18175: loss = 2.1241 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18176: loss = 5.3286 (0.090 sec/step)\n",
            "I1003 01:00:25.012866 139845451286400 learning.py:512] global step 18176: loss = 5.3286 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18177: loss = 11.6925 (0.108 sec/step)\n",
            "I1003 01:00:25.122671 139845451286400 learning.py:512] global step 18177: loss = 11.6925 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18178: loss = 3.6062 (0.111 sec/step)\n",
            "I1003 01:00:25.235598 139845451286400 learning.py:512] global step 18178: loss = 3.6062 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18179: loss = 4.1254 (0.107 sec/step)\n",
            "I1003 01:00:25.344070 139845451286400 learning.py:512] global step 18179: loss = 4.1254 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18180: loss = 5.0019 (0.097 sec/step)\n",
            "I1003 01:00:25.442611 139845451286400 learning.py:512] global step 18180: loss = 5.0019 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18181: loss = 6.8216 (0.105 sec/step)\n",
            "I1003 01:00:25.548692 139845451286400 learning.py:512] global step 18181: loss = 6.8216 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18182: loss = 7.2647 (0.091 sec/step)\n",
            "I1003 01:00:25.641239 139845451286400 learning.py:512] global step 18182: loss = 7.2647 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18183: loss = 5.0320 (0.096 sec/step)\n",
            "I1003 01:00:25.738584 139845451286400 learning.py:512] global step 18183: loss = 5.0320 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18184: loss = 4.2771 (0.090 sec/step)\n",
            "I1003 01:00:25.830291 139845451286400 learning.py:512] global step 18184: loss = 4.2771 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18185: loss = 3.8627 (0.113 sec/step)\n",
            "I1003 01:00:25.945160 139845451286400 learning.py:512] global step 18185: loss = 3.8627 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18186: loss = 4.1772 (0.097 sec/step)\n",
            "I1003 01:00:26.043466 139845451286400 learning.py:512] global step 18186: loss = 4.1772 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18187: loss = 4.3587 (0.089 sec/step)\n",
            "I1003 01:00:26.133738 139845451286400 learning.py:512] global step 18187: loss = 4.3587 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18188: loss = 4.7200 (0.112 sec/step)\n",
            "I1003 01:00:26.246953 139845451286400 learning.py:512] global step 18188: loss = 4.7200 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18189: loss = 7.9741 (0.107 sec/step)\n",
            "I1003 01:00:26.356110 139845451286400 learning.py:512] global step 18189: loss = 7.9741 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18190: loss = 5.4253 (0.116 sec/step)\n",
            "I1003 01:00:26.473800 139845451286400 learning.py:512] global step 18190: loss = 5.4253 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18191: loss = 4.8056 (0.120 sec/step)\n",
            "I1003 01:00:26.595752 139845451286400 learning.py:512] global step 18191: loss = 4.8056 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 18192: loss = 5.1634 (0.119 sec/step)\n",
            "I1003 01:00:26.716439 139845451286400 learning.py:512] global step 18192: loss = 5.1634 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18193: loss = 5.0264 (0.092 sec/step)\n",
            "I1003 01:00:26.809990 139845451286400 learning.py:512] global step 18193: loss = 5.0264 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18194: loss = 2.9511 (0.111 sec/step)\n",
            "I1003 01:00:26.921924 139845451286400 learning.py:512] global step 18194: loss = 2.9511 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18195: loss = 2.8757 (0.107 sec/step)\n",
            "I1003 01:00:27.030464 139845451286400 learning.py:512] global step 18195: loss = 2.8757 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18196: loss = 3.6945 (0.101 sec/step)\n",
            "I1003 01:00:27.132518 139845451286400 learning.py:512] global step 18196: loss = 3.6945 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18197: loss = 2.6904 (0.103 sec/step)\n",
            "I1003 01:00:27.237013 139845451286400 learning.py:512] global step 18197: loss = 2.6904 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18198: loss = 7.2189 (0.100 sec/step)\n",
            "I1003 01:00:27.338732 139845451286400 learning.py:512] global step 18198: loss = 7.2189 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18199: loss = 3.3976 (0.105 sec/step)\n",
            "I1003 01:00:27.445543 139845451286400 learning.py:512] global step 18199: loss = 3.3976 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18200: loss = 3.3671 (0.110 sec/step)\n",
            "I1003 01:00:27.556828 139845451286400 learning.py:512] global step 18200: loss = 3.3671 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18201: loss = 3.5016 (0.108 sec/step)\n",
            "I1003 01:00:27.666460 139845451286400 learning.py:512] global step 18201: loss = 3.5016 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18202: loss = 4.0311 (0.106 sec/step)\n",
            "I1003 01:00:27.773540 139845451286400 learning.py:512] global step 18202: loss = 4.0311 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18203: loss = 3.3869 (0.116 sec/step)\n",
            "I1003 01:00:27.890490 139845451286400 learning.py:512] global step 18203: loss = 3.3869 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18204: loss = 5.4605 (0.099 sec/step)\n",
            "I1003 01:00:27.991001 139845451286400 learning.py:512] global step 18204: loss = 5.4605 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18205: loss = 4.8659 (0.093 sec/step)\n",
            "I1003 01:00:28.084939 139845451286400 learning.py:512] global step 18205: loss = 4.8659 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18206: loss = 3.7158 (0.110 sec/step)\n",
            "I1003 01:00:28.196192 139845451286400 learning.py:512] global step 18206: loss = 3.7158 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18207: loss = 2.4296 (0.101 sec/step)\n",
            "I1003 01:00:28.298180 139845451286400 learning.py:512] global step 18207: loss = 2.4296 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18208: loss = 9.0338 (0.103 sec/step)\n",
            "I1003 01:00:28.402620 139845451286400 learning.py:512] global step 18208: loss = 9.0338 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18209: loss = 6.3764 (0.094 sec/step)\n",
            "I1003 01:00:28.497652 139845451286400 learning.py:512] global step 18209: loss = 6.3764 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18210: loss = 2.7554 (0.092 sec/step)\n",
            "I1003 01:00:28.592555 139845451286400 learning.py:512] global step 18210: loss = 2.7554 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18211: loss = 2.8032 (0.099 sec/step)\n",
            "I1003 01:00:28.692905 139845451286400 learning.py:512] global step 18211: loss = 2.8032 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18212: loss = 3.6719 (0.106 sec/step)\n",
            "I1003 01:00:28.799893 139845451286400 learning.py:512] global step 18212: loss = 3.6719 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18213: loss = 5.0267 (0.104 sec/step)\n",
            "I1003 01:00:28.905199 139845451286400 learning.py:512] global step 18213: loss = 5.0267 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18214: loss = 7.4831 (0.094 sec/step)\n",
            "I1003 01:00:29.000193 139845451286400 learning.py:512] global step 18214: loss = 7.4831 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18215: loss = 4.2866 (0.103 sec/step)\n",
            "I1003 01:00:29.104309 139845451286400 learning.py:512] global step 18215: loss = 4.2866 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18216: loss = 2.9859 (0.105 sec/step)\n",
            "I1003 01:00:29.212011 139845451286400 learning.py:512] global step 18216: loss = 2.9859 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18217: loss = 8.7250 (0.093 sec/step)\n",
            "I1003 01:00:29.307144 139845451286400 learning.py:512] global step 18217: loss = 8.7250 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18218: loss = 4.0366 (0.093 sec/step)\n",
            "I1003 01:00:29.401902 139845451286400 learning.py:512] global step 18218: loss = 4.0366 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18219: loss = 6.3277 (0.111 sec/step)\n",
            "I1003 01:00:29.514615 139845451286400 learning.py:512] global step 18219: loss = 6.3277 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18220: loss = 3.0911 (0.100 sec/step)\n",
            "I1003 01:00:29.615830 139845451286400 learning.py:512] global step 18220: loss = 3.0911 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18221: loss = 5.6102 (0.096 sec/step)\n",
            "I1003 01:00:29.712978 139845451286400 learning.py:512] global step 18221: loss = 5.6102 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18222: loss = 3.6862 (0.108 sec/step)\n",
            "I1003 01:00:29.822851 139845451286400 learning.py:512] global step 18222: loss = 3.6862 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18223: loss = 4.6026 (0.097 sec/step)\n",
            "I1003 01:00:29.921121 139845451286400 learning.py:512] global step 18223: loss = 4.6026 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18224: loss = 4.7202 (0.099 sec/step)\n",
            "I1003 01:00:30.021902 139845451286400 learning.py:512] global step 18224: loss = 4.7202 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18225: loss = 3.2069 (0.091 sec/step)\n",
            "I1003 01:00:30.114513 139845451286400 learning.py:512] global step 18225: loss = 3.2069 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18226: loss = 2.0914 (0.093 sec/step)\n",
            "I1003 01:00:30.209189 139845451286400 learning.py:512] global step 18226: loss = 2.0914 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18227: loss = 5.7976 (0.109 sec/step)\n",
            "I1003 01:00:30.319673 139845451286400 learning.py:512] global step 18227: loss = 5.7976 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18228: loss = 3.2176 (0.100 sec/step)\n",
            "I1003 01:00:30.421263 139845451286400 learning.py:512] global step 18228: loss = 3.2176 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18229: loss = 6.7564 (0.102 sec/step)\n",
            "I1003 01:00:30.524876 139845451286400 learning.py:512] global step 18229: loss = 6.7564 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18230: loss = 7.9964 (0.100 sec/step)\n",
            "I1003 01:00:30.626125 139845451286400 learning.py:512] global step 18230: loss = 7.9964 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18231: loss = 4.4683 (0.092 sec/step)\n",
            "I1003 01:00:30.719282 139845451286400 learning.py:512] global step 18231: loss = 4.4683 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18232: loss = 4.9485 (0.102 sec/step)\n",
            "I1003 01:00:30.823053 139845451286400 learning.py:512] global step 18232: loss = 4.9485 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18233: loss = 3.6366 (0.107 sec/step)\n",
            "I1003 01:00:30.932893 139845451286400 learning.py:512] global step 18233: loss = 3.6366 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18234: loss = 6.1734 (0.114 sec/step)\n",
            "I1003 01:00:31.048665 139845451286400 learning.py:512] global step 18234: loss = 6.1734 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18235: loss = 5.0440 (0.103 sec/step)\n",
            "I1003 01:00:31.153297 139845451286400 learning.py:512] global step 18235: loss = 5.0440 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18236: loss = 2.4542 (0.123 sec/step)\n",
            "I1003 01:00:31.277506 139845451286400 learning.py:512] global step 18236: loss = 2.4542 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 18237: loss = 5.9533 (0.118 sec/step)\n",
            "I1003 01:00:31.396765 139845451286400 learning.py:512] global step 18237: loss = 5.9533 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18238: loss = 3.3284 (0.131 sec/step)\n",
            "I1003 01:00:31.529035 139845451286400 learning.py:512] global step 18238: loss = 3.3284 (0.131 sec/step)\n",
            "INFO:tensorflow:global step 18239: loss = 3.3965 (0.116 sec/step)\n",
            "I1003 01:00:31.646910 139845451286400 learning.py:512] global step 18239: loss = 3.3965 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18240: loss = 9.9284 (0.110 sec/step)\n",
            "I1003 01:00:31.758219 139845451286400 learning.py:512] global step 18240: loss = 9.9284 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18241: loss = 7.0389 (0.098 sec/step)\n",
            "I1003 01:00:31.857173 139845451286400 learning.py:512] global step 18241: loss = 7.0389 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18242: loss = 2.5854 (0.105 sec/step)\n",
            "I1003 01:00:31.963003 139845451286400 learning.py:512] global step 18242: loss = 2.5854 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18243: loss = 5.3084 (0.118 sec/step)\n",
            "I1003 01:00:32.082662 139845451286400 learning.py:512] global step 18243: loss = 5.3084 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18244: loss = 2.6312 (0.112 sec/step)\n",
            "I1003 01:00:32.196369 139845451286400 learning.py:512] global step 18244: loss = 2.6312 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18245: loss = 5.8351 (0.133 sec/step)\n",
            "I1003 01:00:32.330530 139845451286400 learning.py:512] global step 18245: loss = 5.8351 (0.133 sec/step)\n",
            "INFO:tensorflow:global step 18246: loss = 3.4601 (0.104 sec/step)\n",
            "I1003 01:00:32.435589 139845451286400 learning.py:512] global step 18246: loss = 3.4601 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18247: loss = 5.5797 (0.119 sec/step)\n",
            "I1003 01:00:32.556233 139845451286400 learning.py:512] global step 18247: loss = 5.5797 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18248: loss = 5.1520 (0.119 sec/step)\n",
            "I1003 01:00:32.677179 139845451286400 learning.py:512] global step 18248: loss = 5.1520 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18249: loss = 7.2878 (0.103 sec/step)\n",
            "I1003 01:00:32.781742 139845451286400 learning.py:512] global step 18249: loss = 7.2878 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18250: loss = 4.8877 (0.101 sec/step)\n",
            "I1003 01:00:32.884021 139845451286400 learning.py:512] global step 18250: loss = 4.8877 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18251: loss = 4.0223 (0.102 sec/step)\n",
            "I1003 01:00:32.987382 139845451286400 learning.py:512] global step 18251: loss = 4.0223 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18252: loss = 3.0429 (0.108 sec/step)\n",
            "I1003 01:00:33.096860 139845451286400 learning.py:512] global step 18252: loss = 3.0429 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18253: loss = 3.6435 (0.114 sec/step)\n",
            "I1003 01:00:33.212084 139845451286400 learning.py:512] global step 18253: loss = 3.6435 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18254: loss = 3.9388 (0.128 sec/step)\n",
            "I1003 01:00:33.341378 139845451286400 learning.py:512] global step 18254: loss = 3.9388 (0.128 sec/step)\n",
            "INFO:tensorflow:global step 18255: loss = 3.9472 (0.112 sec/step)\n",
            "I1003 01:00:33.455252 139845451286400 learning.py:512] global step 18255: loss = 3.9472 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18256: loss = 4.1478 (0.112 sec/step)\n",
            "I1003 01:00:33.569234 139845451286400 learning.py:512] global step 18256: loss = 4.1478 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18257: loss = 2.6762 (0.116 sec/step)\n",
            "I1003 01:00:33.687131 139845451286400 learning.py:512] global step 18257: loss = 2.6762 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18258: loss = 8.3214 (0.104 sec/step)\n",
            "I1003 01:00:33.792977 139845451286400 learning.py:512] global step 18258: loss = 8.3214 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18259: loss = 3.6330 (0.103 sec/step)\n",
            "I1003 01:00:33.897130 139845451286400 learning.py:512] global step 18259: loss = 3.6330 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18260: loss = 2.5636 (0.110 sec/step)\n",
            "I1003 01:00:34.008423 139845451286400 learning.py:512] global step 18260: loss = 2.5636 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18261: loss = 5.8921 (0.117 sec/step)\n",
            "I1003 01:00:34.126559 139845451286400 learning.py:512] global step 18261: loss = 5.8921 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 18262: loss = 6.9156 (0.102 sec/step)\n",
            "I1003 01:00:34.230047 139845451286400 learning.py:512] global step 18262: loss = 6.9156 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18263: loss = 6.0004 (0.133 sec/step)\n",
            "I1003 01:00:34.365001 139845451286400 learning.py:512] global step 18263: loss = 6.0004 (0.133 sec/step)\n",
            "INFO:tensorflow:global step 18264: loss = 3.9654 (0.117 sec/step)\n",
            "I1003 01:00:34.483099 139845451286400 learning.py:512] global step 18264: loss = 3.9654 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 18265: loss = 3.6044 (0.114 sec/step)\n",
            "I1003 01:00:34.598689 139845451286400 learning.py:512] global step 18265: loss = 3.6044 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18266: loss = 4.9708 (0.107 sec/step)\n",
            "I1003 01:00:34.706992 139845451286400 learning.py:512] global step 18266: loss = 4.9708 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18267: loss = 5.1439 (0.108 sec/step)\n",
            "I1003 01:00:34.816696 139845451286400 learning.py:512] global step 18267: loss = 5.1439 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18268: loss = 3.5720 (0.109 sec/step)\n",
            "I1003 01:00:34.926945 139845451286400 learning.py:512] global step 18268: loss = 3.5720 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18269: loss = 3.0339 (0.113 sec/step)\n",
            "I1003 01:00:35.041048 139845451286400 learning.py:512] global step 18269: loss = 3.0339 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18270: loss = 2.9997 (0.099 sec/step)\n",
            "I1003 01:00:35.141172 139845451286400 learning.py:512] global step 18270: loss = 2.9997 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18271: loss = 3.9928 (0.099 sec/step)\n",
            "I1003 01:00:35.241399 139845451286400 learning.py:512] global step 18271: loss = 3.9928 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18272: loss = 2.4087 (0.099 sec/step)\n",
            "I1003 01:00:35.342102 139845451286400 learning.py:512] global step 18272: loss = 2.4087 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18273: loss = 3.5493 (0.101 sec/step)\n",
            "I1003 01:00:35.444530 139845451286400 learning.py:512] global step 18273: loss = 3.5493 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18274: loss = 2.2075 (0.108 sec/step)\n",
            "I1003 01:00:35.553681 139845451286400 learning.py:512] global step 18274: loss = 2.2075 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18275: loss = 2.7798 (0.110 sec/step)\n",
            "I1003 01:00:35.664802 139845451286400 learning.py:512] global step 18275: loss = 2.7798 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18276: loss = 5.5045 (0.101 sec/step)\n",
            "I1003 01:00:35.767200 139845451286400 learning.py:512] global step 18276: loss = 5.5045 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18277: loss = 4.9349 (0.099 sec/step)\n",
            "I1003 01:00:35.867867 139845451286400 learning.py:512] global step 18277: loss = 4.9349 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18278: loss = 5.1527 (0.098 sec/step)\n",
            "I1003 01:00:35.967499 139845451286400 learning.py:512] global step 18278: loss = 5.1527 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18279: loss = 3.8290 (0.106 sec/step)\n",
            "I1003 01:00:36.075307 139845451286400 learning.py:512] global step 18279: loss = 3.8290 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18280: loss = 1.8677 (0.106 sec/step)\n",
            "I1003 01:00:36.182449 139845451286400 learning.py:512] global step 18280: loss = 1.8677 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18281: loss = 4.7112 (0.093 sec/step)\n",
            "I1003 01:00:36.276465 139845451286400 learning.py:512] global step 18281: loss = 4.7112 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18282: loss = 5.2016 (0.099 sec/step)\n",
            "I1003 01:00:36.376575 139845451286400 learning.py:512] global step 18282: loss = 5.2016 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18283: loss = 2.6008 (0.095 sec/step)\n",
            "I1003 01:00:36.473238 139845451286400 learning.py:512] global step 18283: loss = 2.6008 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18284: loss = 4.4936 (0.091 sec/step)\n",
            "I1003 01:00:36.565862 139845451286400 learning.py:512] global step 18284: loss = 4.4936 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18285: loss = 3.8135 (0.098 sec/step)\n",
            "I1003 01:00:36.665272 139845451286400 learning.py:512] global step 18285: loss = 3.8135 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18286: loss = 4.7765 (0.088 sec/step)\n",
            "I1003 01:00:36.754315 139845451286400 learning.py:512] global step 18286: loss = 4.7765 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18287: loss = 3.5085 (0.103 sec/step)\n",
            "I1003 01:00:36.858111 139845451286400 learning.py:512] global step 18287: loss = 3.5085 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18288: loss = 6.0661 (0.095 sec/step)\n",
            "I1003 01:00:36.954421 139845451286400 learning.py:512] global step 18288: loss = 6.0661 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18289: loss = 4.9246 (0.105 sec/step)\n",
            "I1003 01:00:37.060651 139845451286400 learning.py:512] global step 18289: loss = 4.9246 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18290: loss = 3.8514 (0.112 sec/step)\n",
            "I1003 01:00:37.174254 139845451286400 learning.py:512] global step 18290: loss = 3.8514 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18291: loss = 4.7319 (0.114 sec/step)\n",
            "I1003 01:00:37.289864 139845451286400 learning.py:512] global step 18291: loss = 4.7319 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18292: loss = 4.6023 (0.121 sec/step)\n",
            "I1003 01:00:37.412588 139845451286400 learning.py:512] global step 18292: loss = 4.6023 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 18293: loss = 2.5777 (0.115 sec/step)\n",
            "I1003 01:00:37.528709 139845451286400 learning.py:512] global step 18293: loss = 2.5777 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18294: loss = 3.4611 (0.126 sec/step)\n",
            "I1003 01:00:37.655915 139845451286400 learning.py:512] global step 18294: loss = 3.4611 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 18295: loss = 2.5983 (0.113 sec/step)\n",
            "I1003 01:00:37.770763 139845451286400 learning.py:512] global step 18295: loss = 2.5983 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18296: loss = 5.2492 (0.112 sec/step)\n",
            "I1003 01:00:37.884271 139845451286400 learning.py:512] global step 18296: loss = 5.2492 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18297: loss = 3.8581 (0.089 sec/step)\n",
            "I1003 01:00:37.974990 139845451286400 learning.py:512] global step 18297: loss = 3.8581 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18298: loss = 5.0643 (0.098 sec/step)\n",
            "I1003 01:00:38.074690 139845451286400 learning.py:512] global step 18298: loss = 5.0643 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18299: loss = 4.1247 (0.106 sec/step)\n",
            "I1003 01:00:38.181695 139845451286400 learning.py:512] global step 18299: loss = 4.1247 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18300: loss = 4.1288 (0.093 sec/step)\n",
            "I1003 01:00:38.279319 139845451286400 learning.py:512] global step 18300: loss = 4.1288 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18301: loss = 3.6311 (0.092 sec/step)\n",
            "I1003 01:00:38.372448 139845451286400 learning.py:512] global step 18301: loss = 3.6311 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18302: loss = 4.4127 (0.113 sec/step)\n",
            "I1003 01:00:38.486784 139845451286400 learning.py:512] global step 18302: loss = 4.4127 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18303: loss = 3.1305 (0.099 sec/step)\n",
            "I1003 01:00:38.586995 139845451286400 learning.py:512] global step 18303: loss = 3.1305 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18304: loss = 3.0209 (0.107 sec/step)\n",
            "I1003 01:00:38.695528 139845451286400 learning.py:512] global step 18304: loss = 3.0209 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18305: loss = 2.9420 (0.110 sec/step)\n",
            "I1003 01:00:38.806706 139845451286400 learning.py:512] global step 18305: loss = 2.9420 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18306: loss = 2.7919 (0.102 sec/step)\n",
            "I1003 01:00:38.910728 139845451286400 learning.py:512] global step 18306: loss = 2.7919 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18307: loss = 4.1284 (0.098 sec/step)\n",
            "I1003 01:00:39.010312 139845451286400 learning.py:512] global step 18307: loss = 4.1284 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18308: loss = 2.6592 (0.103 sec/step)\n",
            "I1003 01:00:39.115083 139845451286400 learning.py:512] global step 18308: loss = 2.6592 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18309: loss = 5.8137 (0.104 sec/step)\n",
            "I1003 01:00:39.220104 139845451286400 learning.py:512] global step 18309: loss = 5.8137 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18310: loss = 6.2614 (0.100 sec/step)\n",
            "I1003 01:00:39.321790 139845451286400 learning.py:512] global step 18310: loss = 6.2614 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18311: loss = 4.9044 (0.095 sec/step)\n",
            "I1003 01:00:39.419916 139845451286400 learning.py:512] global step 18311: loss = 4.9044 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18312: loss = 3.3494 (0.101 sec/step)\n",
            "I1003 01:00:39.521892 139845451286400 learning.py:512] global step 18312: loss = 3.3494 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18313: loss = 2.4325 (0.094 sec/step)\n",
            "I1003 01:00:39.617163 139845451286400 learning.py:512] global step 18313: loss = 2.4325 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18314: loss = 3.4844 (0.090 sec/step)\n",
            "I1003 01:00:39.708291 139845451286400 learning.py:512] global step 18314: loss = 3.4844 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18315: loss = 1.9154 (0.108 sec/step)\n",
            "I1003 01:00:39.817787 139845451286400 learning.py:512] global step 18315: loss = 1.9154 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18316: loss = 4.0418 (0.105 sec/step)\n",
            "I1003 01:00:39.924196 139845451286400 learning.py:512] global step 18316: loss = 4.0418 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18317: loss = 4.0924 (0.099 sec/step)\n",
            "I1003 01:00:40.024159 139845451286400 learning.py:512] global step 18317: loss = 4.0924 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18318: loss = 2.3656 (0.108 sec/step)\n",
            "I1003 01:00:40.133592 139845451286400 learning.py:512] global step 18318: loss = 2.3656 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18319: loss = 4.7955 (0.090 sec/step)\n",
            "I1003 01:00:40.224667 139845451286400 learning.py:512] global step 18319: loss = 4.7955 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18320: loss = 3.7498 (0.088 sec/step)\n",
            "I1003 01:00:40.313691 139845451286400 learning.py:512] global step 18320: loss = 3.7498 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18321: loss = 5.2731 (0.101 sec/step)\n",
            "I1003 01:00:40.416592 139845451286400 learning.py:512] global step 18321: loss = 5.2731 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18322: loss = 3.1375 (0.103 sec/step)\n",
            "I1003 01:00:40.520946 139845451286400 learning.py:512] global step 18322: loss = 3.1375 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18323: loss = 5.5285 (0.098 sec/step)\n",
            "I1003 01:00:40.620546 139845451286400 learning.py:512] global step 18323: loss = 5.5285 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18324: loss = 4.2809 (0.111 sec/step)\n",
            "I1003 01:00:40.733332 139845451286400 learning.py:512] global step 18324: loss = 4.2809 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18325: loss = 2.3904 (0.092 sec/step)\n",
            "I1003 01:00:40.828311 139845451286400 learning.py:512] global step 18325: loss = 2.3904 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18326: loss = 2.6009 (0.098 sec/step)\n",
            "I1003 01:00:40.930556 139845451286400 learning.py:512] global step 18326: loss = 2.6009 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18327: loss = 4.3378 (0.103 sec/step)\n",
            "I1003 01:00:41.035378 139845451286400 learning.py:512] global step 18327: loss = 4.3378 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18328: loss = 6.7851 (0.114 sec/step)\n",
            "I1003 01:00:41.150533 139845451286400 learning.py:512] global step 18328: loss = 6.7851 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18329: loss = 3.1223 (0.093 sec/step)\n",
            "I1003 01:00:41.245297 139845451286400 learning.py:512] global step 18329: loss = 3.1223 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18330: loss = 2.8389 (0.097 sec/step)\n",
            "I1003 01:00:41.344047 139845451286400 learning.py:512] global step 18330: loss = 2.8389 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18331: loss = 6.1810 (0.105 sec/step)\n",
            "I1003 01:00:41.450620 139845451286400 learning.py:512] global step 18331: loss = 6.1810 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18332: loss = 2.5099 (0.111 sec/step)\n",
            "I1003 01:00:41.563152 139845451286400 learning.py:512] global step 18332: loss = 2.5099 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18333: loss = 3.7452 (0.099 sec/step)\n",
            "I1003 01:00:41.663350 139845451286400 learning.py:512] global step 18333: loss = 3.7452 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18334: loss = 3.8510 (0.107 sec/step)\n",
            "I1003 01:00:41.771241 139845451286400 learning.py:512] global step 18334: loss = 3.8510 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18335: loss = 3.8630 (0.095 sec/step)\n",
            "I1003 01:00:41.867669 139845451286400 learning.py:512] global step 18335: loss = 3.8630 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18336: loss = 2.8322 (0.099 sec/step)\n",
            "I1003 01:00:41.967734 139845451286400 learning.py:512] global step 18336: loss = 2.8322 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18337: loss = 4.3389 (0.093 sec/step)\n",
            "I1003 01:00:42.062433 139845451286400 learning.py:512] global step 18337: loss = 4.3389 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18338: loss = 5.3951 (0.100 sec/step)\n",
            "I1003 01:00:42.164242 139845451286400 learning.py:512] global step 18338: loss = 5.3951 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18339: loss = 5.5877 (0.097 sec/step)\n",
            "I1003 01:00:42.262341 139845451286400 learning.py:512] global step 18339: loss = 5.5877 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18340: loss = 2.8652 (0.096 sec/step)\n",
            "I1003 01:00:42.360208 139845451286400 learning.py:512] global step 18340: loss = 2.8652 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18341: loss = 2.1988 (0.099 sec/step)\n",
            "I1003 01:00:42.460865 139845451286400 learning.py:512] global step 18341: loss = 2.1988 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18342: loss = 2.6851 (0.109 sec/step)\n",
            "I1003 01:00:42.570735 139845451286400 learning.py:512] global step 18342: loss = 2.6851 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18343: loss = 3.4880 (0.096 sec/step)\n",
            "I1003 01:00:42.668214 139845451286400 learning.py:512] global step 18343: loss = 3.4880 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18344: loss = 10.5575 (0.098 sec/step)\n",
            "I1003 01:00:42.767405 139845451286400 learning.py:512] global step 18344: loss = 10.5575 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18345: loss = 3.0686 (0.106 sec/step)\n",
            "I1003 01:00:42.874329 139845451286400 learning.py:512] global step 18345: loss = 3.0686 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18346: loss = 3.8172 (0.101 sec/step)\n",
            "I1003 01:00:42.976586 139845451286400 learning.py:512] global step 18346: loss = 3.8172 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18347: loss = 3.0324 (0.105 sec/step)\n",
            "I1003 01:00:43.082754 139845451286400 learning.py:512] global step 18347: loss = 3.0324 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18348: loss = 5.3373 (0.107 sec/step)\n",
            "I1003 01:00:43.190884 139845451286400 learning.py:512] global step 18348: loss = 5.3373 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18349: loss = 5.9703 (0.092 sec/step)\n",
            "I1003 01:00:43.283753 139845451286400 learning.py:512] global step 18349: loss = 5.9703 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18350: loss = 2.5781 (0.107 sec/step)\n",
            "I1003 01:00:43.391604 139845451286400 learning.py:512] global step 18350: loss = 2.5781 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18351: loss = 3.3021 (0.096 sec/step)\n",
            "I1003 01:00:43.489284 139845451286400 learning.py:512] global step 18351: loss = 3.3021 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18352: loss = 3.6021 (0.108 sec/step)\n",
            "I1003 01:00:43.598556 139845451286400 learning.py:512] global step 18352: loss = 3.6021 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18353: loss = 3.5093 (0.105 sec/step)\n",
            "I1003 01:00:43.705153 139845451286400 learning.py:512] global step 18353: loss = 3.5093 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18354: loss = 3.3308 (0.105 sec/step)\n",
            "I1003 01:00:43.811036 139845451286400 learning.py:512] global step 18354: loss = 3.3308 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18355: loss = 2.2765 (0.095 sec/step)\n",
            "I1003 01:00:43.907770 139845451286400 learning.py:512] global step 18355: loss = 2.2765 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18356: loss = 5.4677 (0.106 sec/step)\n",
            "I1003 01:00:44.014822 139845451286400 learning.py:512] global step 18356: loss = 5.4677 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18357: loss = 4.0094 (0.095 sec/step)\n",
            "I1003 01:00:44.111502 139845451286400 learning.py:512] global step 18357: loss = 4.0094 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18358: loss = 4.7676 (0.110 sec/step)\n",
            "I1003 01:00:44.222830 139845451286400 learning.py:512] global step 18358: loss = 4.7676 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18359: loss = 2.6309 (0.105 sec/step)\n",
            "I1003 01:00:44.329576 139845451286400 learning.py:512] global step 18359: loss = 2.6309 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18360: loss = 4.6205 (0.096 sec/step)\n",
            "I1003 01:00:44.427321 139845451286400 learning.py:512] global step 18360: loss = 4.6205 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18361: loss = 2.5871 (0.100 sec/step)\n",
            "I1003 01:00:44.529872 139845451286400 learning.py:512] global step 18361: loss = 2.5871 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18362: loss = 4.8880 (0.108 sec/step)\n",
            "I1003 01:00:44.640366 139845451286400 learning.py:512] global step 18362: loss = 4.8880 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18363: loss = 3.5785 (0.095 sec/step)\n",
            "I1003 01:00:44.736535 139845451286400 learning.py:512] global step 18363: loss = 3.5785 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18364: loss = 3.2479 (0.103 sec/step)\n",
            "I1003 01:00:44.841248 139845451286400 learning.py:512] global step 18364: loss = 3.2479 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18365: loss = 4.2133 (0.106 sec/step)\n",
            "I1003 01:00:44.949018 139845451286400 learning.py:512] global step 18365: loss = 4.2133 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18366: loss = 2.4389 (0.111 sec/step)\n",
            "I1003 01:00:45.061250 139845451286400 learning.py:512] global step 18366: loss = 2.4389 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18367: loss = 2.4471 (0.114 sec/step)\n",
            "I1003 01:00:45.177175 139845451286400 learning.py:512] global step 18367: loss = 2.4471 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18368: loss = 4.8981 (0.106 sec/step)\n",
            "I1003 01:00:45.284381 139845451286400 learning.py:512] global step 18368: loss = 4.8981 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18369: loss = 3.9731 (0.114 sec/step)\n",
            "I1003 01:00:45.399717 139845451286400 learning.py:512] global step 18369: loss = 3.9731 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18370: loss = 2.7503 (0.095 sec/step)\n",
            "I1003 01:00:45.496064 139845451286400 learning.py:512] global step 18370: loss = 2.7503 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18371: loss = 4.5749 (0.113 sec/step)\n",
            "I1003 01:00:45.610141 139845451286400 learning.py:512] global step 18371: loss = 4.5749 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18372: loss = 3.6714 (0.093 sec/step)\n",
            "I1003 01:00:45.704228 139845451286400 learning.py:512] global step 18372: loss = 3.6714 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18373: loss = 2.2402 (0.098 sec/step)\n",
            "I1003 01:00:45.803719 139845451286400 learning.py:512] global step 18373: loss = 2.2402 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18374: loss = 4.1273 (0.098 sec/step)\n",
            "I1003 01:00:45.903052 139845451286400 learning.py:512] global step 18374: loss = 4.1273 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18375: loss = 5.9824 (0.112 sec/step)\n",
            "I1003 01:00:46.016183 139845451286400 learning.py:512] global step 18375: loss = 5.9824 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18376: loss = 3.9180 (0.090 sec/step)\n",
            "I1003 01:00:46.107689 139845451286400 learning.py:512] global step 18376: loss = 3.9180 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18377: loss = 10.2985 (0.103 sec/step)\n",
            "I1003 01:00:46.212063 139845451286400 learning.py:512] global step 18377: loss = 10.2985 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18378: loss = 5.7237 (0.098 sec/step)\n",
            "I1003 01:00:46.311331 139845451286400 learning.py:512] global step 18378: loss = 5.7237 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18379: loss = 2.7936 (0.097 sec/step)\n",
            "I1003 01:00:46.409399 139845451286400 learning.py:512] global step 18379: loss = 2.7936 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18380: loss = 3.1817 (0.095 sec/step)\n",
            "I1003 01:00:46.505520 139845451286400 learning.py:512] global step 18380: loss = 3.1817 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18381: loss = 2.9177 (0.108 sec/step)\n",
            "I1003 01:00:46.614979 139845451286400 learning.py:512] global step 18381: loss = 2.9177 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18382: loss = 4.7499 (0.096 sec/step)\n",
            "I1003 01:00:46.711940 139845451286400 learning.py:512] global step 18382: loss = 4.7499 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18383: loss = 3.2779 (0.099 sec/step)\n",
            "I1003 01:00:46.812266 139845451286400 learning.py:512] global step 18383: loss = 3.2779 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18384: loss = 4.6108 (0.106 sec/step)\n",
            "I1003 01:00:46.919350 139845451286400 learning.py:512] global step 18384: loss = 4.6108 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18385: loss = 4.3279 (0.103 sec/step)\n",
            "I1003 01:00:47.023770 139845451286400 learning.py:512] global step 18385: loss = 4.3279 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18386: loss = 3.6452 (0.093 sec/step)\n",
            "I1003 01:00:47.118539 139845451286400 learning.py:512] global step 18386: loss = 3.6452 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18387: loss = 3.6936 (0.103 sec/step)\n",
            "I1003 01:00:47.223428 139845451286400 learning.py:512] global step 18387: loss = 3.6936 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18388: loss = 6.9454 (0.098 sec/step)\n",
            "I1003 01:00:47.323285 139845451286400 learning.py:512] global step 18388: loss = 6.9454 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18389: loss = 2.2878 (0.105 sec/step)\n",
            "I1003 01:00:47.429553 139845451286400 learning.py:512] global step 18389: loss = 2.2878 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18390: loss = 3.9873 (0.092 sec/step)\n",
            "I1003 01:00:47.522626 139845451286400 learning.py:512] global step 18390: loss = 3.9873 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18391: loss = 1.8543 (0.111 sec/step)\n",
            "I1003 01:00:47.634597 139845451286400 learning.py:512] global step 18391: loss = 1.8543 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18392: loss = 4.2121 (0.088 sec/step)\n",
            "I1003 01:00:47.724160 139845451286400 learning.py:512] global step 18392: loss = 4.2121 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18393: loss = 2.4104 (0.095 sec/step)\n",
            "I1003 01:00:47.820652 139845451286400 learning.py:512] global step 18393: loss = 2.4104 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18394: loss = 2.3600 (0.097 sec/step)\n",
            "I1003 01:00:47.918771 139845451286400 learning.py:512] global step 18394: loss = 2.3600 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18395: loss = 3.7628 (0.103 sec/step)\n",
            "I1003 01:00:48.023175 139845451286400 learning.py:512] global step 18395: loss = 3.7628 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18396: loss = 7.2802 (0.094 sec/step)\n",
            "I1003 01:00:48.118304 139845451286400 learning.py:512] global step 18396: loss = 7.2802 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18397: loss = 5.2327 (0.106 sec/step)\n",
            "I1003 01:00:48.225175 139845451286400 learning.py:512] global step 18397: loss = 5.2327 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18398: loss = 4.1918 (0.103 sec/step)\n",
            "I1003 01:00:48.329797 139845451286400 learning.py:512] global step 18398: loss = 4.1918 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18399: loss = 5.9288 (0.105 sec/step)\n",
            "I1003 01:00:48.436587 139845451286400 learning.py:512] global step 18399: loss = 5.9288 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18400: loss = 3.0183 (0.106 sec/step)\n",
            "I1003 01:00:48.544644 139845451286400 learning.py:512] global step 18400: loss = 3.0183 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18401: loss = 7.5418 (0.110 sec/step)\n",
            "I1003 01:00:48.655505 139845451286400 learning.py:512] global step 18401: loss = 7.5418 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18402: loss = 4.1384 (0.094 sec/step)\n",
            "I1003 01:00:48.751198 139845451286400 learning.py:512] global step 18402: loss = 4.1384 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18403: loss = 3.8148 (0.110 sec/step)\n",
            "I1003 01:00:48.862152 139845451286400 learning.py:512] global step 18403: loss = 3.8148 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18404: loss = 6.2768 (0.102 sec/step)\n",
            "I1003 01:00:48.965546 139845451286400 learning.py:512] global step 18404: loss = 6.2768 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18405: loss = 5.7436 (0.100 sec/step)\n",
            "I1003 01:00:49.067414 139845451286400 learning.py:512] global step 18405: loss = 5.7436 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18406: loss = 2.3165 (0.094 sec/step)\n",
            "I1003 01:00:49.163278 139845451286400 learning.py:512] global step 18406: loss = 2.3165 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18407: loss = 5.5425 (0.097 sec/step)\n",
            "I1003 01:00:49.261353 139845451286400 learning.py:512] global step 18407: loss = 5.5425 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18408: loss = 2.6994 (0.100 sec/step)\n",
            "I1003 01:00:49.363036 139845451286400 learning.py:512] global step 18408: loss = 2.6994 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18409: loss = 3.0389 (0.093 sec/step)\n",
            "I1003 01:00:49.457912 139845451286400 learning.py:512] global step 18409: loss = 3.0389 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18410: loss = 5.7043 (0.104 sec/step)\n",
            "I1003 01:00:49.563396 139845451286400 learning.py:512] global step 18410: loss = 5.7043 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18411: loss = 8.9879 (0.105 sec/step)\n",
            "I1003 01:00:49.669844 139845451286400 learning.py:512] global step 18411: loss = 8.9879 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18412: loss = 3.5826 (0.095 sec/step)\n",
            "I1003 01:00:49.765981 139845451286400 learning.py:512] global step 18412: loss = 3.5826 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18413: loss = 2.4817 (0.095 sec/step)\n",
            "I1003 01:00:49.862869 139845451286400 learning.py:512] global step 18413: loss = 2.4817 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18414: loss = 2.4156 (0.106 sec/step)\n",
            "I1003 01:00:49.970580 139845451286400 learning.py:512] global step 18414: loss = 2.4156 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18415: loss = 8.7482 (0.106 sec/step)\n",
            "I1003 01:00:50.077474 139845451286400 learning.py:512] global step 18415: loss = 8.7482 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18416: loss = 2.8744 (0.102 sec/step)\n",
            "I1003 01:00:50.180615 139845451286400 learning.py:512] global step 18416: loss = 2.8744 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18417: loss = 2.0385 (0.113 sec/step)\n",
            "I1003 01:00:50.295148 139845451286400 learning.py:512] global step 18417: loss = 2.0385 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18418: loss = 2.7154 (0.107 sec/step)\n",
            "I1003 01:00:50.403027 139845451286400 learning.py:512] global step 18418: loss = 2.7154 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18419: loss = 3.6225 (0.099 sec/step)\n",
            "I1003 01:00:50.503708 139845451286400 learning.py:512] global step 18419: loss = 3.6225 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18420: loss = 8.3167 (0.099 sec/step)\n",
            "I1003 01:00:50.604203 139845451286400 learning.py:512] global step 18420: loss = 8.3167 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18421: loss = 3.4572 (0.098 sec/step)\n",
            "I1003 01:00:50.703608 139845451286400 learning.py:512] global step 18421: loss = 3.4572 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18422: loss = 3.2277 (0.099 sec/step)\n",
            "I1003 01:00:50.804136 139845451286400 learning.py:512] global step 18422: loss = 3.2277 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18423: loss = 4.8425 (0.101 sec/step)\n",
            "I1003 01:00:50.906857 139845451286400 learning.py:512] global step 18423: loss = 4.8425 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18424: loss = 2.2570 (0.108 sec/step)\n",
            "I1003 01:00:51.016612 139845451286400 learning.py:512] global step 18424: loss = 2.2570 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18425: loss = 3.1354 (0.120 sec/step)\n",
            "I1003 01:00:51.138641 139845451286400 learning.py:512] global step 18425: loss = 3.1354 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 18426: loss = 2.7930 (0.124 sec/step)\n",
            "I1003 01:00:51.264241 139845451286400 learning.py:512] global step 18426: loss = 2.7930 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 18427: loss = 3.7934 (0.116 sec/step)\n",
            "I1003 01:00:51.381417 139845451286400 learning.py:512] global step 18427: loss = 3.7934 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18428: loss = 3.2912 (0.118 sec/step)\n",
            "I1003 01:00:51.500716 139845451286400 learning.py:512] global step 18428: loss = 3.2912 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18429: loss = 2.5968 (0.121 sec/step)\n",
            "I1003 01:00:51.622852 139845451286400 learning.py:512] global step 18429: loss = 2.5968 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 18430: loss = 2.5887 (0.114 sec/step)\n",
            "I1003 01:00:51.737959 139845451286400 learning.py:512] global step 18430: loss = 2.5887 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18431: loss = 3.0747 (0.096 sec/step)\n",
            "I1003 01:00:51.835518 139845451286400 learning.py:512] global step 18431: loss = 3.0747 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18432: loss = 2.5120 (0.093 sec/step)\n",
            "I1003 01:00:51.929571 139845451286400 learning.py:512] global step 18432: loss = 2.5120 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18433: loss = 3.6494 (0.101 sec/step)\n",
            "I1003 01:00:52.031795 139845451286400 learning.py:512] global step 18433: loss = 3.6494 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18434: loss = 6.1699 (0.104 sec/step)\n",
            "I1003 01:00:52.136802 139845451286400 learning.py:512] global step 18434: loss = 6.1699 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18435: loss = 2.8402 (0.112 sec/step)\n",
            "I1003 01:00:52.250032 139845451286400 learning.py:512] global step 18435: loss = 2.8402 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18436: loss = 4.5845 (0.109 sec/step)\n",
            "I1003 01:00:52.360372 139845451286400 learning.py:512] global step 18436: loss = 4.5845 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18437: loss = 3.8169 (0.106 sec/step)\n",
            "I1003 01:00:52.467453 139845451286400 learning.py:512] global step 18437: loss = 3.8169 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18438: loss = 2.2670 (0.104 sec/step)\n",
            "I1003 01:00:52.572858 139845451286400 learning.py:512] global step 18438: loss = 2.2670 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18439: loss = 2.7284 (0.126 sec/step)\n",
            "I1003 01:00:52.700527 139845451286400 learning.py:512] global step 18439: loss = 2.7284 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 18440: loss = 4.1460 (0.098 sec/step)\n",
            "I1003 01:00:52.800432 139845451286400 learning.py:512] global step 18440: loss = 4.1460 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18441: loss = 2.0738 (0.104 sec/step)\n",
            "I1003 01:00:52.906122 139845451286400 learning.py:512] global step 18441: loss = 2.0738 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18442: loss = 2.5188 (0.098 sec/step)\n",
            "I1003 01:00:53.005154 139845451286400 learning.py:512] global step 18442: loss = 2.5188 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18443: loss = 6.0905 (0.097 sec/step)\n",
            "I1003 01:00:53.103647 139845451286400 learning.py:512] global step 18443: loss = 6.0905 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18444: loss = 4.2648 (0.107 sec/step)\n",
            "I1003 01:00:53.212403 139845451286400 learning.py:512] global step 18444: loss = 4.2648 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18445: loss = 3.4015 (0.110 sec/step)\n",
            "I1003 01:00:53.323649 139845451286400 learning.py:512] global step 18445: loss = 3.4015 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18446: loss = 2.0418 (0.114 sec/step)\n",
            "I1003 01:00:53.438926 139845451286400 learning.py:512] global step 18446: loss = 2.0418 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18447: loss = 2.6562 (0.093 sec/step)\n",
            "I1003 01:00:53.533341 139845451286400 learning.py:512] global step 18447: loss = 2.6562 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18448: loss = 7.4367 (0.104 sec/step)\n",
            "I1003 01:00:53.638535 139845451286400 learning.py:512] global step 18448: loss = 7.4367 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18449: loss = 8.1215 (0.114 sec/step)\n",
            "I1003 01:00:53.754356 139845451286400 learning.py:512] global step 18449: loss = 8.1215 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18450: loss = 3.6055 (0.109 sec/step)\n",
            "I1003 01:00:53.864917 139845451286400 learning.py:512] global step 18450: loss = 3.6055 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18451: loss = 2.3989 (0.095 sec/step)\n",
            "I1003 01:00:53.961512 139845451286400 learning.py:512] global step 18451: loss = 2.3989 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18452: loss = 3.8310 (0.095 sec/step)\n",
            "I1003 01:00:54.057686 139845451286400 learning.py:512] global step 18452: loss = 3.8310 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18453: loss = 5.4156 (0.103 sec/step)\n",
            "I1003 01:00:54.162175 139845451286400 learning.py:512] global step 18453: loss = 5.4156 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18454: loss = 1.7928 (0.109 sec/step)\n",
            "I1003 01:00:54.273209 139845451286400 learning.py:512] global step 18454: loss = 1.7928 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18455: loss = 6.4810 (0.108 sec/step)\n",
            "I1003 01:00:54.382887 139845451286400 learning.py:512] global step 18455: loss = 6.4810 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18456: loss = 3.0642 (0.098 sec/step)\n",
            "I1003 01:00:54.482617 139845451286400 learning.py:512] global step 18456: loss = 3.0642 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18457: loss = 3.0525 (0.098 sec/step)\n",
            "I1003 01:00:54.581829 139845451286400 learning.py:512] global step 18457: loss = 3.0525 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18458: loss = 5.6290 (0.094 sec/step)\n",
            "I1003 01:00:54.676918 139845451286400 learning.py:512] global step 18458: loss = 5.6290 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18459: loss = 3.1730 (0.103 sec/step)\n",
            "I1003 01:00:54.781165 139845451286400 learning.py:512] global step 18459: loss = 3.1730 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18460: loss = 7.9492 (0.107 sec/step)\n",
            "I1003 01:00:54.889743 139845451286400 learning.py:512] global step 18460: loss = 7.9492 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18461: loss = 2.8072 (0.097 sec/step)\n",
            "I1003 01:00:54.988673 139845451286400 learning.py:512] global step 18461: loss = 2.8072 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18462: loss = 3.2733 (0.129 sec/step)\n",
            "I1003 01:00:55.119310 139845451286400 learning.py:512] global step 18462: loss = 3.2733 (0.129 sec/step)\n",
            "INFO:tensorflow:global step 18463: loss = 5.5381 (0.104 sec/step)\n",
            "I1003 01:00:55.224540 139845451286400 learning.py:512] global step 18463: loss = 5.5381 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18464: loss = 3.8825 (0.107 sec/step)\n",
            "I1003 01:00:55.333125 139845451286400 learning.py:512] global step 18464: loss = 3.8825 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18465: loss = 3.5141 (0.103 sec/step)\n",
            "I1003 01:00:55.437136 139845451286400 learning.py:512] global step 18465: loss = 3.5141 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18466: loss = 3.3397 (0.098 sec/step)\n",
            "I1003 01:00:55.536404 139845451286400 learning.py:512] global step 18466: loss = 3.3397 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18467: loss = 4.3613 (0.104 sec/step)\n",
            "I1003 01:00:55.642297 139845451286400 learning.py:512] global step 18467: loss = 4.3613 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18468: loss = 2.6398 (0.102 sec/step)\n",
            "I1003 01:00:55.745861 139845451286400 learning.py:512] global step 18468: loss = 2.6398 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18469: loss = 4.5594 (0.104 sec/step)\n",
            "I1003 01:00:55.851397 139845451286400 learning.py:512] global step 18469: loss = 4.5594 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18470: loss = 4.5005 (0.097 sec/step)\n",
            "I1003 01:00:55.950201 139845451286400 learning.py:512] global step 18470: loss = 4.5005 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18471: loss = 3.5115 (0.100 sec/step)\n",
            "I1003 01:00:56.051848 139845451286400 learning.py:512] global step 18471: loss = 3.5115 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18472: loss = 3.1030 (0.096 sec/step)\n",
            "I1003 01:00:56.149607 139845451286400 learning.py:512] global step 18472: loss = 3.1030 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18473: loss = 6.5174 (0.124 sec/step)\n",
            "I1003 01:00:56.274753 139845451286400 learning.py:512] global step 18473: loss = 6.5174 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 18474: loss = 5.4923 (0.124 sec/step)\n",
            "I1003 01:00:56.400264 139845451286400 learning.py:512] global step 18474: loss = 5.4923 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 18475: loss = 2.9733 (0.111 sec/step)\n",
            "I1003 01:00:56.513087 139845451286400 learning.py:512] global step 18475: loss = 2.9733 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18476: loss = 7.3178 (0.114 sec/step)\n",
            "I1003 01:00:56.628423 139845451286400 learning.py:512] global step 18476: loss = 7.3178 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18477: loss = 3.5321 (0.110 sec/step)\n",
            "I1003 01:00:56.740007 139845451286400 learning.py:512] global step 18477: loss = 3.5321 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18478: loss = 3.7821 (0.126 sec/step)\n",
            "I1003 01:00:56.867500 139845451286400 learning.py:512] global step 18478: loss = 3.7821 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 18479: loss = 2.7940 (0.112 sec/step)\n",
            "I1003 01:00:56.980934 139845451286400 learning.py:512] global step 18479: loss = 2.7940 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18480: loss = 6.8964 (0.111 sec/step)\n",
            "I1003 01:00:57.093900 139845451286400 learning.py:512] global step 18480: loss = 6.8964 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18481: loss = 6.8752 (0.105 sec/step)\n",
            "I1003 01:00:57.200537 139845451286400 learning.py:512] global step 18481: loss = 6.8752 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18482: loss = 3.9077 (0.124 sec/step)\n",
            "I1003 01:00:57.326591 139845451286400 learning.py:512] global step 18482: loss = 3.9077 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 18483: loss = 4.3029 (0.118 sec/step)\n",
            "I1003 01:00:57.446296 139845451286400 learning.py:512] global step 18483: loss = 4.3029 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18484: loss = 6.0434 (0.115 sec/step)\n",
            "I1003 01:00:57.562315 139845451286400 learning.py:512] global step 18484: loss = 6.0434 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18485: loss = 5.1342 (0.127 sec/step)\n",
            "I1003 01:00:57.691078 139845451286400 learning.py:512] global step 18485: loss = 5.1342 (0.127 sec/step)\n",
            "INFO:tensorflow:global step 18486: loss = 2.9436 (0.115 sec/step)\n",
            "I1003 01:00:57.809933 139845451286400 learning.py:512] global step 18486: loss = 2.9436 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18487: loss = 5.1437 (0.111 sec/step)\n",
            "I1003 01:00:57.923823 139845451286400 learning.py:512] global step 18487: loss = 5.1437 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18488: loss = 2.8191 (0.105 sec/step)\n",
            "I1003 01:00:58.030470 139845451286400 learning.py:512] global step 18488: loss = 2.8191 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18489: loss = 3.6364 (0.105 sec/step)\n",
            "I1003 01:00:58.137089 139845451286400 learning.py:512] global step 18489: loss = 3.6364 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18490: loss = 3.7629 (0.100 sec/step)\n",
            "I1003 01:00:58.238730 139845451286400 learning.py:512] global step 18490: loss = 3.7629 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18491: loss = 2.8862 (0.096 sec/step)\n",
            "I1003 01:00:58.336123 139845451286400 learning.py:512] global step 18491: loss = 2.8862 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18492: loss = 3.6306 (0.110 sec/step)\n",
            "I1003 01:00:58.447545 139845451286400 learning.py:512] global step 18492: loss = 3.6306 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18493: loss = 4.7318 (0.094 sec/step)\n",
            "I1003 01:00:58.542745 139845451286400 learning.py:512] global step 18493: loss = 4.7318 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18494: loss = 7.4744 (0.087 sec/step)\n",
            "I1003 01:00:58.631598 139845451286400 learning.py:512] global step 18494: loss = 7.4744 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 18495: loss = 6.7565 (0.103 sec/step)\n",
            "I1003 01:00:58.735519 139845451286400 learning.py:512] global step 18495: loss = 6.7565 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18496: loss = 9.5272 (0.103 sec/step)\n",
            "I1003 01:00:58.839520 139845451286400 learning.py:512] global step 18496: loss = 9.5272 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18497: loss = 6.5025 (0.096 sec/step)\n",
            "I1003 01:00:58.936644 139845451286400 learning.py:512] global step 18497: loss = 6.5025 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18498: loss = 7.6491 (0.115 sec/step)\n",
            "I1003 01:00:59.052855 139845451286400 learning.py:512] global step 18498: loss = 7.6491 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18499: loss = 3.8374 (0.107 sec/step)\n",
            "I1003 01:00:59.161784 139845451286400 learning.py:512] global step 18499: loss = 3.8374 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18500: loss = 3.4122 (0.107 sec/step)\n",
            "I1003 01:00:59.270238 139845451286400 learning.py:512] global step 18500: loss = 3.4122 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18501: loss = 3.8302 (0.122 sec/step)\n",
            "I1003 01:00:59.394064 139845451286400 learning.py:512] global step 18501: loss = 3.8302 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 18502: loss = 6.2928 (0.106 sec/step)\n",
            "I1003 01:00:59.501426 139845451286400 learning.py:512] global step 18502: loss = 6.2928 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18503: loss = 5.9096 (0.122 sec/step)\n",
            "I1003 01:00:59.625427 139845451286400 learning.py:512] global step 18503: loss = 5.9096 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 18504: loss = 2.6681 (0.122 sec/step)\n",
            "I1003 01:00:59.748909 139845451286400 learning.py:512] global step 18504: loss = 2.6681 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 18505: loss = 2.4482 (0.104 sec/step)\n",
            "I1003 01:00:59.854056 139845451286400 learning.py:512] global step 18505: loss = 2.4482 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18506: loss = 8.8240 (0.092 sec/step)\n",
            "I1003 01:00:59.946982 139845451286400 learning.py:512] global step 18506: loss = 8.8240 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18507: loss = 5.1244 (0.109 sec/step)\n",
            "I1003 01:01:00.057257 139845451286400 learning.py:512] global step 18507: loss = 5.1244 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18508: loss = 5.4994 (0.112 sec/step)\n",
            "I1003 01:01:00.170642 139845451286400 learning.py:512] global step 18508: loss = 5.4994 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18509: loss = 4.1152 (0.101 sec/step)\n",
            "I1003 01:01:00.273292 139845451286400 learning.py:512] global step 18509: loss = 4.1152 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18510: loss = 4.1733 (0.101 sec/step)\n",
            "I1003 01:01:00.375684 139845451286400 learning.py:512] global step 18510: loss = 4.1733 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18511: loss = 6.9329 (0.100 sec/step)\n",
            "I1003 01:01:00.476999 139845451286400 learning.py:512] global step 18511: loss = 6.9329 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18512: loss = 3.8624 (0.093 sec/step)\n",
            "I1003 01:01:00.570859 139845451286400 learning.py:512] global step 18512: loss = 3.8624 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18513: loss = 2.0065 (0.102 sec/step)\n",
            "I1003 01:01:00.674469 139845451286400 learning.py:512] global step 18513: loss = 2.0065 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18514: loss = 4.7680 (0.113 sec/step)\n",
            "I1003 01:01:00.789078 139845451286400 learning.py:512] global step 18514: loss = 4.7680 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18515: loss = 2.6816 (0.110 sec/step)\n",
            "I1003 01:01:00.900906 139845451286400 learning.py:512] global step 18515: loss = 2.6816 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18516: loss = 12.1166 (0.103 sec/step)\n",
            "I1003 01:01:01.005913 139845451286400 learning.py:512] global step 18516: loss = 12.1166 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18517: loss = 5.1030 (0.105 sec/step)\n",
            "I1003 01:01:01.112624 139845451286400 learning.py:512] global step 18517: loss = 5.1030 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18518: loss = 9.0091 (0.105 sec/step)\n",
            "I1003 01:01:01.218969 139845451286400 learning.py:512] global step 18518: loss = 9.0091 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18519: loss = 5.8124 (0.096 sec/step)\n",
            "I1003 01:01:01.316889 139845451286400 learning.py:512] global step 18519: loss = 5.8124 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18520: loss = 4.2502 (0.092 sec/step)\n",
            "I1003 01:01:01.411403 139845451286400 learning.py:512] global step 18520: loss = 4.2502 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18521: loss = 3.5882 (0.108 sec/step)\n",
            "I1003 01:01:01.520725 139845451286400 learning.py:512] global step 18521: loss = 3.5882 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18522: loss = 6.1057 (0.100 sec/step)\n",
            "I1003 01:01:01.622100 139845451286400 learning.py:512] global step 18522: loss = 6.1057 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18523: loss = 2.2771 (0.115 sec/step)\n",
            "I1003 01:01:01.739060 139845451286400 learning.py:512] global step 18523: loss = 2.2771 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18524: loss = 2.8119 (0.105 sec/step)\n",
            "I1003 01:01:01.845573 139845451286400 learning.py:512] global step 18524: loss = 2.8119 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18525: loss = 4.4915 (0.110 sec/step)\n",
            "I1003 01:01:01.957415 139845451286400 learning.py:512] global step 18525: loss = 4.4915 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18526: loss = 3.1675 (0.097 sec/step)\n",
            "I1003 01:01:02.056031 139845451286400 learning.py:512] global step 18526: loss = 3.1675 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18527: loss = 7.1333 (0.107 sec/step)\n",
            "I1003 01:01:02.164570 139845451286400 learning.py:512] global step 18527: loss = 7.1333 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18528: loss = 3.3186 (0.106 sec/step)\n",
            "I1003 01:01:02.271940 139845451286400 learning.py:512] global step 18528: loss = 3.3186 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18529: loss = 12.1512 (0.094 sec/step)\n",
            "I1003 01:01:02.367183 139845451286400 learning.py:512] global step 18529: loss = 12.1512 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18530: loss = 2.7331 (0.103 sec/step)\n",
            "I1003 01:01:02.471577 139845451286400 learning.py:512] global step 18530: loss = 2.7331 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18531: loss = 3.4030 (0.108 sec/step)\n",
            "I1003 01:01:02.580941 139845451286400 learning.py:512] global step 18531: loss = 3.4030 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18532: loss = 5.9394 (0.101 sec/step)\n",
            "I1003 01:01:02.683675 139845451286400 learning.py:512] global step 18532: loss = 5.9394 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18533: loss = 2.9560 (0.106 sec/step)\n",
            "I1003 01:01:02.790621 139845451286400 learning.py:512] global step 18533: loss = 2.9560 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18534: loss = 2.5288 (0.103 sec/step)\n",
            "I1003 01:01:02.896799 139845451286400 learning.py:512] global step 18534: loss = 2.5288 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18535: loss = 3.8953 (0.097 sec/step)\n",
            "I1003 01:01:02.997569 139845451286400 learning.py:512] global step 18535: loss = 3.8953 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18536: loss = 5.4581 (0.103 sec/step)\n",
            "I1003 01:01:03.102040 139845451286400 learning.py:512] global step 18536: loss = 5.4581 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18537: loss = 4.5005 (0.091 sec/step)\n",
            "I1003 01:01:03.194338 139845451286400 learning.py:512] global step 18537: loss = 4.5005 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18538: loss = 3.0273 (0.138 sec/step)\n",
            "I1003 01:01:03.333334 139845451286400 learning.py:512] global step 18538: loss = 3.0273 (0.138 sec/step)\n",
            "INFO:tensorflow:global step 18539: loss = 2.8937 (0.119 sec/step)\n",
            "I1003 01:01:03.454373 139845451286400 learning.py:512] global step 18539: loss = 2.8937 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18540: loss = 8.6516 (0.108 sec/step)\n",
            "I1003 01:01:03.563620 139845451286400 learning.py:512] global step 18540: loss = 8.6516 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18541: loss = 2.7958 (0.114 sec/step)\n",
            "I1003 01:01:03.678946 139845451286400 learning.py:512] global step 18541: loss = 2.7958 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18542: loss = 2.5848 (0.111 sec/step)\n",
            "I1003 01:01:03.791246 139845451286400 learning.py:512] global step 18542: loss = 2.5848 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18543: loss = 8.1830 (0.100 sec/step)\n",
            "I1003 01:01:03.892966 139845451286400 learning.py:512] global step 18543: loss = 8.1830 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18544: loss = 2.7881 (0.120 sec/step)\n",
            "I1003 01:01:04.014325 139845451286400 learning.py:512] global step 18544: loss = 2.7881 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 18545: loss = 2.6526 (0.093 sec/step)\n",
            "I1003 01:01:04.109072 139845451286400 learning.py:512] global step 18545: loss = 2.6526 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18546: loss = 3.5750 (0.101 sec/step)\n",
            "I1003 01:01:04.211669 139845451286400 learning.py:512] global step 18546: loss = 3.5750 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18547: loss = 3.6157 (0.114 sec/step)\n",
            "I1003 01:01:04.327579 139845451286400 learning.py:512] global step 18547: loss = 3.6157 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18548: loss = 4.1634 (0.114 sec/step)\n",
            "I1003 01:01:04.443013 139845451286400 learning.py:512] global step 18548: loss = 4.1634 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18549: loss = 3.2189 (0.111 sec/step)\n",
            "I1003 01:01:04.555610 139845451286400 learning.py:512] global step 18549: loss = 3.2189 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18550: loss = 5.5017 (0.118 sec/step)\n",
            "I1003 01:01:04.675623 139845451286400 learning.py:512] global step 18550: loss = 5.5017 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18551: loss = 4.0575 (0.113 sec/step)\n",
            "I1003 01:01:04.790322 139845451286400 learning.py:512] global step 18551: loss = 4.0575 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18552: loss = 3.4702 (0.090 sec/step)\n",
            "I1003 01:01:04.882013 139845451286400 learning.py:512] global step 18552: loss = 3.4702 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18553: loss = 4.4663 (0.116 sec/step)\n",
            "I1003 01:01:04.999424 139845451286400 learning.py:512] global step 18553: loss = 4.4663 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18554: loss = 6.0890 (0.100 sec/step)\n",
            "I1003 01:01:05.100470 139845451286400 learning.py:512] global step 18554: loss = 6.0890 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18555: loss = 4.1633 (0.102 sec/step)\n",
            "I1003 01:01:05.204130 139845451286400 learning.py:512] global step 18555: loss = 4.1633 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18556: loss = 3.7997 (0.097 sec/step)\n",
            "I1003 01:01:05.302274 139845451286400 learning.py:512] global step 18556: loss = 3.7997 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18557: loss = 6.3819 (0.099 sec/step)\n",
            "I1003 01:01:05.402845 139845451286400 learning.py:512] global step 18557: loss = 6.3819 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18558: loss = 2.8506 (0.100 sec/step)\n",
            "I1003 01:01:05.504009 139845451286400 learning.py:512] global step 18558: loss = 2.8506 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18559: loss = 3.9729 (0.110 sec/step)\n",
            "I1003 01:01:05.614867 139845451286400 learning.py:512] global step 18559: loss = 3.9729 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18560: loss = 3.2584 (0.100 sec/step)\n",
            "I1003 01:01:05.716247 139845451286400 learning.py:512] global step 18560: loss = 3.2584 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18561: loss = 3.0445 (0.101 sec/step)\n",
            "I1003 01:01:05.818550 139845451286400 learning.py:512] global step 18561: loss = 3.0445 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18562: loss = 3.4323 (0.098 sec/step)\n",
            "I1003 01:01:05.918366 139845451286400 learning.py:512] global step 18562: loss = 3.4323 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18563: loss = 6.2525 (0.103 sec/step)\n",
            "I1003 01:01:06.022837 139845451286400 learning.py:512] global step 18563: loss = 6.2525 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18564: loss = 4.4031 (0.099 sec/step)\n",
            "I1003 01:01:06.122943 139845451286400 learning.py:512] global step 18564: loss = 4.4031 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18565: loss = 3.0978 (0.088 sec/step)\n",
            "I1003 01:01:06.212557 139845451286400 learning.py:512] global step 18565: loss = 3.0978 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18566: loss = 2.5150 (0.106 sec/step)\n",
            "I1003 01:01:06.319618 139845451286400 learning.py:512] global step 18566: loss = 2.5150 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18567: loss = 3.0649 (0.101 sec/step)\n",
            "I1003 01:01:06.421895 139845451286400 learning.py:512] global step 18567: loss = 3.0649 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18568: loss = 6.1029 (0.104 sec/step)\n",
            "I1003 01:01:06.527262 139845451286400 learning.py:512] global step 18568: loss = 6.1029 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18569: loss = 2.6167 (0.101 sec/step)\n",
            "I1003 01:01:06.629445 139845451286400 learning.py:512] global step 18569: loss = 2.6167 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18570: loss = 3.3593 (0.097 sec/step)\n",
            "I1003 01:01:06.727503 139845451286400 learning.py:512] global step 18570: loss = 3.3593 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18571: loss = 6.8097 (0.098 sec/step)\n",
            "I1003 01:01:06.827358 139845451286400 learning.py:512] global step 18571: loss = 6.8097 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18572: loss = 3.2756 (0.090 sec/step)\n",
            "I1003 01:01:06.918754 139845451286400 learning.py:512] global step 18572: loss = 3.2756 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18573: loss = 3.5606 (0.103 sec/step)\n",
            "I1003 01:01:07.023528 139845451286400 learning.py:512] global step 18573: loss = 3.5606 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18574: loss = 4.5918 (0.092 sec/step)\n",
            "I1003 01:01:07.117035 139845451286400 learning.py:512] global step 18574: loss = 4.5918 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18575: loss = 2.3444 (0.105 sec/step)\n",
            "I1003 01:01:07.223232 139845451286400 learning.py:512] global step 18575: loss = 2.3444 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18576: loss = 6.0654 (0.094 sec/step)\n",
            "I1003 01:01:07.318555 139845451286400 learning.py:512] global step 18576: loss = 6.0654 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18577: loss = 8.6624 (0.088 sec/step)\n",
            "I1003 01:01:07.407674 139845451286400 learning.py:512] global step 18577: loss = 8.6624 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18578: loss = 8.8418 (0.099 sec/step)\n",
            "I1003 01:01:07.508370 139845451286400 learning.py:512] global step 18578: loss = 8.8418 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18579: loss = 2.4868 (0.104 sec/step)\n",
            "I1003 01:01:07.613439 139845451286400 learning.py:512] global step 18579: loss = 2.4868 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18580: loss = 6.4839 (0.099 sec/step)\n",
            "I1003 01:01:07.713483 139845451286400 learning.py:512] global step 18580: loss = 6.4839 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18581: loss = 5.5324 (0.096 sec/step)\n",
            "I1003 01:01:07.810525 139845451286400 learning.py:512] global step 18581: loss = 5.5324 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18582: loss = 5.5738 (0.091 sec/step)\n",
            "I1003 01:01:07.902922 139845451286400 learning.py:512] global step 18582: loss = 5.5738 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18583: loss = 4.5136 (0.106 sec/step)\n",
            "I1003 01:01:08.010598 139845451286400 learning.py:512] global step 18583: loss = 4.5136 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18584: loss = 2.3236 (0.086 sec/step)\n",
            "I1003 01:01:08.098370 139845451286400 learning.py:512] global step 18584: loss = 2.3236 (0.086 sec/step)\n",
            "INFO:tensorflow:global step 18585: loss = 3.3258 (0.093 sec/step)\n",
            "I1003 01:01:08.192583 139845451286400 learning.py:512] global step 18585: loss = 3.3258 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18586: loss = 4.9629 (0.096 sec/step)\n",
            "I1003 01:01:08.289663 139845451286400 learning.py:512] global step 18586: loss = 4.9629 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18587: loss = 2.7065 (0.101 sec/step)\n",
            "I1003 01:01:08.391896 139845451286400 learning.py:512] global step 18587: loss = 2.7065 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18588: loss = 4.3662 (0.096 sec/step)\n",
            "I1003 01:01:08.489483 139845451286400 learning.py:512] global step 18588: loss = 4.3662 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18589: loss = 6.1038 (0.093 sec/step)\n",
            "I1003 01:01:08.584115 139845451286400 learning.py:512] global step 18589: loss = 6.1038 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18590: loss = 4.1454 (0.099 sec/step)\n",
            "I1003 01:01:08.684090 139845451286400 learning.py:512] global step 18590: loss = 4.1454 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18591: loss = 5.6686 (0.103 sec/step)\n",
            "I1003 01:01:08.788530 139845451286400 learning.py:512] global step 18591: loss = 5.6686 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18592: loss = 4.9481 (0.101 sec/step)\n",
            "I1003 01:01:08.891577 139845451286400 learning.py:512] global step 18592: loss = 4.9481 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18593: loss = 2.6857 (0.116 sec/step)\n",
            "I1003 01:01:09.008613 139845451286400 learning.py:512] global step 18593: loss = 2.6857 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18594: loss = 5.7862 (0.129 sec/step)\n",
            "I1003 01:01:09.138911 139845451286400 learning.py:512] global step 18594: loss = 5.7862 (0.129 sec/step)\n",
            "INFO:tensorflow:global step 18595: loss = 8.0747 (0.095 sec/step)\n",
            "I1003 01:01:09.235005 139845451286400 learning.py:512] global step 18595: loss = 8.0747 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18596: loss = 3.0585 (0.094 sec/step)\n",
            "I1003 01:01:09.330748 139845451286400 learning.py:512] global step 18596: loss = 3.0585 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18597: loss = 3.2146 (0.098 sec/step)\n",
            "I1003 01:01:09.430372 139845451286400 learning.py:512] global step 18597: loss = 3.2146 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18598: loss = 5.0630 (0.096 sec/step)\n",
            "I1003 01:01:09.528049 139845451286400 learning.py:512] global step 18598: loss = 5.0630 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18599: loss = 3.4675 (0.104 sec/step)\n",
            "I1003 01:01:09.633663 139845451286400 learning.py:512] global step 18599: loss = 3.4675 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18600: loss = 11.5224 (0.093 sec/step)\n",
            "I1003 01:01:09.727876 139845451286400 learning.py:512] global step 18600: loss = 11.5224 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18601: loss = 5.2598 (0.099 sec/step)\n",
            "I1003 01:01:09.827679 139845451286400 learning.py:512] global step 18601: loss = 5.2598 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18602: loss = 3.4474 (0.099 sec/step)\n",
            "I1003 01:01:09.927623 139845451286400 learning.py:512] global step 18602: loss = 3.4474 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18603: loss = 4.2634 (0.088 sec/step)\n",
            "I1003 01:01:10.017208 139845451286400 learning.py:512] global step 18603: loss = 4.2634 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18604: loss = 3.2142 (0.109 sec/step)\n",
            "I1003 01:01:10.127698 139845451286400 learning.py:512] global step 18604: loss = 3.2142 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18605: loss = 2.5545 (0.092 sec/step)\n",
            "I1003 01:01:10.221313 139845451286400 learning.py:512] global step 18605: loss = 2.5545 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18606: loss = 4.9215 (0.101 sec/step)\n",
            "I1003 01:01:10.323530 139845451286400 learning.py:512] global step 18606: loss = 4.9215 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18607: loss = 2.4447 (0.097 sec/step)\n",
            "I1003 01:01:10.422185 139845451286400 learning.py:512] global step 18607: loss = 2.4447 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18608: loss = 4.3037 (0.104 sec/step)\n",
            "I1003 01:01:10.527833 139845451286400 learning.py:512] global step 18608: loss = 4.3037 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18609: loss = 3.3704 (0.103 sec/step)\n",
            "I1003 01:01:10.632515 139845451286400 learning.py:512] global step 18609: loss = 3.3704 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18610: loss = 6.2486 (0.096 sec/step)\n",
            "I1003 01:01:10.729929 139845451286400 learning.py:512] global step 18610: loss = 6.2486 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18611: loss = 5.7877 (0.111 sec/step)\n",
            "I1003 01:01:10.842679 139845451286400 learning.py:512] global step 18611: loss = 5.7877 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18612: loss = 2.5669 (0.102 sec/step)\n",
            "I1003 01:01:10.946501 139845451286400 learning.py:512] global step 18612: loss = 2.5669 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18613: loss = 2.6658 (0.097 sec/step)\n",
            "I1003 01:01:11.045176 139845451286400 learning.py:512] global step 18613: loss = 2.6658 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18614: loss = 4.0063 (0.113 sec/step)\n",
            "I1003 01:01:11.159830 139845451286400 learning.py:512] global step 18614: loss = 4.0063 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18615: loss = 2.0753 (0.092 sec/step)\n",
            "I1003 01:01:11.252888 139845451286400 learning.py:512] global step 18615: loss = 2.0753 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18616: loss = 3.4239 (0.094 sec/step)\n",
            "I1003 01:01:11.348066 139845451286400 learning.py:512] global step 18616: loss = 3.4239 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18617: loss = 2.8970 (0.104 sec/step)\n",
            "I1003 01:01:11.453296 139845451286400 learning.py:512] global step 18617: loss = 2.8970 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18618: loss = 5.1196 (0.104 sec/step)\n",
            "I1003 01:01:11.558437 139845451286400 learning.py:512] global step 18618: loss = 5.1196 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18619: loss = 2.3436 (0.106 sec/step)\n",
            "I1003 01:01:11.665297 139845451286400 learning.py:512] global step 18619: loss = 2.3436 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18620: loss = 3.5906 (0.089 sec/step)\n",
            "I1003 01:01:11.755962 139845451286400 learning.py:512] global step 18620: loss = 3.5906 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18621: loss = 2.7589 (0.087 sec/step)\n",
            "I1003 01:01:11.844077 139845451286400 learning.py:512] global step 18621: loss = 2.7589 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 18622: loss = 3.9402 (0.106 sec/step)\n",
            "I1003 01:01:11.951699 139845451286400 learning.py:512] global step 18622: loss = 3.9402 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18623: loss = 5.8495 (0.098 sec/step)\n",
            "I1003 01:01:12.050749 139845451286400 learning.py:512] global step 18623: loss = 5.8495 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18624: loss = 4.0316 (0.095 sec/step)\n",
            "I1003 01:01:12.147310 139845451286400 learning.py:512] global step 18624: loss = 4.0316 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18625: loss = 3.5167 (0.096 sec/step)\n",
            "I1003 01:01:12.245083 139845451286400 learning.py:512] global step 18625: loss = 3.5167 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18626: loss = 5.3619 (0.100 sec/step)\n",
            "I1003 01:01:12.347015 139845451286400 learning.py:512] global step 18626: loss = 5.3619 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18627: loss = 10.7527 (0.094 sec/step)\n",
            "I1003 01:01:12.441914 139845451286400 learning.py:512] global step 18627: loss = 10.7527 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18628: loss = 1.7961 (0.116 sec/step)\n",
            "I1003 01:01:12.559441 139845451286400 learning.py:512] global step 18628: loss = 1.7961 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18629: loss = 10.3240 (0.096 sec/step)\n",
            "I1003 01:01:12.656969 139845451286400 learning.py:512] global step 18629: loss = 10.3240 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18630: loss = 4.2955 (0.105 sec/step)\n",
            "I1003 01:01:12.763175 139845451286400 learning.py:512] global step 18630: loss = 4.2955 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18631: loss = 5.3848 (0.100 sec/step)\n",
            "I1003 01:01:12.864156 139845451286400 learning.py:512] global step 18631: loss = 5.3848 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18632: loss = 6.7256 (0.097 sec/step)\n",
            "I1003 01:01:12.962672 139845451286400 learning.py:512] global step 18632: loss = 6.7256 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18633: loss = 3.5030 (0.110 sec/step)\n",
            "I1003 01:01:13.074357 139845451286400 learning.py:512] global step 18633: loss = 3.5030 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18634: loss = 2.7825 (0.096 sec/step)\n",
            "I1003 01:01:13.172155 139845451286400 learning.py:512] global step 18634: loss = 2.7825 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18635: loss = 7.4334 (0.095 sec/step)\n",
            "I1003 01:01:13.268475 139845451286400 learning.py:512] global step 18635: loss = 7.4334 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18636: loss = 6.3566 (0.095 sec/step)\n",
            "I1003 01:01:13.364716 139845451286400 learning.py:512] global step 18636: loss = 6.3566 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18637: loss = 3.8488 (0.101 sec/step)\n",
            "I1003 01:01:13.467277 139845451286400 learning.py:512] global step 18637: loss = 3.8488 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18638: loss = 2.8730 (0.097 sec/step)\n",
            "I1003 01:01:13.566237 139845451286400 learning.py:512] global step 18638: loss = 2.8730 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18639: loss = 5.4229 (0.097 sec/step)\n",
            "I1003 01:01:13.664926 139845451286400 learning.py:512] global step 18639: loss = 5.4229 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18640: loss = 2.9228 (0.094 sec/step)\n",
            "I1003 01:01:13.760613 139845451286400 learning.py:512] global step 18640: loss = 2.9228 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18641: loss = 3.2084 (0.099 sec/step)\n",
            "I1003 01:01:13.860764 139845451286400 learning.py:512] global step 18641: loss = 3.2084 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18642: loss = 7.8024 (0.101 sec/step)\n",
            "I1003 01:01:13.963490 139845451286400 learning.py:512] global step 18642: loss = 7.8024 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18643: loss = 9.0481 (0.106 sec/step)\n",
            "I1003 01:01:14.071305 139845451286400 learning.py:512] global step 18643: loss = 9.0481 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18644: loss = 2.9583 (0.100 sec/step)\n",
            "I1003 01:01:14.172517 139845451286400 learning.py:512] global step 18644: loss = 2.9583 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18645: loss = 2.6381 (0.100 sec/step)\n",
            "I1003 01:01:14.273779 139845451286400 learning.py:512] global step 18645: loss = 2.6381 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18646: loss = 3.6316 (0.103 sec/step)\n",
            "I1003 01:01:14.377993 139845451286400 learning.py:512] global step 18646: loss = 3.6316 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18647: loss = 2.9841 (0.094 sec/step)\n",
            "I1003 01:01:14.473277 139845451286400 learning.py:512] global step 18647: loss = 2.9841 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18648: loss = 2.2853 (0.112 sec/step)\n",
            "I1003 01:01:14.586554 139845451286400 learning.py:512] global step 18648: loss = 2.2853 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18649: loss = 4.0367 (0.120 sec/step)\n",
            "I1003 01:01:14.708275 139845451286400 learning.py:512] global step 18649: loss = 4.0367 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 18650: loss = 2.3169 (0.102 sec/step)\n",
            "I1003 01:01:14.811597 139845451286400 learning.py:512] global step 18650: loss = 2.3169 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18651: loss = 7.9858 (0.099 sec/step)\n",
            "I1003 01:01:14.916056 139845451286400 learning.py:512] global step 18651: loss = 7.9858 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18652: loss = 5.8793 (0.096 sec/step)\n",
            "I1003 01:01:15.015171 139845451286400 learning.py:512] global step 18652: loss = 5.8793 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18653: loss = 5.2866 (0.096 sec/step)\n",
            "I1003 01:01:15.112771 139845451286400 learning.py:512] global step 18653: loss = 5.2866 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18654: loss = 3.8366 (0.119 sec/step)\n",
            "I1003 01:01:15.232761 139845451286400 learning.py:512] global step 18654: loss = 3.8366 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18655: loss = 4.5901 (0.097 sec/step)\n",
            "I1003 01:01:15.331102 139845451286400 learning.py:512] global step 18655: loss = 4.5901 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18656: loss = 2.5470 (0.098 sec/step)\n",
            "I1003 01:01:15.430048 139845451286400 learning.py:512] global step 18656: loss = 2.5470 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18657: loss = 4.5435 (0.101 sec/step)\n",
            "I1003 01:01:15.532714 139845451286400 learning.py:512] global step 18657: loss = 4.5435 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18658: loss = 2.0557 (0.117 sec/step)\n",
            "I1003 01:01:15.651523 139845451286400 learning.py:512] global step 18658: loss = 2.0557 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 18659: loss = 8.5422 (0.099 sec/step)\n",
            "I1003 01:01:15.751781 139845451286400 learning.py:512] global step 18659: loss = 8.5422 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18660: loss = 7.0921 (0.093 sec/step)\n",
            "I1003 01:01:15.846633 139845451286400 learning.py:512] global step 18660: loss = 7.0921 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18661: loss = 3.6857 (0.101 sec/step)\n",
            "I1003 01:01:15.949556 139845451286400 learning.py:512] global step 18661: loss = 3.6857 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18662: loss = 5.9975 (0.094 sec/step)\n",
            "I1003 01:01:16.045712 139845451286400 learning.py:512] global step 18662: loss = 5.9975 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18663: loss = 4.8909 (0.101 sec/step)\n",
            "I1003 01:01:16.147966 139845451286400 learning.py:512] global step 18663: loss = 4.8909 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18664: loss = 2.6512 (0.106 sec/step)\n",
            "I1003 01:01:16.255780 139845451286400 learning.py:512] global step 18664: loss = 2.6512 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18665: loss = 5.0522 (0.103 sec/step)\n",
            "I1003 01:01:16.360075 139845451286400 learning.py:512] global step 18665: loss = 5.0522 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18666: loss = 7.4818 (0.092 sec/step)\n",
            "I1003 01:01:16.453382 139845451286400 learning.py:512] global step 18666: loss = 7.4818 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18667: loss = 6.0263 (0.104 sec/step)\n",
            "I1003 01:01:16.558744 139845451286400 learning.py:512] global step 18667: loss = 6.0263 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18668: loss = 3.7600 (0.101 sec/step)\n",
            "I1003 01:01:16.660757 139845451286400 learning.py:512] global step 18668: loss = 3.7600 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18669: loss = 1.9810 (0.101 sec/step)\n",
            "I1003 01:01:16.763321 139845451286400 learning.py:512] global step 18669: loss = 1.9810 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18670: loss = 4.8424 (0.099 sec/step)\n",
            "I1003 01:01:16.863904 139845451286400 learning.py:512] global step 18670: loss = 4.8424 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18671: loss = 2.9929 (0.100 sec/step)\n",
            "I1003 01:01:16.965563 139845451286400 learning.py:512] global step 18671: loss = 2.9929 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18672: loss = 2.7549 (0.101 sec/step)\n",
            "I1003 01:01:17.067902 139845451286400 learning.py:512] global step 18672: loss = 2.7549 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18673: loss = 2.0538 (0.094 sec/step)\n",
            "I1003 01:01:17.163719 139845451286400 learning.py:512] global step 18673: loss = 2.0538 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18674: loss = 5.8962 (0.113 sec/step)\n",
            "I1003 01:01:17.278659 139845451286400 learning.py:512] global step 18674: loss = 5.8962 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18675: loss = 2.5854 (0.103 sec/step)\n",
            "I1003 01:01:17.383465 139845451286400 learning.py:512] global step 18675: loss = 2.5854 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18676: loss = 2.0474 (0.096 sec/step)\n",
            "I1003 01:01:17.480893 139845451286400 learning.py:512] global step 18676: loss = 2.0474 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18677: loss = 5.6617 (0.103 sec/step)\n",
            "I1003 01:01:17.585127 139845451286400 learning.py:512] global step 18677: loss = 5.6617 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18678: loss = 2.7105 (0.105 sec/step)\n",
            "I1003 01:01:17.691045 139845451286400 learning.py:512] global step 18678: loss = 2.7105 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18679: loss = 5.6940 (0.091 sec/step)\n",
            "I1003 01:01:17.785100 139845451286400 learning.py:512] global step 18679: loss = 5.6940 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18680: loss = 2.1305 (0.097 sec/step)\n",
            "I1003 01:01:17.883933 139845451286400 learning.py:512] global step 18680: loss = 2.1305 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18681: loss = 1.8930 (0.105 sec/step)\n",
            "I1003 01:01:17.989740 139845451286400 learning.py:512] global step 18681: loss = 1.8930 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18682: loss = 3.4353 (0.098 sec/step)\n",
            "I1003 01:01:18.088675 139845451286400 learning.py:512] global step 18682: loss = 3.4353 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18683: loss = 5.1455 (0.104 sec/step)\n",
            "I1003 01:01:18.194353 139845451286400 learning.py:512] global step 18683: loss = 5.1455 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18684: loss = 3.9197 (0.097 sec/step)\n",
            "I1003 01:01:18.292771 139845451286400 learning.py:512] global step 18684: loss = 3.9197 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18685: loss = 3.0753 (0.102 sec/step)\n",
            "I1003 01:01:18.395898 139845451286400 learning.py:512] global step 18685: loss = 3.0753 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18686: loss = 9.3482 (0.108 sec/step)\n",
            "I1003 01:01:18.505610 139845451286400 learning.py:512] global step 18686: loss = 9.3482 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18687: loss = 2.9101 (0.104 sec/step)\n",
            "I1003 01:01:18.613637 139845451286400 learning.py:512] global step 18687: loss = 2.9101 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18688: loss = 3.4753 (0.101 sec/step)\n",
            "I1003 01:01:18.716366 139845451286400 learning.py:512] global step 18688: loss = 3.4753 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18689: loss = 4.8573 (0.098 sec/step)\n",
            "I1003 01:01:18.816102 139845451286400 learning.py:512] global step 18689: loss = 4.8573 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18690: loss = 4.5246 (0.105 sec/step)\n",
            "I1003 01:01:18.922503 139845451286400 learning.py:512] global step 18690: loss = 4.5246 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18691: loss = 3.2262 (0.095 sec/step)\n",
            "I1003 01:01:19.018526 139845451286400 learning.py:512] global step 18691: loss = 3.2262 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18692: loss = 3.4751 (0.114 sec/step)\n",
            "I1003 01:01:19.133555 139845451286400 learning.py:512] global step 18692: loss = 3.4751 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18693: loss = 2.2886 (0.108 sec/step)\n",
            "I1003 01:01:19.244015 139845451286400 learning.py:512] global step 18693: loss = 2.2886 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18694: loss = 4.5790 (0.103 sec/step)\n",
            "I1003 01:01:19.348111 139845451286400 learning.py:512] global step 18694: loss = 4.5790 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18695: loss = 2.6373 (0.108 sec/step)\n",
            "I1003 01:01:19.457058 139845451286400 learning.py:512] global step 18695: loss = 2.6373 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18696: loss = 2.5502 (0.099 sec/step)\n",
            "I1003 01:01:19.557593 139845451286400 learning.py:512] global step 18696: loss = 2.5502 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18697: loss = 3.2658 (0.103 sec/step)\n",
            "I1003 01:01:19.661637 139845451286400 learning.py:512] global step 18697: loss = 3.2658 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18698: loss = 3.4009 (0.095 sec/step)\n",
            "I1003 01:01:19.758039 139845451286400 learning.py:512] global step 18698: loss = 3.4009 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18699: loss = 5.8060 (0.092 sec/step)\n",
            "I1003 01:01:19.851632 139845451286400 learning.py:512] global step 18699: loss = 5.8060 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18700: loss = 2.5645 (0.101 sec/step)\n",
            "I1003 01:01:19.954052 139845451286400 learning.py:512] global step 18700: loss = 2.5645 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18701: loss = 5.8360 (0.100 sec/step)\n",
            "I1003 01:01:20.055750 139845451286400 learning.py:512] global step 18701: loss = 5.8360 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18702: loss = 5.2085 (0.092 sec/step)\n",
            "I1003 01:01:20.148940 139845451286400 learning.py:512] global step 18702: loss = 5.2085 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18703: loss = 7.7405 (0.104 sec/step)\n",
            "I1003 01:01:20.254585 139845451286400 learning.py:512] global step 18703: loss = 7.7405 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18704: loss = 3.3988 (0.116 sec/step)\n",
            "I1003 01:01:20.372152 139845451286400 learning.py:512] global step 18704: loss = 3.3988 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18705: loss = 4.9694 (0.091 sec/step)\n",
            "I1003 01:01:20.464472 139845451286400 learning.py:512] global step 18705: loss = 4.9694 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18706: loss = 5.7815 (0.104 sec/step)\n",
            "I1003 01:01:20.569905 139845451286400 learning.py:512] global step 18706: loss = 5.7815 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18707: loss = 3.4177 (0.114 sec/step)\n",
            "I1003 01:01:20.685094 139845451286400 learning.py:512] global step 18707: loss = 3.4177 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18708: loss = 1.9767 (0.118 sec/step)\n",
            "I1003 01:01:20.804925 139845451286400 learning.py:512] global step 18708: loss = 1.9767 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18709: loss = 3.2900 (0.120 sec/step)\n",
            "I1003 01:01:20.926887 139845451286400 learning.py:512] global step 18709: loss = 3.2900 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 18710: loss = 2.4290 (0.106 sec/step)\n",
            "I1003 01:01:21.033997 139845451286400 learning.py:512] global step 18710: loss = 2.4290 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18711: loss = 6.5049 (0.097 sec/step)\n",
            "I1003 01:01:21.132713 139845451286400 learning.py:512] global step 18711: loss = 6.5049 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18712: loss = 2.1532 (0.101 sec/step)\n",
            "I1003 01:01:21.234890 139845451286400 learning.py:512] global step 18712: loss = 2.1532 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18713: loss = 6.8776 (0.128 sec/step)\n",
            "I1003 01:01:21.364783 139845451286400 learning.py:512] global step 18713: loss = 6.8776 (0.128 sec/step)\n",
            "INFO:tensorflow:global step 18714: loss = 2.6412 (0.109 sec/step)\n",
            "I1003 01:01:21.475414 139845451286400 learning.py:512] global step 18714: loss = 2.6412 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18715: loss = 3.6288 (0.116 sec/step)\n",
            "I1003 01:01:21.593766 139845451286400 learning.py:512] global step 18715: loss = 3.6288 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18716: loss = 7.8510 (0.119 sec/step)\n",
            "I1003 01:01:21.713791 139845451286400 learning.py:512] global step 18716: loss = 7.8510 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18717: loss = 6.4855 (0.090 sec/step)\n",
            "I1003 01:01:21.805333 139845451286400 learning.py:512] global step 18717: loss = 6.4855 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18718: loss = 9.8476 (0.092 sec/step)\n",
            "I1003 01:01:21.899029 139845451286400 learning.py:512] global step 18718: loss = 9.8476 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18719: loss = 2.4150 (0.104 sec/step)\n",
            "I1003 01:01:22.004310 139845451286400 learning.py:512] global step 18719: loss = 2.4150 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18720: loss = 6.3999 (0.099 sec/step)\n",
            "I1003 01:01:22.104353 139845451286400 learning.py:512] global step 18720: loss = 6.3999 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18721: loss = 3.0641 (0.096 sec/step)\n",
            "I1003 01:01:22.201552 139845451286400 learning.py:512] global step 18721: loss = 3.0641 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18722: loss = 3.9577 (0.097 sec/step)\n",
            "I1003 01:01:22.301271 139845451286400 learning.py:512] global step 18722: loss = 3.9577 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18723: loss = 3.3709 (0.100 sec/step)\n",
            "I1003 01:01:22.403635 139845451286400 learning.py:512] global step 18723: loss = 3.3709 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18724: loss = 2.5786 (0.099 sec/step)\n",
            "I1003 01:01:22.504354 139845451286400 learning.py:512] global step 18724: loss = 2.5786 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18725: loss = 4.5271 (0.094 sec/step)\n",
            "I1003 01:01:22.599754 139845451286400 learning.py:512] global step 18725: loss = 4.5271 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18726: loss = 3.4850 (0.105 sec/step)\n",
            "I1003 01:01:22.705914 139845451286400 learning.py:512] global step 18726: loss = 3.4850 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18727: loss = 5.3238 (0.106 sec/step)\n",
            "I1003 01:01:22.813702 139845451286400 learning.py:512] global step 18727: loss = 5.3238 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18728: loss = 7.2066 (0.095 sec/step)\n",
            "I1003 01:01:22.910501 139845451286400 learning.py:512] global step 18728: loss = 7.2066 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18729: loss = 4.2980 (0.102 sec/step)\n",
            "I1003 01:01:23.013674 139845451286400 learning.py:512] global step 18729: loss = 4.2980 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18730: loss = 3.0456 (0.104 sec/step)\n",
            "I1003 01:01:23.119418 139845451286400 learning.py:512] global step 18730: loss = 3.0456 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18731: loss = 4.1468 (0.099 sec/step)\n",
            "I1003 01:01:23.219635 139845451286400 learning.py:512] global step 18731: loss = 4.1468 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18732: loss = 2.6190 (0.114 sec/step)\n",
            "I1003 01:01:23.334567 139845451286400 learning.py:512] global step 18732: loss = 2.6190 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18733: loss = 2.3818 (0.116 sec/step)\n",
            "I1003 01:01:23.451544 139845451286400 learning.py:512] global step 18733: loss = 2.3818 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18734: loss = 3.3138 (0.116 sec/step)\n",
            "I1003 01:01:23.569388 139845451286400 learning.py:512] global step 18734: loss = 3.3138 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18735: loss = 3.5477 (0.119 sec/step)\n",
            "I1003 01:01:23.689966 139845451286400 learning.py:512] global step 18735: loss = 3.5477 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18736: loss = 5.1525 (0.098 sec/step)\n",
            "I1003 01:01:23.790365 139845451286400 learning.py:512] global step 18736: loss = 5.1525 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18737: loss = 4.6299 (0.105 sec/step)\n",
            "I1003 01:01:23.896511 139845451286400 learning.py:512] global step 18737: loss = 4.6299 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18738: loss = 3.3725 (0.096 sec/step)\n",
            "I1003 01:01:23.994136 139845451286400 learning.py:512] global step 18738: loss = 3.3725 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18739: loss = 2.3471 (0.100 sec/step)\n",
            "I1003 01:01:24.095344 139845451286400 learning.py:512] global step 18739: loss = 2.3471 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18740: loss = 5.0560 (0.098 sec/step)\n",
            "I1003 01:01:24.194705 139845451286400 learning.py:512] global step 18740: loss = 5.0560 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18741: loss = 5.2037 (0.094 sec/step)\n",
            "I1003 01:01:24.290734 139845451286400 learning.py:512] global step 18741: loss = 5.2037 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18742: loss = 4.7432 (0.104 sec/step)\n",
            "I1003 01:01:24.396141 139845451286400 learning.py:512] global step 18742: loss = 4.7432 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18743: loss = 4.8565 (0.111 sec/step)\n",
            "I1003 01:01:24.508019 139845451286400 learning.py:512] global step 18743: loss = 4.8565 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18744: loss = 2.7139 (0.096 sec/step)\n",
            "I1003 01:01:24.605639 139845451286400 learning.py:512] global step 18744: loss = 2.7139 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18745: loss = 2.8672 (0.104 sec/step)\n",
            "I1003 01:01:24.710912 139845451286400 learning.py:512] global step 18745: loss = 2.8672 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18746: loss = 2.7154 (0.101 sec/step)\n",
            "I1003 01:01:24.813071 139845451286400 learning.py:512] global step 18746: loss = 2.7154 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18747: loss = 3.0341 (0.100 sec/step)\n",
            "I1003 01:01:24.914412 139845451286400 learning.py:512] global step 18747: loss = 3.0341 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18748: loss = 5.5201 (0.098 sec/step)\n",
            "I1003 01:01:25.014129 139845451286400 learning.py:512] global step 18748: loss = 5.5201 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18749: loss = 3.1740 (0.105 sec/step)\n",
            "I1003 01:01:25.121000 139845451286400 learning.py:512] global step 18749: loss = 3.1740 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18750: loss = 3.3343 (0.108 sec/step)\n",
            "I1003 01:01:25.229937 139845451286400 learning.py:512] global step 18750: loss = 3.3343 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18751: loss = 2.3585 (0.093 sec/step)\n",
            "I1003 01:01:25.323970 139845451286400 learning.py:512] global step 18751: loss = 2.3585 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18752: loss = 8.0176 (0.101 sec/step)\n",
            "I1003 01:01:25.426636 139845451286400 learning.py:512] global step 18752: loss = 8.0176 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18753: loss = 2.9362 (0.098 sec/step)\n",
            "I1003 01:01:25.526324 139845451286400 learning.py:512] global step 18753: loss = 2.9362 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18754: loss = 2.6743 (0.098 sec/step)\n",
            "I1003 01:01:25.625980 139845451286400 learning.py:512] global step 18754: loss = 2.6743 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18755: loss = 3.3613 (0.107 sec/step)\n",
            "I1003 01:01:25.734213 139845451286400 learning.py:512] global step 18755: loss = 3.3613 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18756: loss = 2.7368 (0.094 sec/step)\n",
            "I1003 01:01:25.829680 139845451286400 learning.py:512] global step 18756: loss = 2.7368 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18757: loss = 2.8422 (0.091 sec/step)\n",
            "I1003 01:01:25.922354 139845451286400 learning.py:512] global step 18757: loss = 2.8422 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18758: loss = 4.9782 (0.116 sec/step)\n",
            "I1003 01:01:26.040012 139845451286400 learning.py:512] global step 18758: loss = 4.9782 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18759: loss = 2.1053 (0.121 sec/step)\n",
            "I1003 01:01:26.162666 139845451286400 learning.py:512] global step 18759: loss = 2.1053 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 18760: loss = 3.7080 (0.098 sec/step)\n",
            "I1003 01:01:26.261785 139845451286400 learning.py:512] global step 18760: loss = 3.7080 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18761: loss = 3.4441 (0.099 sec/step)\n",
            "I1003 01:01:26.362076 139845451286400 learning.py:512] global step 18761: loss = 3.4441 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18762: loss = 5.1762 (0.098 sec/step)\n",
            "I1003 01:01:26.461237 139845451286400 learning.py:512] global step 18762: loss = 5.1762 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18763: loss = 2.9196 (0.102 sec/step)\n",
            "I1003 01:01:26.564321 139845451286400 learning.py:512] global step 18763: loss = 2.9196 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18764: loss = 5.1659 (0.103 sec/step)\n",
            "I1003 01:01:26.668565 139845451286400 learning.py:512] global step 18764: loss = 5.1659 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18765: loss = 4.0907 (0.103 sec/step)\n",
            "I1003 01:01:26.772982 139845451286400 learning.py:512] global step 18765: loss = 4.0907 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18766: loss = 3.7881 (0.094 sec/step)\n",
            "I1003 01:01:26.868448 139845451286400 learning.py:512] global step 18766: loss = 3.7881 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18767: loss = 7.6392 (0.103 sec/step)\n",
            "I1003 01:01:26.972978 139845451286400 learning.py:512] global step 18767: loss = 7.6392 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18768: loss = 1.9783 (0.102 sec/step)\n",
            "I1003 01:01:27.076604 139845451286400 learning.py:512] global step 18768: loss = 1.9783 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18769: loss = 2.9820 (0.104 sec/step)\n",
            "I1003 01:01:27.182403 139845451286400 learning.py:512] global step 18769: loss = 2.9820 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18770: loss = 3.6038 (0.102 sec/step)\n",
            "I1003 01:01:27.285873 139845451286400 learning.py:512] global step 18770: loss = 3.6038 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18771: loss = 3.7640 (0.111 sec/step)\n",
            "I1003 01:01:27.398785 139845451286400 learning.py:512] global step 18771: loss = 3.7640 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18772: loss = 2.3879 (0.103 sec/step)\n",
            "I1003 01:01:27.502599 139845451286400 learning.py:512] global step 18772: loss = 2.3879 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18773: loss = 3.2489 (0.101 sec/step)\n",
            "I1003 01:01:27.604724 139845451286400 learning.py:512] global step 18773: loss = 3.2489 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18774: loss = 3.0479 (0.099 sec/step)\n",
            "I1003 01:01:27.704702 139845451286400 learning.py:512] global step 18774: loss = 3.0479 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18775: loss = 2.6020 (0.112 sec/step)\n",
            "I1003 01:01:27.817657 139845451286400 learning.py:512] global step 18775: loss = 2.6020 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18776: loss = 2.3613 (0.108 sec/step)\n",
            "I1003 01:01:27.927091 139845451286400 learning.py:512] global step 18776: loss = 2.3613 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18777: loss = 7.3625 (0.102 sec/step)\n",
            "I1003 01:01:28.030947 139845451286400 learning.py:512] global step 18777: loss = 7.3625 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18778: loss = 2.2805 (0.091 sec/step)\n",
            "I1003 01:01:28.124143 139845451286400 learning.py:512] global step 18778: loss = 2.2805 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18779: loss = 2.9988 (0.108 sec/step)\n",
            "I1003 01:01:28.234054 139845451286400 learning.py:512] global step 18779: loss = 2.9988 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18780: loss = 3.3617 (0.108 sec/step)\n",
            "I1003 01:01:28.343536 139845451286400 learning.py:512] global step 18780: loss = 3.3617 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18781: loss = 3.1135 (0.131 sec/step)\n",
            "I1003 01:01:28.476626 139845451286400 learning.py:512] global step 18781: loss = 3.1135 (0.131 sec/step)\n",
            "INFO:tensorflow:global step 18782: loss = 5.0908 (0.105 sec/step)\n",
            "I1003 01:01:28.582669 139845451286400 learning.py:512] global step 18782: loss = 5.0908 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18783: loss = 2.8548 (0.121 sec/step)\n",
            "I1003 01:01:28.705108 139845451286400 learning.py:512] global step 18783: loss = 2.8548 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 18784: loss = 2.6234 (0.113 sec/step)\n",
            "I1003 01:01:28.819670 139845451286400 learning.py:512] global step 18784: loss = 2.6234 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18785: loss = 2.6948 (0.097 sec/step)\n",
            "I1003 01:01:28.918152 139845451286400 learning.py:512] global step 18785: loss = 2.6948 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18786: loss = 2.7199 (0.101 sec/step)\n",
            "I1003 01:01:29.020325 139845451286400 learning.py:512] global step 18786: loss = 2.7199 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18787: loss = 2.1008 (0.097 sec/step)\n",
            "I1003 01:01:29.119197 139845451286400 learning.py:512] global step 18787: loss = 2.1008 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18788: loss = 3.4119 (0.105 sec/step)\n",
            "I1003 01:01:29.225708 139845451286400 learning.py:512] global step 18788: loss = 3.4119 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18789: loss = 3.6866 (0.105 sec/step)\n",
            "I1003 01:01:29.331894 139845451286400 learning.py:512] global step 18789: loss = 3.6866 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18790: loss = 2.6505 (0.106 sec/step)\n",
            "I1003 01:01:29.438885 139845451286400 learning.py:512] global step 18790: loss = 2.6505 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18791: loss = 1.9822 (0.098 sec/step)\n",
            "I1003 01:01:29.538072 139845451286400 learning.py:512] global step 18791: loss = 1.9822 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18792: loss = 2.3307 (0.107 sec/step)\n",
            "I1003 01:01:29.646688 139845451286400 learning.py:512] global step 18792: loss = 2.3307 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18793: loss = 7.2830 (0.102 sec/step)\n",
            "I1003 01:01:29.749844 139845451286400 learning.py:512] global step 18793: loss = 7.2830 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18794: loss = 2.1516 (0.105 sec/step)\n",
            "I1003 01:01:29.856052 139845451286400 learning.py:512] global step 18794: loss = 2.1516 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18795: loss = 4.2531 (0.109 sec/step)\n",
            "I1003 01:01:29.966613 139845451286400 learning.py:512] global step 18795: loss = 4.2531 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18796: loss = 5.3791 (0.108 sec/step)\n",
            "I1003 01:01:30.076009 139845451286400 learning.py:512] global step 18796: loss = 5.3791 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18797: loss = 4.9336 (0.109 sec/step)\n",
            "I1003 01:01:30.186316 139845451286400 learning.py:512] global step 18797: loss = 4.9336 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18798: loss = 2.2489 (0.121 sec/step)\n",
            "I1003 01:01:30.309036 139845451286400 learning.py:512] global step 18798: loss = 2.2489 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 18799: loss = 5.5568 (0.113 sec/step)\n",
            "I1003 01:01:30.423265 139845451286400 learning.py:512] global step 18799: loss = 5.5568 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18800: loss = 2.9747 (0.123 sec/step)\n",
            "I1003 01:01:30.548343 139845451286400 learning.py:512] global step 18800: loss = 2.9747 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 18801: loss = 5.9622 (0.110 sec/step)\n",
            "I1003 01:01:30.659910 139845451286400 learning.py:512] global step 18801: loss = 5.9622 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18802: loss = 2.9995 (0.104 sec/step)\n",
            "I1003 01:01:30.765765 139845451286400 learning.py:512] global step 18802: loss = 2.9995 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18803: loss = 3.8458 (0.106 sec/step)\n",
            "I1003 01:01:30.873590 139845451286400 learning.py:512] global step 18803: loss = 3.8458 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18804: loss = 4.3999 (0.100 sec/step)\n",
            "I1003 01:01:30.975147 139845451286400 learning.py:512] global step 18804: loss = 4.3999 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18805: loss = 3.1004 (0.111 sec/step)\n",
            "I1003 01:01:31.087858 139845451286400 learning.py:512] global step 18805: loss = 3.1004 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18806: loss = 4.7772 (0.095 sec/step)\n",
            "I1003 01:01:31.184276 139845451286400 learning.py:512] global step 18806: loss = 4.7772 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18807: loss = 3.4049 (0.100 sec/step)\n",
            "I1003 01:01:31.285248 139845451286400 learning.py:512] global step 18807: loss = 3.4049 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18808: loss = 3.5801 (0.101 sec/step)\n",
            "I1003 01:01:31.388350 139845451286400 learning.py:512] global step 18808: loss = 3.5801 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18809: loss = 3.9209 (0.101 sec/step)\n",
            "I1003 01:01:31.490384 139845451286400 learning.py:512] global step 18809: loss = 3.9209 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18810: loss = 2.5732 (0.105 sec/step)\n",
            "I1003 01:01:31.596529 139845451286400 learning.py:512] global step 18810: loss = 2.5732 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18811: loss = 3.1374 (0.099 sec/step)\n",
            "I1003 01:01:31.697139 139845451286400 learning.py:512] global step 18811: loss = 3.1374 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18812: loss = 5.4562 (0.109 sec/step)\n",
            "I1003 01:01:31.807132 139845451286400 learning.py:512] global step 18812: loss = 5.4562 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18813: loss = 3.8923 (0.101 sec/step)\n",
            "I1003 01:01:31.909204 139845451286400 learning.py:512] global step 18813: loss = 3.8923 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18814: loss = 3.5152 (0.096 sec/step)\n",
            "I1003 01:01:32.007174 139845451286400 learning.py:512] global step 18814: loss = 3.5152 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18815: loss = 3.1211 (0.106 sec/step)\n",
            "I1003 01:01:32.114907 139845451286400 learning.py:512] global step 18815: loss = 3.1211 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18816: loss = 5.1465 (0.098 sec/step)\n",
            "I1003 01:01:32.214241 139845451286400 learning.py:512] global step 18816: loss = 5.1465 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18817: loss = 4.2217 (0.107 sec/step)\n",
            "I1003 01:01:32.323008 139845451286400 learning.py:512] global step 18817: loss = 4.2217 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18818: loss = 5.2947 (0.109 sec/step)\n",
            "I1003 01:01:32.433688 139845451286400 learning.py:512] global step 18818: loss = 5.2947 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18819: loss = 2.3294 (0.138 sec/step)\n",
            "I1003 01:01:32.573132 139845451286400 learning.py:512] global step 18819: loss = 2.3294 (0.138 sec/step)\n",
            "INFO:tensorflow:global step 18820: loss = 7.2725 (0.126 sec/step)\n",
            "I1003 01:01:32.700363 139845451286400 learning.py:512] global step 18820: loss = 7.2725 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 18821: loss = 4.3453 (0.100 sec/step)\n",
            "I1003 01:01:32.801748 139845451286400 learning.py:512] global step 18821: loss = 4.3453 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18822: loss = 2.9233 (0.106 sec/step)\n",
            "I1003 01:01:32.909500 139845451286400 learning.py:512] global step 18822: loss = 2.9233 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18823: loss = 4.7194 (0.097 sec/step)\n",
            "I1003 01:01:33.007975 139845451286400 learning.py:512] global step 18823: loss = 4.7194 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18824: loss = 2.9574 (0.094 sec/step)\n",
            "I1003 01:01:33.103713 139845451286400 learning.py:512] global step 18824: loss = 2.9574 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18825: loss = 3.2546 (0.114 sec/step)\n",
            "I1003 01:01:33.219522 139845451286400 learning.py:512] global step 18825: loss = 3.2546 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18826: loss = 3.0338 (0.090 sec/step)\n",
            "I1003 01:01:33.310661 139845451286400 learning.py:512] global step 18826: loss = 3.0338 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18827: loss = 9.8040 (0.102 sec/step)\n",
            "I1003 01:01:33.414043 139845451286400 learning.py:512] global step 18827: loss = 9.8040 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18828: loss = 1.9479 (0.102 sec/step)\n",
            "I1003 01:01:33.517015 139845451286400 learning.py:512] global step 18828: loss = 1.9479 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18829: loss = 2.5872 (0.103 sec/step)\n",
            "I1003 01:01:33.621065 139845451286400 learning.py:512] global step 18829: loss = 2.5872 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18830: loss = 8.7150 (0.091 sec/step)\n",
            "I1003 01:01:33.713444 139845451286400 learning.py:512] global step 18830: loss = 8.7150 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18831: loss = 3.9007 (0.101 sec/step)\n",
            "I1003 01:01:33.817801 139845451286400 learning.py:512] global step 18831: loss = 3.9007 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18832: loss = 6.2089 (0.111 sec/step)\n",
            "I1003 01:01:33.931417 139845451286400 learning.py:512] global step 18832: loss = 6.2089 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18833: loss = 5.3139 (0.096 sec/step)\n",
            "I1003 01:01:34.029181 139845451286400 learning.py:512] global step 18833: loss = 5.3139 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18834: loss = 2.3749 (0.088 sec/step)\n",
            "I1003 01:01:34.118439 139845451286400 learning.py:512] global step 18834: loss = 2.3749 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18835: loss = 4.7977 (0.097 sec/step)\n",
            "I1003 01:01:34.216542 139845451286400 learning.py:512] global step 18835: loss = 4.7977 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18836: loss = 2.8722 (0.093 sec/step)\n",
            "I1003 01:01:34.311157 139845451286400 learning.py:512] global step 18836: loss = 2.8722 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18837: loss = 4.2601 (0.097 sec/step)\n",
            "I1003 01:01:34.409175 139845451286400 learning.py:512] global step 18837: loss = 4.2601 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18838: loss = 3.1560 (0.088 sec/step)\n",
            "I1003 01:01:34.498195 139845451286400 learning.py:512] global step 18838: loss = 3.1560 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 18839: loss = 3.0542 (0.102 sec/step)\n",
            "I1003 01:01:34.601106 139845451286400 learning.py:512] global step 18839: loss = 3.0542 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18840: loss = 5.6472 (0.098 sec/step)\n",
            "I1003 01:01:34.700469 139845451286400 learning.py:512] global step 18840: loss = 5.6472 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18841: loss = 2.2304 (0.102 sec/step)\n",
            "I1003 01:01:34.803508 139845451286400 learning.py:512] global step 18841: loss = 2.2304 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18842: loss = 2.8188 (0.097 sec/step)\n",
            "I1003 01:01:34.901921 139845451286400 learning.py:512] global step 18842: loss = 2.8188 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18843: loss = 3.5759 (0.119 sec/step)\n",
            "I1003 01:01:35.022273 139845451286400 learning.py:512] global step 18843: loss = 3.5759 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 18844: loss = 3.6174 (0.098 sec/step)\n",
            "I1003 01:01:35.121204 139845451286400 learning.py:512] global step 18844: loss = 3.6174 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18845: loss = 7.3351 (0.103 sec/step)\n",
            "I1003 01:01:35.225790 139845451286400 learning.py:512] global step 18845: loss = 7.3351 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18846: loss = 2.5289 (0.122 sec/step)\n",
            "I1003 01:01:35.349340 139845451286400 learning.py:512] global step 18846: loss = 2.5289 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 18847: loss = 3.0065 (0.114 sec/step)\n",
            "I1003 01:01:35.465371 139845451286400 learning.py:512] global step 18847: loss = 3.0065 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 18848: loss = 3.4895 (0.115 sec/step)\n",
            "I1003 01:01:35.581790 139845451286400 learning.py:512] global step 18848: loss = 3.4895 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18849: loss = 4.3545 (0.107 sec/step)\n",
            "I1003 01:01:35.690100 139845451286400 learning.py:512] global step 18849: loss = 4.3545 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18850: loss = 4.4635 (0.110 sec/step)\n",
            "I1003 01:01:35.801475 139845451286400 learning.py:512] global step 18850: loss = 4.4635 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18851: loss = 2.9129 (0.098 sec/step)\n",
            "I1003 01:01:35.901082 139845451286400 learning.py:512] global step 18851: loss = 2.9129 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18852: loss = 4.5830 (0.105 sec/step)\n",
            "I1003 01:01:36.006935 139845451286400 learning.py:512] global step 18852: loss = 4.5830 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18853: loss = 4.2075 (0.096 sec/step)\n",
            "I1003 01:01:36.104869 139845451286400 learning.py:512] global step 18853: loss = 4.2075 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18854: loss = 3.0520 (0.091 sec/step)\n",
            "I1003 01:01:36.196799 139845451286400 learning.py:512] global step 18854: loss = 3.0520 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18855: loss = 7.1031 (0.093 sec/step)\n",
            "I1003 01:01:36.293452 139845451286400 learning.py:512] global step 18855: loss = 7.1031 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18856: loss = 4.0534 (0.096 sec/step)\n",
            "I1003 01:01:36.390853 139845451286400 learning.py:512] global step 18856: loss = 4.0534 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18857: loss = 7.3521 (0.089 sec/step)\n",
            "I1003 01:01:36.481189 139845451286400 learning.py:512] global step 18857: loss = 7.3521 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18858: loss = 3.0892 (0.100 sec/step)\n",
            "I1003 01:01:36.582591 139845451286400 learning.py:512] global step 18858: loss = 3.0892 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18859: loss = 4.6275 (0.111 sec/step)\n",
            "I1003 01:01:36.695063 139845451286400 learning.py:512] global step 18859: loss = 4.6275 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18860: loss = 6.4455 (0.092 sec/step)\n",
            "I1003 01:01:36.791338 139845451286400 learning.py:512] global step 18860: loss = 6.4455 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18861: loss = 5.6819 (0.110 sec/step)\n",
            "I1003 01:01:36.902471 139845451286400 learning.py:512] global step 18861: loss = 5.6819 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18862: loss = 2.8697 (0.095 sec/step)\n",
            "I1003 01:01:37.000650 139845451286400 learning.py:512] global step 18862: loss = 2.8697 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18863: loss = 2.2672 (0.101 sec/step)\n",
            "I1003 01:01:37.103507 139845451286400 learning.py:512] global step 18863: loss = 2.2672 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18864: loss = 2.5926 (0.090 sec/step)\n",
            "I1003 01:01:37.195192 139845451286400 learning.py:512] global step 18864: loss = 2.5926 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18865: loss = 4.7070 (0.104 sec/step)\n",
            "I1003 01:01:37.300428 139845451286400 learning.py:512] global step 18865: loss = 4.7070 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18866: loss = 5.9570 (0.089 sec/step)\n",
            "I1003 01:01:37.390676 139845451286400 learning.py:512] global step 18866: loss = 5.9570 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18867: loss = 4.9794 (0.095 sec/step)\n",
            "I1003 01:01:37.486674 139845451286400 learning.py:512] global step 18867: loss = 4.9794 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18868: loss = 6.4301 (0.096 sec/step)\n",
            "I1003 01:01:37.584063 139845451286400 learning.py:512] global step 18868: loss = 6.4301 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18869: loss = 6.5684 (0.102 sec/step)\n",
            "I1003 01:01:37.687342 139845451286400 learning.py:512] global step 18869: loss = 6.5684 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18870: loss = 2.1329 (0.110 sec/step)\n",
            "I1003 01:01:37.798393 139845451286400 learning.py:512] global step 18870: loss = 2.1329 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18871: loss = 5.1564 (0.116 sec/step)\n",
            "I1003 01:01:37.916284 139845451286400 learning.py:512] global step 18871: loss = 5.1564 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18872: loss = 4.8723 (0.103 sec/step)\n",
            "I1003 01:01:38.020770 139845451286400 learning.py:512] global step 18872: loss = 4.8723 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18873: loss = 5.2345 (0.097 sec/step)\n",
            "I1003 01:01:38.119403 139845451286400 learning.py:512] global step 18873: loss = 5.2345 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18874: loss = 2.5717 (0.109 sec/step)\n",
            "I1003 01:01:38.229651 139845451286400 learning.py:512] global step 18874: loss = 2.5717 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18875: loss = 3.0342 (0.097 sec/step)\n",
            "I1003 01:01:38.327639 139845451286400 learning.py:512] global step 18875: loss = 3.0342 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18876: loss = 2.7423 (0.101 sec/step)\n",
            "I1003 01:01:38.430010 139845451286400 learning.py:512] global step 18876: loss = 2.7423 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18877: loss = 2.4902 (0.098 sec/step)\n",
            "I1003 01:01:38.529982 139845451286400 learning.py:512] global step 18877: loss = 2.4902 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18878: loss = 2.7496 (0.107 sec/step)\n",
            "I1003 01:01:38.638322 139845451286400 learning.py:512] global step 18878: loss = 2.7496 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18879: loss = 3.6243 (0.118 sec/step)\n",
            "I1003 01:01:38.757944 139845451286400 learning.py:512] global step 18879: loss = 3.6243 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18880: loss = 6.0351 (0.096 sec/step)\n",
            "I1003 01:01:38.855557 139845451286400 learning.py:512] global step 18880: loss = 6.0351 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18881: loss = 5.6630 (0.112 sec/step)\n",
            "I1003 01:01:38.968367 139845451286400 learning.py:512] global step 18881: loss = 5.6630 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18882: loss = 5.1423 (0.095 sec/step)\n",
            "I1003 01:01:39.064460 139845451286400 learning.py:512] global step 18882: loss = 5.1423 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18883: loss = 2.7570 (0.103 sec/step)\n",
            "I1003 01:01:39.169210 139845451286400 learning.py:512] global step 18883: loss = 2.7570 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18884: loss = 3.0532 (0.091 sec/step)\n",
            "I1003 01:01:39.261465 139845451286400 learning.py:512] global step 18884: loss = 3.0532 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18885: loss = 6.9928 (0.086 sec/step)\n",
            "I1003 01:01:39.348542 139845451286400 learning.py:512] global step 18885: loss = 6.9928 (0.086 sec/step)\n",
            "INFO:tensorflow:global step 18886: loss = 4.7238 (0.108 sec/step)\n",
            "I1003 01:01:39.457557 139845451286400 learning.py:512] global step 18886: loss = 4.7238 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18887: loss = 7.5087 (0.103 sec/step)\n",
            "I1003 01:01:39.561558 139845451286400 learning.py:512] global step 18887: loss = 7.5087 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18888: loss = 5.0614 (0.113 sec/step)\n",
            "I1003 01:01:39.676160 139845451286400 learning.py:512] global step 18888: loss = 5.0614 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18889: loss = 5.1695 (0.116 sec/step)\n",
            "I1003 01:01:39.793527 139845451286400 learning.py:512] global step 18889: loss = 5.1695 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18890: loss = 3.1072 (0.116 sec/step)\n",
            "I1003 01:01:39.910640 139845451286400 learning.py:512] global step 18890: loss = 3.1072 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18891: loss = 5.2210 (0.109 sec/step)\n",
            "I1003 01:01:40.021195 139845451286400 learning.py:512] global step 18891: loss = 5.2210 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18892: loss = 2.5152 (0.103 sec/step)\n",
            "I1003 01:01:40.125390 139845451286400 learning.py:512] global step 18892: loss = 2.5152 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18893: loss = 3.0270 (0.104 sec/step)\n",
            "I1003 01:01:40.230797 139845451286400 learning.py:512] global step 18893: loss = 3.0270 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18894: loss = 4.6873 (0.093 sec/step)\n",
            "I1003 01:01:40.325050 139845451286400 learning.py:512] global step 18894: loss = 4.6873 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18895: loss = 4.5897 (0.100 sec/step)\n",
            "I1003 01:01:40.426668 139845451286400 learning.py:512] global step 18895: loss = 4.5897 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18896: loss = 3.6519 (0.092 sec/step)\n",
            "I1003 01:01:40.520406 139845451286400 learning.py:512] global step 18896: loss = 3.6519 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18897: loss = 2.7009 (0.103 sec/step)\n",
            "I1003 01:01:40.625299 139845451286400 learning.py:512] global step 18897: loss = 2.7009 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18898: loss = 2.7347 (0.105 sec/step)\n",
            "I1003 01:01:40.731560 139845451286400 learning.py:512] global step 18898: loss = 2.7347 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18899: loss = 5.5270 (0.104 sec/step)\n",
            "I1003 01:01:40.837163 139845451286400 learning.py:512] global step 18899: loss = 5.5270 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18900: loss = 4.9311 (0.118 sec/step)\n",
            "I1003 01:01:40.957295 139845451286400 learning.py:512] global step 18900: loss = 4.9311 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18901: loss = 2.7532 (0.118 sec/step)\n",
            "I1003 01:01:41.077479 139845451286400 learning.py:512] global step 18901: loss = 2.7532 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18902: loss = 4.5959 (0.098 sec/step)\n",
            "I1003 01:01:41.177498 139845451286400 learning.py:512] global step 18902: loss = 4.5959 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18903: loss = 4.6236 (0.110 sec/step)\n",
            "I1003 01:01:41.288796 139845451286400 learning.py:512] global step 18903: loss = 4.6236 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18904: loss = 2.5789 (0.092 sec/step)\n",
            "I1003 01:01:41.382490 139845451286400 learning.py:512] global step 18904: loss = 2.5789 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18905: loss = 10.5022 (0.097 sec/step)\n",
            "I1003 01:01:41.481664 139845451286400 learning.py:512] global step 18905: loss = 10.5022 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18906: loss = 3.7235 (0.099 sec/step)\n",
            "I1003 01:01:41.581677 139845451286400 learning.py:512] global step 18906: loss = 3.7235 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18907: loss = 4.5594 (0.089 sec/step)\n",
            "I1003 01:01:41.671792 139845451286400 learning.py:512] global step 18907: loss = 4.5594 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 18908: loss = 8.8827 (0.110 sec/step)\n",
            "I1003 01:01:41.783490 139845451286400 learning.py:512] global step 18908: loss = 8.8827 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18909: loss = 3.2658 (0.096 sec/step)\n",
            "I1003 01:01:41.882022 139845451286400 learning.py:512] global step 18909: loss = 3.2658 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18910: loss = 4.5645 (0.106 sec/step)\n",
            "I1003 01:01:41.989207 139845451286400 learning.py:512] global step 18910: loss = 4.5645 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18911: loss = 7.1690 (0.101 sec/step)\n",
            "I1003 01:01:42.091868 139845451286400 learning.py:512] global step 18911: loss = 7.1690 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18912: loss = 4.8297 (0.092 sec/step)\n",
            "I1003 01:01:42.185427 139845451286400 learning.py:512] global step 18912: loss = 4.8297 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 18913: loss = 3.6492 (0.093 sec/step)\n",
            "I1003 01:01:42.279604 139845451286400 learning.py:512] global step 18913: loss = 3.6492 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18914: loss = 4.5051 (0.093 sec/step)\n",
            "I1003 01:01:42.373795 139845451286400 learning.py:512] global step 18914: loss = 4.5051 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18915: loss = 3.1515 (0.103 sec/step)\n",
            "I1003 01:01:42.478051 139845451286400 learning.py:512] global step 18915: loss = 3.1515 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18916: loss = 3.9691 (0.102 sec/step)\n",
            "I1003 01:01:42.581213 139845451286400 learning.py:512] global step 18916: loss = 3.9691 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18917: loss = 7.8968 (0.110 sec/step)\n",
            "I1003 01:01:42.692672 139845451286400 learning.py:512] global step 18917: loss = 7.8968 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18918: loss = 3.9064 (0.112 sec/step)\n",
            "I1003 01:01:42.805771 139845451286400 learning.py:512] global step 18918: loss = 3.9064 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18919: loss = 4.9567 (0.108 sec/step)\n",
            "I1003 01:01:42.915268 139845451286400 learning.py:512] global step 18919: loss = 4.9567 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18920: loss = 4.2902 (0.107 sec/step)\n",
            "I1003 01:01:43.023535 139845451286400 learning.py:512] global step 18920: loss = 4.2902 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18921: loss = 4.1988 (0.090 sec/step)\n",
            "I1003 01:01:43.114728 139845451286400 learning.py:512] global step 18921: loss = 4.1988 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18922: loss = 4.0198 (0.093 sec/step)\n",
            "I1003 01:01:43.209231 139845451286400 learning.py:512] global step 18922: loss = 4.0198 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18923: loss = 6.1512 (0.097 sec/step)\n",
            "I1003 01:01:43.307956 139845451286400 learning.py:512] global step 18923: loss = 6.1512 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18924: loss = 4.9012 (0.100 sec/step)\n",
            "I1003 01:01:43.409618 139845451286400 learning.py:512] global step 18924: loss = 4.9012 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18925: loss = 7.3963 (0.095 sec/step)\n",
            "I1003 01:01:43.506000 139845451286400 learning.py:512] global step 18925: loss = 7.3963 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18926: loss = 3.3928 (0.096 sec/step)\n",
            "I1003 01:01:43.602928 139845451286400 learning.py:512] global step 18926: loss = 3.3928 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18927: loss = 5.1451 (0.098 sec/step)\n",
            "I1003 01:01:43.702035 139845451286400 learning.py:512] global step 18927: loss = 5.1451 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18928: loss = 4.0412 (0.102 sec/step)\n",
            "I1003 01:01:43.805317 139845451286400 learning.py:512] global step 18928: loss = 4.0412 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18929: loss = 3.0230 (0.100 sec/step)\n",
            "I1003 01:01:43.906298 139845451286400 learning.py:512] global step 18929: loss = 3.0230 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18930: loss = 3.1105 (0.112 sec/step)\n",
            "I1003 01:01:44.019621 139845451286400 learning.py:512] global step 18930: loss = 3.1105 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 18931: loss = 6.8503 (0.108 sec/step)\n",
            "I1003 01:01:44.128602 139845451286400 learning.py:512] global step 18931: loss = 6.8503 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18932: loss = 9.5672 (0.097 sec/step)\n",
            "I1003 01:01:44.227374 139845451286400 learning.py:512] global step 18932: loss = 9.5672 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18933: loss = 2.5765 (0.098 sec/step)\n",
            "I1003 01:01:44.326674 139845451286400 learning.py:512] global step 18933: loss = 2.5765 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18934: loss = 3.4341 (0.108 sec/step)\n",
            "I1003 01:01:44.436552 139845451286400 learning.py:512] global step 18934: loss = 3.4341 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18935: loss = 4.7150 (0.109 sec/step)\n",
            "I1003 01:01:44.547108 139845451286400 learning.py:512] global step 18935: loss = 4.7150 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18936: loss = 2.8846 (0.106 sec/step)\n",
            "I1003 01:01:44.654605 139845451286400 learning.py:512] global step 18936: loss = 2.8846 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18937: loss = 4.7268 (0.096 sec/step)\n",
            "I1003 01:01:44.751509 139845451286400 learning.py:512] global step 18937: loss = 4.7268 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18938: loss = 7.0769 (0.109 sec/step)\n",
            "I1003 01:01:44.862115 139845451286400 learning.py:512] global step 18938: loss = 7.0769 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 18939: loss = 3.7990 (0.100 sec/step)\n",
            "I1003 01:01:44.963686 139845451286400 learning.py:512] global step 18939: loss = 3.7990 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18940: loss = 3.4279 (0.110 sec/step)\n",
            "I1003 01:01:45.074806 139845451286400 learning.py:512] global step 18940: loss = 3.4279 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18941: loss = 2.2534 (0.100 sec/step)\n",
            "I1003 01:01:45.176427 139845451286400 learning.py:512] global step 18941: loss = 2.2534 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18942: loss = 6.2719 (0.095 sec/step)\n",
            "I1003 01:01:45.273176 139845451286400 learning.py:512] global step 18942: loss = 6.2719 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18943: loss = 4.1721 (0.095 sec/step)\n",
            "I1003 01:01:45.369853 139845451286400 learning.py:512] global step 18943: loss = 4.1721 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18944: loss = 3.8741 (0.097 sec/step)\n",
            "I1003 01:01:45.468117 139845451286400 learning.py:512] global step 18944: loss = 3.8741 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 18945: loss = 8.2984 (0.110 sec/step)\n",
            "I1003 01:01:45.579608 139845451286400 learning.py:512] global step 18945: loss = 8.2984 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18946: loss = 3.5388 (0.113 sec/step)\n",
            "I1003 01:01:45.694746 139845451286400 learning.py:512] global step 18946: loss = 3.5388 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18947: loss = 4.2824 (0.102 sec/step)\n",
            "I1003 01:01:45.798017 139845451286400 learning.py:512] global step 18947: loss = 4.2824 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18948: loss = 2.6423 (0.101 sec/step)\n",
            "I1003 01:01:45.900072 139845451286400 learning.py:512] global step 18948: loss = 2.6423 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18949: loss = 2.0851 (0.100 sec/step)\n",
            "I1003 01:01:46.002100 139845451286400 learning.py:512] global step 18949: loss = 2.0851 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18950: loss = 5.9191 (0.103 sec/step)\n",
            "I1003 01:01:46.106203 139845451286400 learning.py:512] global step 18950: loss = 5.9191 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18951: loss = 3.3411 (0.100 sec/step)\n",
            "I1003 01:01:46.208065 139845451286400 learning.py:512] global step 18951: loss = 3.3411 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18952: loss = 3.2049 (0.091 sec/step)\n",
            "I1003 01:01:46.300743 139845451286400 learning.py:512] global step 18952: loss = 3.2049 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18953: loss = 8.0180 (0.107 sec/step)\n",
            "I1003 01:01:46.409174 139845451286400 learning.py:512] global step 18953: loss = 8.0180 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 18954: loss = 3.2871 (0.108 sec/step)\n",
            "I1003 01:01:46.519427 139845451286400 learning.py:512] global step 18954: loss = 3.2871 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18955: loss = 3.8653 (0.105 sec/step)\n",
            "I1003 01:01:46.626005 139845451286400 learning.py:512] global step 18955: loss = 3.8653 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18956: loss = 3.3683 (0.103 sec/step)\n",
            "I1003 01:01:46.729981 139845451286400 learning.py:512] global step 18956: loss = 3.3683 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 18957: loss = 3.0119 (0.110 sec/step)\n",
            "I1003 01:01:46.840908 139845451286400 learning.py:512] global step 18957: loss = 3.0119 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 18958: loss = 3.9430 (0.094 sec/step)\n",
            "I1003 01:01:46.936112 139845451286400 learning.py:512] global step 18958: loss = 3.9430 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18959: loss = 2.5403 (0.111 sec/step)\n",
            "I1003 01:01:47.048917 139845451286400 learning.py:512] global step 18959: loss = 2.5403 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 18960: loss = 2.6823 (0.115 sec/step)\n",
            "I1003 01:01:47.165571 139845451286400 learning.py:512] global step 18960: loss = 2.6823 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 18961: loss = 3.3639 (0.105 sec/step)\n",
            "I1003 01:01:47.272238 139845451286400 learning.py:512] global step 18961: loss = 3.3639 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18962: loss = 2.7091 (0.101 sec/step)\n",
            "I1003 01:01:47.374680 139845451286400 learning.py:512] global step 18962: loss = 2.7091 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 18963: loss = 4.1427 (0.106 sec/step)\n",
            "I1003 01:01:47.481877 139845451286400 learning.py:512] global step 18963: loss = 4.1427 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18964: loss = 1.8837 (0.094 sec/step)\n",
            "I1003 01:01:47.577152 139845451286400 learning.py:512] global step 18964: loss = 1.8837 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18965: loss = 4.0301 (0.104 sec/step)\n",
            "I1003 01:01:47.682263 139845451286400 learning.py:512] global step 18965: loss = 4.0301 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18966: loss = 2.3414 (0.106 sec/step)\n",
            "I1003 01:01:47.789458 139845451286400 learning.py:512] global step 18966: loss = 2.3414 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18967: loss = 5.1467 (0.102 sec/step)\n",
            "I1003 01:01:47.893162 139845451286400 learning.py:512] global step 18967: loss = 5.1467 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 18968: loss = 3.3555 (0.090 sec/step)\n",
            "I1003 01:01:47.984055 139845451286400 learning.py:512] global step 18968: loss = 3.3555 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18969: loss = 2.9154 (0.118 sec/step)\n",
            "I1003 01:01:48.103125 139845451286400 learning.py:512] global step 18969: loss = 2.9154 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18970: loss = 2.4319 (0.096 sec/step)\n",
            "I1003 01:01:48.200467 139845451286400 learning.py:512] global step 18970: loss = 2.4319 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18971: loss = 2.8325 (0.098 sec/step)\n",
            "I1003 01:01:48.299513 139845451286400 learning.py:512] global step 18971: loss = 2.8325 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 18972: loss = 4.4861 (0.094 sec/step)\n",
            "I1003 01:01:48.394452 139845451286400 learning.py:512] global step 18972: loss = 4.4861 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 18973: loss = 5.0824 (0.105 sec/step)\n",
            "I1003 01:01:48.500766 139845451286400 learning.py:512] global step 18973: loss = 5.0824 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18974: loss = 5.4423 (0.096 sec/step)\n",
            "I1003 01:01:48.597970 139845451286400 learning.py:512] global step 18974: loss = 5.4423 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 18975: loss = 2.6954 (0.100 sec/step)\n",
            "I1003 01:01:48.699770 139845451286400 learning.py:512] global step 18975: loss = 2.6954 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18976: loss = 3.9800 (0.095 sec/step)\n",
            "I1003 01:01:48.795936 139845451286400 learning.py:512] global step 18976: loss = 3.9800 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 18977: loss = 4.1993 (0.104 sec/step)\n",
            "I1003 01:01:48.900879 139845451286400 learning.py:512] global step 18977: loss = 4.1993 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 18978: loss = 1.7811 (0.108 sec/step)\n",
            "I1003 01:01:49.010023 139845451286400 learning.py:512] global step 18978: loss = 1.7811 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 18979: loss = 4.5721 (0.105 sec/step)\n",
            "I1003 01:01:49.116200 139845451286400 learning.py:512] global step 18979: loss = 4.5721 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18980: loss = 2.5222 (0.093 sec/step)\n",
            "I1003 01:01:49.210901 139845451286400 learning.py:512] global step 18980: loss = 2.5222 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18981: loss = 2.5607 (0.090 sec/step)\n",
            "I1003 01:01:49.302237 139845451286400 learning.py:512] global step 18981: loss = 2.5607 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 18982: loss = 5.2412 (0.105 sec/step)\n",
            "I1003 01:01:49.408668 139845451286400 learning.py:512] global step 18982: loss = 5.2412 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18983: loss = 5.0434 (0.091 sec/step)\n",
            "I1003 01:01:49.501224 139845451286400 learning.py:512] global step 18983: loss = 5.0434 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 18984: loss = 3.0832 (0.087 sec/step)\n",
            "I1003 01:01:49.589989 139845451286400 learning.py:512] global step 18984: loss = 3.0832 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 18985: loss = 3.2573 (0.099 sec/step)\n",
            "I1003 01:01:49.690662 139845451286400 learning.py:512] global step 18985: loss = 3.2573 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18986: loss = 3.8744 (0.093 sec/step)\n",
            "I1003 01:01:49.785196 139845451286400 learning.py:512] global step 18986: loss = 3.8744 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 18987: loss = 2.2795 (0.106 sec/step)\n",
            "I1003 01:01:49.892603 139845451286400 learning.py:512] global step 18987: loss = 2.2795 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18988: loss = 2.3622 (0.105 sec/step)\n",
            "I1003 01:01:49.998975 139845451286400 learning.py:512] global step 18988: loss = 2.3622 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 18989: loss = 3.6025 (0.113 sec/step)\n",
            "I1003 01:01:50.112939 139845451286400 learning.py:512] global step 18989: loss = 3.6025 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18990: loss = 4.9436 (0.117 sec/step)\n",
            "I1003 01:01:50.231655 139845451286400 learning.py:512] global step 18990: loss = 4.9436 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 18991: loss = 6.6511 (0.127 sec/step)\n",
            "I1003 01:01:50.359946 139845451286400 learning.py:512] global step 18991: loss = 6.6511 (0.127 sec/step)\n",
            "INFO:tensorflow:global step 18992: loss = 5.4224 (0.116 sec/step)\n",
            "I1003 01:01:50.477633 139845451286400 learning.py:512] global step 18992: loss = 5.4224 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18993: loss = 2.6451 (0.118 sec/step)\n",
            "I1003 01:01:50.596852 139845451286400 learning.py:512] global step 18993: loss = 2.6451 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 18994: loss = 2.8139 (0.116 sec/step)\n",
            "I1003 01:01:50.714316 139845451286400 learning.py:512] global step 18994: loss = 2.8139 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 18995: loss = 4.3431 (0.100 sec/step)\n",
            "I1003 01:01:50.816031 139845451286400 learning.py:512] global step 18995: loss = 4.3431 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 18996: loss = 4.0461 (0.106 sec/step)\n",
            "I1003 01:01:50.923361 139845451286400 learning.py:512] global step 18996: loss = 4.0461 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 18997: loss = 2.1287 (0.099 sec/step)\n",
            "I1003 01:01:51.023681 139845451286400 learning.py:512] global step 18997: loss = 2.1287 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 18998: loss = 2.9634 (0.113 sec/step)\n",
            "I1003 01:01:51.138173 139845451286400 learning.py:512] global step 18998: loss = 2.9634 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 18999: loss = 2.2451 (0.088 sec/step)\n",
            "I1003 01:01:51.227418 139845451286400 learning.py:512] global step 18999: loss = 2.2451 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19000: loss = 2.5739 (0.106 sec/step)\n",
            "I1003 01:01:51.334735 139845451286400 learning.py:512] global step 19000: loss = 2.5739 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19001: loss = 5.3385 (0.096 sec/step)\n",
            "I1003 01:01:51.431928 139845451286400 learning.py:512] global step 19001: loss = 5.3385 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19002: loss = 2.9200 (0.099 sec/step)\n",
            "I1003 01:01:51.532439 139845451286400 learning.py:512] global step 19002: loss = 2.9200 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19003: loss = 3.0838 (0.108 sec/step)\n",
            "I1003 01:01:51.641784 139845451286400 learning.py:512] global step 19003: loss = 3.0838 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19004: loss = 4.1921 (0.104 sec/step)\n",
            "I1003 01:01:51.747574 139845451286400 learning.py:512] global step 19004: loss = 4.1921 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19005: loss = 5.2165 (0.102 sec/step)\n",
            "I1003 01:01:51.851312 139845451286400 learning.py:512] global step 19005: loss = 5.2165 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19006: loss = 3.1015 (0.099 sec/step)\n",
            "I1003 01:01:51.952097 139845451286400 learning.py:512] global step 19006: loss = 3.1015 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19007: loss = 3.7802 (0.106 sec/step)\n",
            "I1003 01:01:52.060140 139845451286400 learning.py:512] global step 19007: loss = 3.7802 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19008: loss = 4.2916 (0.105 sec/step)\n",
            "I1003 01:01:52.166801 139845451286400 learning.py:512] global step 19008: loss = 4.2916 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19009: loss = 9.0376 (0.102 sec/step)\n",
            "I1003 01:01:52.270518 139845451286400 learning.py:512] global step 19009: loss = 9.0376 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19010: loss = 2.2031 (0.099 sec/step)\n",
            "I1003 01:01:52.371297 139845451286400 learning.py:512] global step 19010: loss = 2.2031 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19011: loss = 4.3502 (0.107 sec/step)\n",
            "I1003 01:01:52.479449 139845451286400 learning.py:512] global step 19011: loss = 4.3502 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19012: loss = 7.4783 (0.097 sec/step)\n",
            "I1003 01:01:52.578353 139845451286400 learning.py:512] global step 19012: loss = 7.4783 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19013: loss = 2.2683 (0.108 sec/step)\n",
            "I1003 01:01:52.688112 139845451286400 learning.py:512] global step 19013: loss = 2.2683 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19014: loss = 4.3408 (0.098 sec/step)\n",
            "I1003 01:01:52.787704 139845451286400 learning.py:512] global step 19014: loss = 4.3408 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19015: loss = 2.6201 (0.091 sec/step)\n",
            "I1003 01:01:52.879749 139845451286400 learning.py:512] global step 19015: loss = 2.6201 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19016: loss = 2.5515 (0.105 sec/step)\n",
            "I1003 01:01:52.985838 139845451286400 learning.py:512] global step 19016: loss = 2.5515 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19017: loss = 2.1589 (0.105 sec/step)\n",
            "I1003 01:01:53.093325 139845451286400 learning.py:512] global step 19017: loss = 2.1589 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19018: loss = 3.1025 (0.102 sec/step)\n",
            "I1003 01:01:53.197869 139845451286400 learning.py:512] global step 19018: loss = 3.1025 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19019: loss = 3.3558 (0.102 sec/step)\n",
            "I1003 01:01:53.301050 139845451286400 learning.py:512] global step 19019: loss = 3.3558 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19020: loss = 4.2862 (0.100 sec/step)\n",
            "I1003 01:01:53.402149 139845451286400 learning.py:512] global step 19020: loss = 4.2862 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19021: loss = 2.3783 (0.093 sec/step)\n",
            "I1003 01:01:53.496858 139845451286400 learning.py:512] global step 19021: loss = 2.3783 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19022: loss = 4.4134 (0.088 sec/step)\n",
            "I1003 01:01:53.586150 139845451286400 learning.py:512] global step 19022: loss = 4.4134 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19023: loss = 4.7023 (0.098 sec/step)\n",
            "I1003 01:01:53.686394 139845451286400 learning.py:512] global step 19023: loss = 4.7023 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19024: loss = 4.1182 (0.102 sec/step)\n",
            "I1003 01:01:53.790142 139845451286400 learning.py:512] global step 19024: loss = 4.1182 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19025: loss = 6.9224 (0.102 sec/step)\n",
            "I1003 01:01:53.893002 139845451286400 learning.py:512] global step 19025: loss = 6.9224 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19026: loss = 4.5268 (0.114 sec/step)\n",
            "I1003 01:01:54.008624 139845451286400 learning.py:512] global step 19026: loss = 4.5268 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19027: loss = 5.2748 (0.104 sec/step)\n",
            "I1003 01:01:54.114380 139845451286400 learning.py:512] global step 19027: loss = 5.2748 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19028: loss = 8.1183 (0.100 sec/step)\n",
            "I1003 01:01:54.215978 139845451286400 learning.py:512] global step 19028: loss = 8.1183 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19029: loss = 3.1009 (0.119 sec/step)\n",
            "I1003 01:01:54.336471 139845451286400 learning.py:512] global step 19029: loss = 3.1009 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 19030: loss = 4.2461 (0.108 sec/step)\n",
            "I1003 01:01:54.445831 139845451286400 learning.py:512] global step 19030: loss = 4.2461 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19031: loss = 2.4170 (0.125 sec/step)\n",
            "I1003 01:01:54.572576 139845451286400 learning.py:512] global step 19031: loss = 2.4170 (0.125 sec/step)\n",
            "INFO:tensorflow:global step 19032: loss = 1.9683 (0.116 sec/step)\n",
            "I1003 01:01:54.691232 139845451286400 learning.py:512] global step 19032: loss = 1.9683 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 19033: loss = 3.9310 (0.105 sec/step)\n",
            "I1003 01:01:54.799599 139845451286400 learning.py:512] global step 19033: loss = 3.9310 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19034: loss = 3.4626 (0.087 sec/step)\n",
            "I1003 01:01:54.888144 139845451286400 learning.py:512] global step 19034: loss = 3.4626 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 19035: loss = 2.6130 (0.108 sec/step)\n",
            "I1003 01:01:54.997657 139845451286400 learning.py:512] global step 19035: loss = 2.6130 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19036: loss = 4.4713 (0.130 sec/step)\n",
            "I1003 01:01:55.129419 139845451286400 learning.py:512] global step 19036: loss = 4.4713 (0.130 sec/step)\n",
            "INFO:tensorflow:global step 19037: loss = 2.6842 (0.099 sec/step)\n",
            "I1003 01:01:55.229558 139845451286400 learning.py:512] global step 19037: loss = 2.6842 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19038: loss = 6.1032 (0.101 sec/step)\n",
            "I1003 01:01:55.331624 139845451286400 learning.py:512] global step 19038: loss = 6.1032 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19039: loss = 1.7381 (0.100 sec/step)\n",
            "I1003 01:01:55.432719 139845451286400 learning.py:512] global step 19039: loss = 1.7381 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19040: loss = 3.1971 (0.101 sec/step)\n",
            "I1003 01:01:55.535793 139845451286400 learning.py:512] global step 19040: loss = 3.1971 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19041: loss = 6.2882 (0.096 sec/step)\n",
            "I1003 01:01:55.633363 139845451286400 learning.py:512] global step 19041: loss = 6.2882 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19042: loss = 5.6507 (0.108 sec/step)\n",
            "I1003 01:01:55.742633 139845451286400 learning.py:512] global step 19042: loss = 5.6507 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19043: loss = 3.7122 (0.106 sec/step)\n",
            "I1003 01:01:55.849828 139845451286400 learning.py:512] global step 19043: loss = 3.7122 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19044: loss = 6.3608 (0.094 sec/step)\n",
            "I1003 01:01:55.945172 139845451286400 learning.py:512] global step 19044: loss = 6.3608 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19045: loss = 2.2137 (0.117 sec/step)\n",
            "I1003 01:01:56.063556 139845451286400 learning.py:512] global step 19045: loss = 2.2137 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19046: loss = 7.3736 (0.106 sec/step)\n",
            "I1003 01:01:56.170715 139845451286400 learning.py:512] global step 19046: loss = 7.3736 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19047: loss = 3.1119 (0.120 sec/step)\n",
            "I1003 01:01:56.292273 139845451286400 learning.py:512] global step 19047: loss = 3.1119 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19048: loss = 3.0736 (0.112 sec/step)\n",
            "I1003 01:01:56.405599 139845451286400 learning.py:512] global step 19048: loss = 3.0736 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19049: loss = 2.6845 (0.117 sec/step)\n",
            "I1003 01:01:56.524297 139845451286400 learning.py:512] global step 19049: loss = 2.6845 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19050: loss = 5.5472 (0.116 sec/step)\n",
            "I1003 01:01:56.641551 139845451286400 learning.py:512] global step 19050: loss = 5.5472 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 19051: loss = 4.5930 (0.119 sec/step)\n",
            "I1003 01:01:56.762501 139845451286400 learning.py:512] global step 19051: loss = 4.5930 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 19052: loss = 6.0390 (0.117 sec/step)\n",
            "I1003 01:01:56.881336 139845451286400 learning.py:512] global step 19052: loss = 6.0390 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19053: loss = 8.8914 (0.108 sec/step)\n",
            "I1003 01:01:56.991010 139845451286400 learning.py:512] global step 19053: loss = 8.8914 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19054: loss = 3.5510 (0.129 sec/step)\n",
            "I1003 01:01:57.122063 139845451286400 learning.py:512] global step 19054: loss = 3.5510 (0.129 sec/step)\n",
            "INFO:tensorflow:global step 19055: loss = 3.8822 (0.128 sec/step)\n",
            "I1003 01:01:57.251966 139845451286400 learning.py:512] global step 19055: loss = 3.8822 (0.128 sec/step)\n",
            "INFO:tensorflow:global step 19056: loss = 4.8318 (0.105 sec/step)\n",
            "I1003 01:01:57.358554 139845451286400 learning.py:512] global step 19056: loss = 4.8318 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19057: loss = 3.8926 (0.107 sec/step)\n",
            "I1003 01:01:57.466661 139845451286400 learning.py:512] global step 19057: loss = 3.8926 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19058: loss = 3.3811 (0.122 sec/step)\n",
            "I1003 01:01:57.589962 139845451286400 learning.py:512] global step 19058: loss = 3.3811 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19059: loss = 4.0755 (0.112 sec/step)\n",
            "I1003 01:01:57.703567 139845451286400 learning.py:512] global step 19059: loss = 4.0755 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19060: loss = 3.3096 (0.093 sec/step)\n",
            "I1003 01:01:57.798090 139845451286400 learning.py:512] global step 19060: loss = 3.3096 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19061: loss = 3.2091 (0.100 sec/step)\n",
            "I1003 01:01:57.899931 139845451286400 learning.py:512] global step 19061: loss = 3.2091 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19062: loss = 5.2228 (0.095 sec/step)\n",
            "I1003 01:01:57.996729 139845451286400 learning.py:512] global step 19062: loss = 5.2228 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19063: loss = 2.9089 (0.117 sec/step)\n",
            "I1003 01:01:58.114854 139845451286400 learning.py:512] global step 19063: loss = 2.9089 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19064: loss = 2.1342 (0.111 sec/step)\n",
            "I1003 01:01:58.227694 139845451286400 learning.py:512] global step 19064: loss = 2.1342 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19065: loss = 4.2462 (0.106 sec/step)\n",
            "I1003 01:01:58.335324 139845451286400 learning.py:512] global step 19065: loss = 4.2462 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19066: loss = 7.5554 (0.102 sec/step)\n",
            "I1003 01:01:58.438827 139845451286400 learning.py:512] global step 19066: loss = 7.5554 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19067: loss = 3.7561 (0.093 sec/step)\n",
            "I1003 01:01:58.533447 139845451286400 learning.py:512] global step 19067: loss = 3.7561 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19068: loss = 3.6062 (0.103 sec/step)\n",
            "I1003 01:01:58.638211 139845451286400 learning.py:512] global step 19068: loss = 3.6062 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19069: loss = 3.0926 (0.102 sec/step)\n",
            "I1003 01:01:58.741112 139845451286400 learning.py:512] global step 19069: loss = 3.0926 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19070: loss = 3.0785 (0.097 sec/step)\n",
            "I1003 01:01:58.839668 139845451286400 learning.py:512] global step 19070: loss = 3.0785 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19071: loss = 4.8581 (0.097 sec/step)\n",
            "I1003 01:01:58.937942 139845451286400 learning.py:512] global step 19071: loss = 4.8581 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19072: loss = 8.4859 (0.108 sec/step)\n",
            "I1003 01:01:59.048030 139845451286400 learning.py:512] global step 19072: loss = 8.4859 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19073: loss = 3.1093 (0.101 sec/step)\n",
            "I1003 01:01:59.150060 139845451286400 learning.py:512] global step 19073: loss = 3.1093 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19074: loss = 4.4330 (0.092 sec/step)\n",
            "I1003 01:01:59.243424 139845451286400 learning.py:512] global step 19074: loss = 4.4330 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19075: loss = 3.6157 (0.097 sec/step)\n",
            "I1003 01:01:59.341964 139845451286400 learning.py:512] global step 19075: loss = 3.6157 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19076: loss = 3.2370 (0.093 sec/step)\n",
            "I1003 01:01:59.436142 139845451286400 learning.py:512] global step 19076: loss = 3.2370 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19077: loss = 3.8274 (0.102 sec/step)\n",
            "I1003 01:01:59.539476 139845451286400 learning.py:512] global step 19077: loss = 3.8274 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19078: loss = 4.7734 (0.104 sec/step)\n",
            "I1003 01:01:59.644790 139845451286400 learning.py:512] global step 19078: loss = 4.7734 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19079: loss = 6.4620 (0.088 sec/step)\n",
            "I1003 01:01:59.734571 139845451286400 learning.py:512] global step 19079: loss = 6.4620 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19080: loss = 4.8140 (0.107 sec/step)\n",
            "I1003 01:01:59.843366 139845451286400 learning.py:512] global step 19080: loss = 4.8140 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19081: loss = 2.8571 (0.099 sec/step)\n",
            "I1003 01:01:59.943264 139845451286400 learning.py:512] global step 19081: loss = 2.8571 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19082: loss = 7.4892 (0.097 sec/step)\n",
            "I1003 01:02:00.041158 139845451286400 learning.py:512] global step 19082: loss = 7.4892 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19083: loss = 6.0072 (0.112 sec/step)\n",
            "I1003 01:02:00.154082 139845451286400 learning.py:512] global step 19083: loss = 6.0072 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19084: loss = 5.9217 (0.109 sec/step)\n",
            "I1003 01:02:00.264921 139845451286400 learning.py:512] global step 19084: loss = 5.9217 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19085: loss = 4.9544 (0.092 sec/step)\n",
            "I1003 01:02:00.358682 139845451286400 learning.py:512] global step 19085: loss = 4.9544 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19086: loss = 2.9950 (0.107 sec/step)\n",
            "I1003 01:02:00.466941 139845451286400 learning.py:512] global step 19086: loss = 2.9950 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19087: loss = 3.4911 (0.099 sec/step)\n",
            "I1003 01:02:00.567066 139845451286400 learning.py:512] global step 19087: loss = 3.4911 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19088: loss = 4.6729 (0.099 sec/step)\n",
            "I1003 01:02:00.667704 139845451286400 learning.py:512] global step 19088: loss = 4.6729 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19089: loss = 2.5478 (0.101 sec/step)\n",
            "I1003 01:02:00.769797 139845451286400 learning.py:512] global step 19089: loss = 2.5478 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19090: loss = 3.4961 (0.096 sec/step)\n",
            "I1003 01:02:00.867474 139845451286400 learning.py:512] global step 19090: loss = 3.4961 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19091: loss = 2.6253 (0.102 sec/step)\n",
            "I1003 01:02:00.970877 139845451286400 learning.py:512] global step 19091: loss = 2.6253 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19092: loss = 3.5298 (0.125 sec/step)\n",
            "I1003 01:02:01.097759 139845451286400 learning.py:512] global step 19092: loss = 3.5298 (0.125 sec/step)\n",
            "INFO:tensorflow:global step 19093: loss = 4.0608 (0.094 sec/step)\n",
            "I1003 01:02:01.193441 139845451286400 learning.py:512] global step 19093: loss = 4.0608 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19094: loss = 5.5366 (0.110 sec/step)\n",
            "I1003 01:02:01.304732 139845451286400 learning.py:512] global step 19094: loss = 5.5366 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19095: loss = 4.1091 (0.105 sec/step)\n",
            "I1003 01:02:01.411169 139845451286400 learning.py:512] global step 19095: loss = 4.1091 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19096: loss = 5.1050 (0.089 sec/step)\n",
            "I1003 01:02:01.502167 139845451286400 learning.py:512] global step 19096: loss = 5.1050 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 19097: loss = 3.7146 (0.096 sec/step)\n",
            "I1003 01:02:01.599229 139845451286400 learning.py:512] global step 19097: loss = 3.7146 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19098: loss = 2.7296 (0.093 sec/step)\n",
            "I1003 01:02:01.693742 139845451286400 learning.py:512] global step 19098: loss = 2.7296 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19099: loss = 2.9942 (0.100 sec/step)\n",
            "I1003 01:02:01.795410 139845451286400 learning.py:512] global step 19099: loss = 2.9942 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19100: loss = 3.7441 (0.100 sec/step)\n",
            "I1003 01:02:01.896657 139845451286400 learning.py:512] global step 19100: loss = 3.7441 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19101: loss = 2.7397 (0.102 sec/step)\n",
            "I1003 01:02:01.999869 139845451286400 learning.py:512] global step 19101: loss = 2.7397 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19102: loss = 2.0829 (0.095 sec/step)\n",
            "I1003 01:02:02.095991 139845451286400 learning.py:512] global step 19102: loss = 2.0829 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19103: loss = 5.0956 (0.110 sec/step)\n",
            "I1003 01:02:02.207506 139845451286400 learning.py:512] global step 19103: loss = 5.0956 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19104: loss = 4.0171 (0.100 sec/step)\n",
            "I1003 01:02:02.309802 139845451286400 learning.py:512] global step 19104: loss = 4.0171 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19105: loss = 2.4395 (0.098 sec/step)\n",
            "I1003 01:02:02.409165 139845451286400 learning.py:512] global step 19105: loss = 2.4395 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19106: loss = 3.0814 (0.097 sec/step)\n",
            "I1003 01:02:02.508021 139845451286400 learning.py:512] global step 19106: loss = 3.0814 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19107: loss = 1.7623 (0.093 sec/step)\n",
            "I1003 01:02:02.602562 139845451286400 learning.py:512] global step 19107: loss = 1.7623 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19108: loss = 3.7591 (0.097 sec/step)\n",
            "I1003 01:02:02.701048 139845451286400 learning.py:512] global step 19108: loss = 3.7591 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19109: loss = 1.9089 (0.100 sec/step)\n",
            "I1003 01:02:02.802734 139845451286400 learning.py:512] global step 19109: loss = 1.9089 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19110: loss = 3.2439 (0.102 sec/step)\n",
            "I1003 01:02:02.905892 139845451286400 learning.py:512] global step 19110: loss = 3.2439 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19111: loss = 3.7179 (0.099 sec/step)\n",
            "I1003 01:02:03.006017 139845451286400 learning.py:512] global step 19111: loss = 3.7179 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19112: loss = 5.5367 (0.093 sec/step)\n",
            "I1003 01:02:03.100442 139845451286400 learning.py:512] global step 19112: loss = 5.5367 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19113: loss = 3.5987 (0.099 sec/step)\n",
            "I1003 01:02:03.200848 139845451286400 learning.py:512] global step 19113: loss = 3.5987 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19114: loss = 3.4169 (0.108 sec/step)\n",
            "I1003 01:02:03.310388 139845451286400 learning.py:512] global step 19114: loss = 3.4169 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19115: loss = 2.7229 (0.099 sec/step)\n",
            "I1003 01:02:03.411013 139845451286400 learning.py:512] global step 19115: loss = 2.7229 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19116: loss = 6.5476 (0.096 sec/step)\n",
            "I1003 01:02:03.508504 139845451286400 learning.py:512] global step 19116: loss = 6.5476 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19117: loss = 3.2042 (0.107 sec/step)\n",
            "I1003 01:02:03.617131 139845451286400 learning.py:512] global step 19117: loss = 3.2042 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19118: loss = 2.1762 (0.092 sec/step)\n",
            "I1003 01:02:03.711042 139845451286400 learning.py:512] global step 19118: loss = 2.1762 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19119: loss = 6.8538 (0.092 sec/step)\n",
            "I1003 01:02:03.804575 139845451286400 learning.py:512] global step 19119: loss = 6.8538 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19120: loss = 3.7834 (0.093 sec/step)\n",
            "I1003 01:02:03.898794 139845451286400 learning.py:512] global step 19120: loss = 3.7834 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19121: loss = 3.8338 (0.095 sec/step)\n",
            "I1003 01:02:03.994935 139845451286400 learning.py:512] global step 19121: loss = 3.8338 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19122: loss = 2.3933 (0.121 sec/step)\n",
            "I1003 01:02:04.117014 139845451286400 learning.py:512] global step 19122: loss = 2.3933 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19123: loss = 2.7652 (0.097 sec/step)\n",
            "I1003 01:02:04.215070 139845451286400 learning.py:512] global step 19123: loss = 2.7652 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19124: loss = 2.4880 (0.115 sec/step)\n",
            "I1003 01:02:04.331612 139845451286400 learning.py:512] global step 19124: loss = 2.4880 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19125: loss = 9.3997 (0.091 sec/step)\n",
            "I1003 01:02:04.424048 139845451286400 learning.py:512] global step 19125: loss = 9.3997 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19126: loss = 4.7061 (0.095 sec/step)\n",
            "I1003 01:02:04.520584 139845451286400 learning.py:512] global step 19126: loss = 4.7061 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19127: loss = 6.5617 (0.103 sec/step)\n",
            "I1003 01:02:04.625188 139845451286400 learning.py:512] global step 19127: loss = 6.5617 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19128: loss = 2.3275 (0.115 sec/step)\n",
            "I1003 01:02:04.741849 139845451286400 learning.py:512] global step 19128: loss = 2.3275 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19129: loss = 4.0438 (0.106 sec/step)\n",
            "I1003 01:02:04.849448 139845451286400 learning.py:512] global step 19129: loss = 4.0438 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19130: loss = 2.5942 (0.087 sec/step)\n",
            "I1003 01:02:04.937967 139845451286400 learning.py:512] global step 19130: loss = 2.5942 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 19131: loss = 3.7272 (0.121 sec/step)\n",
            "I1003 01:02:05.060454 139845451286400 learning.py:512] global step 19131: loss = 3.7272 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19132: loss = 3.3914 (0.102 sec/step)\n",
            "I1003 01:02:05.163792 139845451286400 learning.py:512] global step 19132: loss = 3.3914 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19133: loss = 1.6800 (0.120 sec/step)\n",
            "I1003 01:02:05.285419 139845451286400 learning.py:512] global step 19133: loss = 1.6800 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19134: loss = 4.0581 (0.098 sec/step)\n",
            "I1003 01:02:05.385150 139845451286400 learning.py:512] global step 19134: loss = 4.0581 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19135: loss = 6.0560 (0.101 sec/step)\n",
            "I1003 01:02:05.487273 139845451286400 learning.py:512] global step 19135: loss = 6.0560 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19136: loss = 1.8151 (0.091 sec/step)\n",
            "I1003 01:02:05.580321 139845451286400 learning.py:512] global step 19136: loss = 1.8151 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19137: loss = 3.7706 (0.096 sec/step)\n",
            "I1003 01:02:05.677592 139845451286400 learning.py:512] global step 19137: loss = 3.7706 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19138: loss = 3.3994 (0.105 sec/step)\n",
            "I1003 01:02:05.785388 139845451286400 learning.py:512] global step 19138: loss = 3.3994 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19139: loss = 3.3796 (0.096 sec/step)\n",
            "I1003 01:02:05.883380 139845451286400 learning.py:512] global step 19139: loss = 3.3796 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19140: loss = 2.9879 (0.111 sec/step)\n",
            "I1003 01:02:05.995599 139845451286400 learning.py:512] global step 19140: loss = 2.9879 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19141: loss = 5.5508 (0.119 sec/step)\n",
            "I1003 01:02:06.116065 139845451286400 learning.py:512] global step 19141: loss = 5.5508 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 19142: loss = 4.2882 (0.110 sec/step)\n",
            "I1003 01:02:06.227596 139845451286400 learning.py:512] global step 19142: loss = 4.2882 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19143: loss = 2.8526 (0.122 sec/step)\n",
            "I1003 01:02:06.351105 139845451286400 learning.py:512] global step 19143: loss = 2.8526 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19144: loss = 2.1349 (0.108 sec/step)\n",
            "I1003 01:02:06.461115 139845451286400 learning.py:512] global step 19144: loss = 2.1349 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19145: loss = 6.1728 (0.121 sec/step)\n",
            "I1003 01:02:06.583783 139845451286400 learning.py:512] global step 19145: loss = 6.1728 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19146: loss = 3.2160 (0.105 sec/step)\n",
            "I1003 01:02:06.690655 139845451286400 learning.py:512] global step 19146: loss = 3.2160 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19147: loss = 4.2750 (0.124 sec/step)\n",
            "I1003 01:02:06.816585 139845451286400 learning.py:512] global step 19147: loss = 4.2750 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 19148: loss = 2.4436 (0.110 sec/step)\n",
            "I1003 01:02:06.928263 139845451286400 learning.py:512] global step 19148: loss = 2.4436 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19149: loss = 3.9604 (0.097 sec/step)\n",
            "I1003 01:02:07.026157 139845451286400 learning.py:512] global step 19149: loss = 3.9604 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19150: loss = 2.9111 (0.091 sec/step)\n",
            "I1003 01:02:07.118470 139845451286400 learning.py:512] global step 19150: loss = 2.9111 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19151: loss = 3.1468 (0.096 sec/step)\n",
            "I1003 01:02:07.216099 139845451286400 learning.py:512] global step 19151: loss = 3.1468 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19152: loss = 6.6961 (0.117 sec/step)\n",
            "I1003 01:02:07.334580 139845451286400 learning.py:512] global step 19152: loss = 6.6961 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19153: loss = 3.1899 (0.094 sec/step)\n",
            "I1003 01:02:07.430516 139845451286400 learning.py:512] global step 19153: loss = 3.1899 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19154: loss = 4.9450 (0.101 sec/step)\n",
            "I1003 01:02:07.532375 139845451286400 learning.py:512] global step 19154: loss = 4.9450 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19155: loss = 3.4230 (0.103 sec/step)\n",
            "I1003 01:02:07.636741 139845451286400 learning.py:512] global step 19155: loss = 3.4230 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19156: loss = 6.0397 (0.104 sec/step)\n",
            "I1003 01:02:07.742342 139845451286400 learning.py:512] global step 19156: loss = 6.0397 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19157: loss = 3.9341 (0.103 sec/step)\n",
            "I1003 01:02:07.846995 139845451286400 learning.py:512] global step 19157: loss = 3.9341 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19158: loss = 3.4426 (0.111 sec/step)\n",
            "I1003 01:02:07.959724 139845451286400 learning.py:512] global step 19158: loss = 3.4426 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19159: loss = 3.7706 (0.093 sec/step)\n",
            "I1003 01:02:08.054132 139845451286400 learning.py:512] global step 19159: loss = 3.7706 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19160: loss = 9.5430 (0.099 sec/step)\n",
            "I1003 01:02:08.154503 139845451286400 learning.py:512] global step 19160: loss = 9.5430 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19161: loss = 2.9073 (0.115 sec/step)\n",
            "I1003 01:02:08.271014 139845451286400 learning.py:512] global step 19161: loss = 2.9073 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19162: loss = 11.7450 (0.104 sec/step)\n",
            "I1003 01:02:08.375962 139845451286400 learning.py:512] global step 19162: loss = 11.7450 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19163: loss = 3.1006 (0.096 sec/step)\n",
            "I1003 01:02:08.473860 139845451286400 learning.py:512] global step 19163: loss = 3.1006 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19164: loss = 3.8682 (0.093 sec/step)\n",
            "I1003 01:02:08.568455 139845451286400 learning.py:512] global step 19164: loss = 3.8682 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19165: loss = 3.9336 (0.102 sec/step)\n",
            "I1003 01:02:08.672047 139845451286400 learning.py:512] global step 19165: loss = 3.9336 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19166: loss = 1.4008 (0.092 sec/step)\n",
            "I1003 01:02:08.765600 139845451286400 learning.py:512] global step 19166: loss = 1.4008 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19167: loss = 3.7559 (0.102 sec/step)\n",
            "I1003 01:02:08.869204 139845451286400 learning.py:512] global step 19167: loss = 3.7559 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19168: loss = 1.9097 (0.091 sec/step)\n",
            "I1003 01:02:08.961239 139845451286400 learning.py:512] global step 19168: loss = 1.9097 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19169: loss = 5.3603 (0.105 sec/step)\n",
            "I1003 01:02:09.067633 139845451286400 learning.py:512] global step 19169: loss = 5.3603 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19170: loss = 3.9030 (0.105 sec/step)\n",
            "I1003 01:02:09.173995 139845451286400 learning.py:512] global step 19170: loss = 3.9030 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19171: loss = 4.0037 (0.110 sec/step)\n",
            "I1003 01:02:09.285662 139845451286400 learning.py:512] global step 19171: loss = 4.0037 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19172: loss = 3.6268 (0.127 sec/step)\n",
            "I1003 01:02:09.413954 139845451286400 learning.py:512] global step 19172: loss = 3.6268 (0.127 sec/step)\n",
            "INFO:tensorflow:global step 19173: loss = 5.6855 (0.095 sec/step)\n",
            "I1003 01:02:09.510257 139845451286400 learning.py:512] global step 19173: loss = 5.6855 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19174: loss = 3.6327 (0.097 sec/step)\n",
            "I1003 01:02:09.608574 139845451286400 learning.py:512] global step 19174: loss = 3.6327 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19175: loss = 3.0862 (0.103 sec/step)\n",
            "I1003 01:02:09.713172 139845451286400 learning.py:512] global step 19175: loss = 3.0862 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19176: loss = 3.0843 (0.102 sec/step)\n",
            "I1003 01:02:09.816233 139845451286400 learning.py:512] global step 19176: loss = 3.0843 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19177: loss = 3.8462 (0.087 sec/step)\n",
            "I1003 01:02:09.904250 139845451286400 learning.py:512] global step 19177: loss = 3.8462 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 19178: loss = 2.4607 (0.108 sec/step)\n",
            "I1003 01:02:10.014136 139845451286400 learning.py:512] global step 19178: loss = 2.4607 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19179: loss = 3.5034 (0.109 sec/step)\n",
            "I1003 01:02:10.124974 139845451286400 learning.py:512] global step 19179: loss = 3.5034 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19180: loss = 2.2585 (0.121 sec/step)\n",
            "I1003 01:02:10.247735 139845451286400 learning.py:512] global step 19180: loss = 2.2585 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19181: loss = 8.8021 (0.129 sec/step)\n",
            "I1003 01:02:10.378473 139845451286400 learning.py:512] global step 19181: loss = 8.8021 (0.129 sec/step)\n",
            "INFO:tensorflow:global step 19182: loss = 2.4051 (0.132 sec/step)\n",
            "I1003 01:02:10.511514 139845451286400 learning.py:512] global step 19182: loss = 2.4051 (0.132 sec/step)\n",
            "INFO:tensorflow:global step 19183: loss = 3.0533 (0.114 sec/step)\n",
            "I1003 01:02:10.627039 139845451286400 learning.py:512] global step 19183: loss = 3.0533 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19184: loss = 2.9718 (0.106 sec/step)\n",
            "I1003 01:02:10.734520 139845451286400 learning.py:512] global step 19184: loss = 2.9718 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19185: loss = 2.8386 (0.098 sec/step)\n",
            "I1003 01:02:10.833675 139845451286400 learning.py:512] global step 19185: loss = 2.8386 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19186: loss = 2.3122 (0.105 sec/step)\n",
            "I1003 01:02:10.939665 139845451286400 learning.py:512] global step 19186: loss = 2.3122 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19187: loss = 4.5696 (0.090 sec/step)\n",
            "I1003 01:02:11.031585 139845451286400 learning.py:512] global step 19187: loss = 4.5696 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19188: loss = 3.0523 (0.108 sec/step)\n",
            "I1003 01:02:11.141104 139845451286400 learning.py:512] global step 19188: loss = 3.0523 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19189: loss = 3.0024 (0.093 sec/step)\n",
            "I1003 01:02:11.235105 139845451286400 learning.py:512] global step 19189: loss = 3.0024 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19190: loss = 3.2689 (0.112 sec/step)\n",
            "I1003 01:02:11.348166 139845451286400 learning.py:512] global step 19190: loss = 3.2689 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19191: loss = 2.2878 (0.097 sec/step)\n",
            "I1003 01:02:11.446520 139845451286400 learning.py:512] global step 19191: loss = 2.2878 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19192: loss = 2.0388 (0.105 sec/step)\n",
            "I1003 01:02:11.552920 139845451286400 learning.py:512] global step 19192: loss = 2.0388 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19193: loss = 2.9096 (0.099 sec/step)\n",
            "I1003 01:02:11.653872 139845451286400 learning.py:512] global step 19193: loss = 2.9096 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19194: loss = 2.5849 (0.105 sec/step)\n",
            "I1003 01:02:11.760728 139845451286400 learning.py:512] global step 19194: loss = 2.5849 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19195: loss = 2.9041 (0.106 sec/step)\n",
            "I1003 01:02:11.867705 139845451286400 learning.py:512] global step 19195: loss = 2.9041 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19196: loss = 2.6983 (0.095 sec/step)\n",
            "I1003 01:02:11.963687 139845451286400 learning.py:512] global step 19196: loss = 2.6983 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19197: loss = 1.9823 (0.106 sec/step)\n",
            "I1003 01:02:12.070558 139845451286400 learning.py:512] global step 19197: loss = 1.9823 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19198: loss = 3.2982 (0.094 sec/step)\n",
            "I1003 01:02:12.166321 139845451286400 learning.py:512] global step 19198: loss = 3.2982 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19199: loss = 3.6196 (0.109 sec/step)\n",
            "I1003 01:02:12.276407 139845451286400 learning.py:512] global step 19199: loss = 3.6196 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19200: loss = 4.6310 (0.113 sec/step)\n",
            "I1003 01:02:12.390856 139845451286400 learning.py:512] global step 19200: loss = 4.6310 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 19201: loss = 3.8969 (0.104 sec/step)\n",
            "I1003 01:02:12.496099 139845451286400 learning.py:512] global step 19201: loss = 3.8969 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19202: loss = 2.9687 (0.106 sec/step)\n",
            "I1003 01:02:12.603007 139845451286400 learning.py:512] global step 19202: loss = 2.9687 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19203: loss = 2.1090 (0.091 sec/step)\n",
            "I1003 01:02:12.695344 139845451286400 learning.py:512] global step 19203: loss = 2.1090 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19204: loss = 2.7202 (0.094 sec/step)\n",
            "I1003 01:02:12.790973 139845451286400 learning.py:512] global step 19204: loss = 2.7202 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19205: loss = 1.8868 (0.105 sec/step)\n",
            "I1003 01:02:12.897560 139845451286400 learning.py:512] global step 19205: loss = 1.8868 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19206: loss = 2.8461 (0.104 sec/step)\n",
            "I1003 01:02:13.005447 139845451286400 learning.py:512] global step 19206: loss = 2.8461 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19207: loss = 2.8243 (0.121 sec/step)\n",
            "I1003 01:02:13.128145 139845451286400 learning.py:512] global step 19207: loss = 2.8243 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19208: loss = 2.8764 (0.098 sec/step)\n",
            "I1003 01:02:13.227581 139845451286400 learning.py:512] global step 19208: loss = 2.8764 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19209: loss = 3.0641 (0.103 sec/step)\n",
            "I1003 01:02:13.332037 139845451286400 learning.py:512] global step 19209: loss = 3.0641 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19210: loss = 1.8010 (0.123 sec/step)\n",
            "I1003 01:02:13.456585 139845451286400 learning.py:512] global step 19210: loss = 1.8010 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 19211: loss = 4.4672 (0.101 sec/step)\n",
            "I1003 01:02:13.558883 139845451286400 learning.py:512] global step 19211: loss = 4.4672 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19212: loss = 3.6517 (0.100 sec/step)\n",
            "I1003 01:02:13.660568 139845451286400 learning.py:512] global step 19212: loss = 3.6517 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19213: loss = 2.5136 (0.099 sec/step)\n",
            "I1003 01:02:13.760680 139845451286400 learning.py:512] global step 19213: loss = 2.5136 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19214: loss = 2.4254 (0.098 sec/step)\n",
            "I1003 01:02:13.859922 139845451286400 learning.py:512] global step 19214: loss = 2.4254 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19215: loss = 2.8786 (0.101 sec/step)\n",
            "I1003 01:02:13.961914 139845451286400 learning.py:512] global step 19215: loss = 2.8786 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19216: loss = 1.7228 (0.105 sec/step)\n",
            "I1003 01:02:14.068248 139845451286400 learning.py:512] global step 19216: loss = 1.7228 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19217: loss = 2.5774 (0.099 sec/step)\n",
            "I1003 01:02:14.169104 139845451286400 learning.py:512] global step 19217: loss = 2.5774 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19218: loss = 6.2182 (0.105 sec/step)\n",
            "I1003 01:02:14.275690 139845451286400 learning.py:512] global step 19218: loss = 6.2182 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19219: loss = 3.4441 (0.108 sec/step)\n",
            "I1003 01:02:14.387465 139845451286400 learning.py:512] global step 19219: loss = 3.4441 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19220: loss = 3.6888 (0.105 sec/step)\n",
            "I1003 01:02:14.494874 139845451286400 learning.py:512] global step 19220: loss = 3.6888 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19221: loss = 12.4151 (0.100 sec/step)\n",
            "I1003 01:02:14.595806 139845451286400 learning.py:512] global step 19221: loss = 12.4151 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19222: loss = 3.6157 (0.099 sec/step)\n",
            "I1003 01:02:14.696090 139845451286400 learning.py:512] global step 19222: loss = 3.6157 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19223: loss = 7.8530 (0.102 sec/step)\n",
            "I1003 01:02:14.799633 139845451286400 learning.py:512] global step 19223: loss = 7.8530 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19224: loss = 2.8130 (0.103 sec/step)\n",
            "I1003 01:02:14.904177 139845451286400 learning.py:512] global step 19224: loss = 2.8130 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19225: loss = 4.3140 (0.102 sec/step)\n",
            "I1003 01:02:15.007385 139845451286400 learning.py:512] global step 19225: loss = 4.3140 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19226: loss = 5.0323 (0.125 sec/step)\n",
            "I1003 01:02:15.133532 139845451286400 learning.py:512] global step 19226: loss = 5.0323 (0.125 sec/step)\n",
            "INFO:tensorflow:global step 19227: loss = 3.1653 (0.094 sec/step)\n",
            "I1003 01:02:15.229381 139845451286400 learning.py:512] global step 19227: loss = 3.1653 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19228: loss = 2.5217 (0.106 sec/step)\n",
            "I1003 01:02:15.336589 139845451286400 learning.py:512] global step 19228: loss = 2.5217 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19229: loss = 8.3195 (0.120 sec/step)\n",
            "I1003 01:02:15.457851 139845451286400 learning.py:512] global step 19229: loss = 8.3195 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19230: loss = 3.8711 (0.097 sec/step)\n",
            "I1003 01:02:15.556071 139845451286400 learning.py:512] global step 19230: loss = 3.8711 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19231: loss = 3.6829 (0.112 sec/step)\n",
            "I1003 01:02:15.669496 139845451286400 learning.py:512] global step 19231: loss = 3.6829 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19232: loss = 9.2951 (0.090 sec/step)\n",
            "I1003 01:02:15.761144 139845451286400 learning.py:512] global step 19232: loss = 9.2951 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19233: loss = 3.7526 (0.102 sec/step)\n",
            "I1003 01:02:15.864163 139845451286400 learning.py:512] global step 19233: loss = 3.7526 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19234: loss = 4.4262 (0.093 sec/step)\n",
            "I1003 01:02:15.958798 139845451286400 learning.py:512] global step 19234: loss = 4.4262 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19235: loss = 3.4063 (0.092 sec/step)\n",
            "I1003 01:02:16.053173 139845451286400 learning.py:512] global step 19235: loss = 3.4063 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19236: loss = 2.3298 (0.109 sec/step)\n",
            "I1003 01:02:16.163299 139845451286400 learning.py:512] global step 19236: loss = 2.3298 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19237: loss = 3.6591 (0.106 sec/step)\n",
            "I1003 01:02:16.270401 139845451286400 learning.py:512] global step 19237: loss = 3.6591 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19238: loss = 3.1871 (0.093 sec/step)\n",
            "I1003 01:02:16.364920 139845451286400 learning.py:512] global step 19238: loss = 3.1871 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19239: loss = 3.6584 (0.114 sec/step)\n",
            "I1003 01:02:16.480424 139845451286400 learning.py:512] global step 19239: loss = 3.6584 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19240: loss = 3.8620 (0.103 sec/step)\n",
            "I1003 01:02:16.584963 139845451286400 learning.py:512] global step 19240: loss = 3.8620 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19241: loss = 6.9420 (0.114 sec/step)\n",
            "I1003 01:02:16.699856 139845451286400 learning.py:512] global step 19241: loss = 6.9420 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19242: loss = 2.4919 (0.095 sec/step)\n",
            "I1003 01:02:16.795827 139845451286400 learning.py:512] global step 19242: loss = 2.4919 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19243: loss = 6.7401 (0.100 sec/step)\n",
            "I1003 01:02:16.897289 139845451286400 learning.py:512] global step 19243: loss = 6.7401 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19244: loss = 2.1911 (0.106 sec/step)\n",
            "I1003 01:02:17.004555 139845451286400 learning.py:512] global step 19244: loss = 2.1911 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19245: loss = 3.2863 (0.107 sec/step)\n",
            "I1003 01:02:17.113570 139845451286400 learning.py:512] global step 19245: loss = 3.2863 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19246: loss = 2.2009 (0.113 sec/step)\n",
            "I1003 01:02:17.227689 139845451286400 learning.py:512] global step 19246: loss = 2.2009 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 19247: loss = 3.3497 (0.094 sec/step)\n",
            "I1003 01:02:17.323167 139845451286400 learning.py:512] global step 19247: loss = 3.3497 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19248: loss = 2.3249 (0.092 sec/step)\n",
            "I1003 01:02:17.416877 139845451286400 learning.py:512] global step 19248: loss = 2.3249 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19249: loss = 4.1345 (0.106 sec/step)\n",
            "I1003 01:02:17.524418 139845451286400 learning.py:512] global step 19249: loss = 4.1345 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19250: loss = 2.8850 (0.102 sec/step)\n",
            "I1003 01:02:17.627524 139845451286400 learning.py:512] global step 19250: loss = 2.8850 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19251: loss = 4.7401 (0.098 sec/step)\n",
            "I1003 01:02:17.726793 139845451286400 learning.py:512] global step 19251: loss = 4.7401 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19252: loss = 2.4560 (0.102 sec/step)\n",
            "I1003 01:02:17.829844 139845451286400 learning.py:512] global step 19252: loss = 2.4560 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19253: loss = 2.6746 (0.099 sec/step)\n",
            "I1003 01:02:17.930577 139845451286400 learning.py:512] global step 19253: loss = 2.6746 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19254: loss = 4.3355 (0.117 sec/step)\n",
            "I1003 01:02:18.049351 139845451286400 learning.py:512] global step 19254: loss = 4.3355 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19255: loss = 5.6841 (0.129 sec/step)\n",
            "I1003 01:02:18.179743 139845451286400 learning.py:512] global step 19255: loss = 5.6841 (0.129 sec/step)\n",
            "INFO:tensorflow:global step 19256: loss = 6.5280 (0.118 sec/step)\n",
            "I1003 01:02:18.299250 139845451286400 learning.py:512] global step 19256: loss = 6.5280 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19257: loss = 3.9354 (0.116 sec/step)\n",
            "I1003 01:02:18.417078 139845451286400 learning.py:512] global step 19257: loss = 3.9354 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 19258: loss = 2.9754 (0.123 sec/step)\n",
            "I1003 01:02:18.541498 139845451286400 learning.py:512] global step 19258: loss = 2.9754 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 19259: loss = 3.1441 (0.114 sec/step)\n",
            "I1003 01:02:18.657538 139845451286400 learning.py:512] global step 19259: loss = 3.1441 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19260: loss = 7.8498 (0.108 sec/step)\n",
            "I1003 01:02:18.767530 139845451286400 learning.py:512] global step 19260: loss = 7.8498 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19261: loss = 2.1666 (0.094 sec/step)\n",
            "I1003 01:02:18.862634 139845451286400 learning.py:512] global step 19261: loss = 2.1666 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19262: loss = 3.2413 (0.097 sec/step)\n",
            "I1003 01:02:18.961126 139845451286400 learning.py:512] global step 19262: loss = 3.2413 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19263: loss = 5.7523 (0.105 sec/step)\n",
            "I1003 01:02:19.067246 139845451286400 learning.py:512] global step 19263: loss = 5.7523 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19264: loss = 8.9445 (0.097 sec/step)\n",
            "I1003 01:02:19.165456 139845451286400 learning.py:512] global step 19264: loss = 8.9445 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19265: loss = 4.6342 (0.099 sec/step)\n",
            "I1003 01:02:19.265400 139845451286400 learning.py:512] global step 19265: loss = 4.6342 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19266: loss = 3.1798 (0.097 sec/step)\n",
            "I1003 01:02:19.363440 139845451286400 learning.py:512] global step 19266: loss = 3.1798 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19267: loss = 3.7058 (0.098 sec/step)\n",
            "I1003 01:02:19.463267 139845451286400 learning.py:512] global step 19267: loss = 3.7058 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19268: loss = 4.1360 (0.117 sec/step)\n",
            "I1003 01:02:19.581222 139845451286400 learning.py:512] global step 19268: loss = 4.1360 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19269: loss = 2.0695 (0.101 sec/step)\n",
            "I1003 01:02:19.683944 139845451286400 learning.py:512] global step 19269: loss = 2.0695 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19270: loss = 3.0194 (0.087 sec/step)\n",
            "I1003 01:02:19.772168 139845451286400 learning.py:512] global step 19270: loss = 3.0194 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 19271: loss = 6.8890 (0.132 sec/step)\n",
            "I1003 01:02:19.929569 139845451286400 learning.py:512] global step 19271: loss = 6.8890 (0.132 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 19272.\n",
            "I1003 01:02:20.128837 139841898313472 supervisor.py:1050] Recording summary at step 19272.\n",
            "INFO:tensorflow:global step 19272: loss = 1.9259 (0.204 sec/step)\n",
            "I1003 01:02:20.138503 139845451286400 learning.py:512] global step 19272: loss = 1.9259 (0.204 sec/step)\n",
            "INFO:tensorflow:global step 19273: loss = 7.6938 (0.106 sec/step)\n",
            "I1003 01:02:20.246554 139845451286400 learning.py:512] global step 19273: loss = 7.6938 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19274: loss = 6.8621 (0.120 sec/step)\n",
            "I1003 01:02:20.368269 139845451286400 learning.py:512] global step 19274: loss = 6.8621 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19275: loss = 2.7183 (0.117 sec/step)\n",
            "I1003 01:02:20.487546 139845451286400 learning.py:512] global step 19275: loss = 2.7183 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19276: loss = 5.1774 (0.122 sec/step)\n",
            "I1003 01:02:20.611123 139845451286400 learning.py:512] global step 19276: loss = 5.1774 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19277: loss = 4.2008 (0.096 sec/step)\n",
            "I1003 01:02:20.709026 139845451286400 learning.py:512] global step 19277: loss = 4.2008 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19278: loss = 8.4598 (0.103 sec/step)\n",
            "I1003 01:02:20.813501 139845451286400 learning.py:512] global step 19278: loss = 8.4598 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19279: loss = 3.8767 (0.097 sec/step)\n",
            "I1003 01:02:20.912088 139845451286400 learning.py:512] global step 19279: loss = 3.8767 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19280: loss = 2.3595 (0.106 sec/step)\n",
            "I1003 01:02:21.019642 139845451286400 learning.py:512] global step 19280: loss = 2.3595 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19281: loss = 8.4982 (0.099 sec/step)\n",
            "I1003 01:02:21.120939 139845451286400 learning.py:512] global step 19281: loss = 8.4982 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19282: loss = 5.6489 (0.101 sec/step)\n",
            "I1003 01:02:21.223707 139845451286400 learning.py:512] global step 19282: loss = 5.6489 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19283: loss = 3.4775 (0.098 sec/step)\n",
            "I1003 01:02:21.323362 139845451286400 learning.py:512] global step 19283: loss = 3.4775 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19284: loss = 4.2328 (0.104 sec/step)\n",
            "I1003 01:02:21.428415 139845451286400 learning.py:512] global step 19284: loss = 4.2328 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19285: loss = 3.8200 (0.097 sec/step)\n",
            "I1003 01:02:21.526487 139845451286400 learning.py:512] global step 19285: loss = 3.8200 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19286: loss = 5.0986 (0.109 sec/step)\n",
            "I1003 01:02:21.636939 139845451286400 learning.py:512] global step 19286: loss = 5.0986 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19287: loss = 7.9489 (0.092 sec/step)\n",
            "I1003 01:02:21.730727 139845451286400 learning.py:512] global step 19287: loss = 7.9489 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19288: loss = 4.5414 (0.110 sec/step)\n",
            "I1003 01:02:21.842334 139845451286400 learning.py:512] global step 19288: loss = 4.5414 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19289: loss = 4.1876 (0.096 sec/step)\n",
            "I1003 01:02:21.939416 139845451286400 learning.py:512] global step 19289: loss = 4.1876 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19290: loss = 3.3546 (0.115 sec/step)\n",
            "I1003 01:02:22.055622 139845451286400 learning.py:512] global step 19290: loss = 3.3546 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19291: loss = 10.8192 (0.110 sec/step)\n",
            "I1003 01:02:22.167181 139845451286400 learning.py:512] global step 19291: loss = 10.8192 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19292: loss = 6.4988 (0.117 sec/step)\n",
            "I1003 01:02:22.285326 139845451286400 learning.py:512] global step 19292: loss = 6.4988 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19293: loss = 2.3236 (0.113 sec/step)\n",
            "I1003 01:02:22.399484 139845451286400 learning.py:512] global step 19293: loss = 2.3236 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 19294: loss = 5.7124 (0.111 sec/step)\n",
            "I1003 01:02:22.511736 139845451286400 learning.py:512] global step 19294: loss = 5.7124 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19295: loss = 4.0415 (0.124 sec/step)\n",
            "I1003 01:02:22.636977 139845451286400 learning.py:512] global step 19295: loss = 4.0415 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 19296: loss = 2.9136 (0.114 sec/step)\n",
            "I1003 01:02:22.751988 139845451286400 learning.py:512] global step 19296: loss = 2.9136 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19297: loss = 4.1742 (0.096 sec/step)\n",
            "I1003 01:02:22.849828 139845451286400 learning.py:512] global step 19297: loss = 4.1742 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19298: loss = 4.1100 (0.105 sec/step)\n",
            "I1003 01:02:22.956142 139845451286400 learning.py:512] global step 19298: loss = 4.1100 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19299: loss = 4.3155 (0.100 sec/step)\n",
            "I1003 01:02:23.057094 139845451286400 learning.py:512] global step 19299: loss = 4.3155 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19300: loss = 2.5276 (0.109 sec/step)\n",
            "I1003 01:02:23.168198 139845451286400 learning.py:512] global step 19300: loss = 2.5276 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19301: loss = 5.5606 (0.108 sec/step)\n",
            "I1003 01:02:23.277325 139845451286400 learning.py:512] global step 19301: loss = 5.5606 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19302: loss = 4.4321 (0.088 sec/step)\n",
            "I1003 01:02:23.368495 139845451286400 learning.py:512] global step 19302: loss = 4.4321 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19303: loss = 3.5736 (0.096 sec/step)\n",
            "I1003 01:02:23.466141 139845451286400 learning.py:512] global step 19303: loss = 3.5736 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19304: loss = 6.3466 (0.103 sec/step)\n",
            "I1003 01:02:23.570791 139845451286400 learning.py:512] global step 19304: loss = 6.3466 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19305: loss = 3.5335 (0.125 sec/step)\n",
            "I1003 01:02:23.697334 139845451286400 learning.py:512] global step 19305: loss = 3.5335 (0.125 sec/step)\n",
            "INFO:tensorflow:global step 19306: loss = 4.0885 (0.101 sec/step)\n",
            "I1003 01:02:23.799646 139845451286400 learning.py:512] global step 19306: loss = 4.0885 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19307: loss = 4.2672 (0.096 sec/step)\n",
            "I1003 01:02:23.896781 139845451286400 learning.py:512] global step 19307: loss = 4.2672 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19308: loss = 3.3512 (0.102 sec/step)\n",
            "I1003 01:02:23.999694 139845451286400 learning.py:512] global step 19308: loss = 3.3512 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19309: loss = 5.5927 (0.092 sec/step)\n",
            "I1003 01:02:24.092835 139845451286400 learning.py:512] global step 19309: loss = 5.5927 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19310: loss = 6.4554 (0.105 sec/step)\n",
            "I1003 01:02:24.199406 139845451286400 learning.py:512] global step 19310: loss = 6.4554 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19311: loss = 2.7950 (0.100 sec/step)\n",
            "I1003 01:02:24.301051 139845451286400 learning.py:512] global step 19311: loss = 2.7950 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19312: loss = 3.6673 (0.107 sec/step)\n",
            "I1003 01:02:24.409142 139845451286400 learning.py:512] global step 19312: loss = 3.6673 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19313: loss = 4.1290 (0.107 sec/step)\n",
            "I1003 01:02:24.517280 139845451286400 learning.py:512] global step 19313: loss = 4.1290 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19314: loss = 5.0354 (0.098 sec/step)\n",
            "I1003 01:02:24.616853 139845451286400 learning.py:512] global step 19314: loss = 5.0354 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19315: loss = 3.1683 (0.101 sec/step)\n",
            "I1003 01:02:24.719015 139845451286400 learning.py:512] global step 19315: loss = 3.1683 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19316: loss = 2.8834 (0.095 sec/step)\n",
            "I1003 01:02:24.816143 139845451286400 learning.py:512] global step 19316: loss = 2.8834 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19317: loss = 6.2010 (0.098 sec/step)\n",
            "I1003 01:02:24.915911 139845451286400 learning.py:512] global step 19317: loss = 6.2010 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19318: loss = 2.8386 (0.100 sec/step)\n",
            "I1003 01:02:25.017762 139845451286400 learning.py:512] global step 19318: loss = 2.8386 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19319: loss = 5.2300 (0.110 sec/step)\n",
            "I1003 01:02:25.128972 139845451286400 learning.py:512] global step 19319: loss = 5.2300 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19320: loss = 2.2603 (0.096 sec/step)\n",
            "I1003 01:02:25.225935 139845451286400 learning.py:512] global step 19320: loss = 2.2603 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19321: loss = 4.9041 (0.097 sec/step)\n",
            "I1003 01:02:25.324039 139845451286400 learning.py:512] global step 19321: loss = 4.9041 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19322: loss = 4.5298 (0.104 sec/step)\n",
            "I1003 01:02:25.429789 139845451286400 learning.py:512] global step 19322: loss = 4.5298 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19323: loss = 4.8052 (0.095 sec/step)\n",
            "I1003 01:02:25.526567 139845451286400 learning.py:512] global step 19323: loss = 4.8052 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19324: loss = 5.1275 (0.104 sec/step)\n",
            "I1003 01:02:25.631905 139845451286400 learning.py:512] global step 19324: loss = 5.1275 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19325: loss = 3.0602 (0.126 sec/step)\n",
            "I1003 01:02:25.759486 139845451286400 learning.py:512] global step 19325: loss = 3.0602 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 19326: loss = 4.0954 (0.106 sec/step)\n",
            "I1003 01:02:25.866621 139845451286400 learning.py:512] global step 19326: loss = 4.0954 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19327: loss = 2.4302 (0.096 sec/step)\n",
            "I1003 01:02:25.963849 139845451286400 learning.py:512] global step 19327: loss = 2.4302 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19328: loss = 2.9250 (0.089 sec/step)\n",
            "I1003 01:02:26.054105 139845451286400 learning.py:512] global step 19328: loss = 2.9250 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 19329: loss = 5.3859 (0.091 sec/step)\n",
            "I1003 01:02:26.146489 139845451286400 learning.py:512] global step 19329: loss = 5.3859 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19330: loss = 2.9505 (0.101 sec/step)\n",
            "I1003 01:02:26.248923 139845451286400 learning.py:512] global step 19330: loss = 2.9505 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19331: loss = 4.6443 (0.097 sec/step)\n",
            "I1003 01:02:26.347768 139845451286400 learning.py:512] global step 19331: loss = 4.6443 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19332: loss = 5.1347 (0.093 sec/step)\n",
            "I1003 01:02:26.442277 139845451286400 learning.py:512] global step 19332: loss = 5.1347 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19333: loss = 3.5556 (0.086 sec/step)\n",
            "I1003 01:02:26.529880 139845451286400 learning.py:512] global step 19333: loss = 3.5556 (0.086 sec/step)\n",
            "INFO:tensorflow:global step 19334: loss = 1.7865 (0.088 sec/step)\n",
            "I1003 01:02:26.619394 139845451286400 learning.py:512] global step 19334: loss = 1.7865 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19335: loss = 8.1465 (0.104 sec/step)\n",
            "I1003 01:02:26.724757 139845451286400 learning.py:512] global step 19335: loss = 8.1465 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19336: loss = 6.1395 (0.098 sec/step)\n",
            "I1003 01:02:26.824212 139845451286400 learning.py:512] global step 19336: loss = 6.1395 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19337: loss = 4.5881 (0.119 sec/step)\n",
            "I1003 01:02:26.944613 139845451286400 learning.py:512] global step 19337: loss = 4.5881 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 19338: loss = 3.4349 (0.101 sec/step)\n",
            "I1003 01:02:27.046795 139845451286400 learning.py:512] global step 19338: loss = 3.4349 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19339: loss = 3.9474 (0.097 sec/step)\n",
            "I1003 01:02:27.144937 139845451286400 learning.py:512] global step 19339: loss = 3.9474 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19340: loss = 5.0210 (0.095 sec/step)\n",
            "I1003 01:02:27.241613 139845451286400 learning.py:512] global step 19340: loss = 5.0210 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19341: loss = 6.8411 (0.097 sec/step)\n",
            "I1003 01:02:27.340273 139845451286400 learning.py:512] global step 19341: loss = 6.8411 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19342: loss = 3.3908 (0.090 sec/step)\n",
            "I1003 01:02:27.431955 139845451286400 learning.py:512] global step 19342: loss = 3.3908 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19343: loss = 3.4158 (0.103 sec/step)\n",
            "I1003 01:02:27.536501 139845451286400 learning.py:512] global step 19343: loss = 3.4158 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19344: loss = 5.5469 (0.090 sec/step)\n",
            "I1003 01:02:27.628204 139845451286400 learning.py:512] global step 19344: loss = 5.5469 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19345: loss = 3.4822 (0.117 sec/step)\n",
            "I1003 01:02:27.746950 139845451286400 learning.py:512] global step 19345: loss = 3.4822 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19346: loss = 4.5283 (0.097 sec/step)\n",
            "I1003 01:02:27.845624 139845451286400 learning.py:512] global step 19346: loss = 4.5283 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19347: loss = 3.7120 (0.102 sec/step)\n",
            "I1003 01:02:27.949213 139845451286400 learning.py:512] global step 19347: loss = 3.7120 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19348: loss = 4.0428 (0.093 sec/step)\n",
            "I1003 01:02:28.043917 139845451286400 learning.py:512] global step 19348: loss = 4.0428 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19349: loss = 3.4811 (0.120 sec/step)\n",
            "I1003 01:02:28.165000 139845451286400 learning.py:512] global step 19349: loss = 3.4811 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19350: loss = 4.2761 (0.108 sec/step)\n",
            "I1003 01:02:28.274615 139845451286400 learning.py:512] global step 19350: loss = 4.2761 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19351: loss = 3.6032 (0.098 sec/step)\n",
            "I1003 01:02:28.373949 139845451286400 learning.py:512] global step 19351: loss = 3.6032 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19352: loss = 3.2109 (0.100 sec/step)\n",
            "I1003 01:02:28.475460 139845451286400 learning.py:512] global step 19352: loss = 3.2109 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19353: loss = 2.4519 (0.100 sec/step)\n",
            "I1003 01:02:28.576453 139845451286400 learning.py:512] global step 19353: loss = 2.4519 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19354: loss = 3.9504 (0.103 sec/step)\n",
            "I1003 01:02:28.681226 139845451286400 learning.py:512] global step 19354: loss = 3.9504 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19355: loss = 8.6191 (0.112 sec/step)\n",
            "I1003 01:02:28.795096 139845451286400 learning.py:512] global step 19355: loss = 8.6191 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19356: loss = 2.6846 (0.103 sec/step)\n",
            "I1003 01:02:28.899962 139845451286400 learning.py:512] global step 19356: loss = 2.6846 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19357: loss = 2.4301 (0.100 sec/step)\n",
            "I1003 01:02:29.001564 139845451286400 learning.py:512] global step 19357: loss = 2.4301 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19358: loss = 2.9492 (0.104 sec/step)\n",
            "I1003 01:02:29.107058 139845451286400 learning.py:512] global step 19358: loss = 2.9492 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19359: loss = 3.8787 (0.087 sec/step)\n",
            "I1003 01:02:29.195493 139845451286400 learning.py:512] global step 19359: loss = 3.8787 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 19360: loss = 9.3439 (0.084 sec/step)\n",
            "I1003 01:02:29.281118 139845451286400 learning.py:512] global step 19360: loss = 9.3439 (0.084 sec/step)\n",
            "INFO:tensorflow:global step 19361: loss = 2.7844 (0.104 sec/step)\n",
            "I1003 01:02:29.386704 139845451286400 learning.py:512] global step 19361: loss = 2.7844 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19362: loss = 2.1515 (0.101 sec/step)\n",
            "I1003 01:02:29.489127 139845451286400 learning.py:512] global step 19362: loss = 2.1515 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19363: loss = 5.3482 (0.104 sec/step)\n",
            "I1003 01:02:29.594039 139845451286400 learning.py:512] global step 19363: loss = 5.3482 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19364: loss = 4.0072 (0.105 sec/step)\n",
            "I1003 01:02:29.701003 139845451286400 learning.py:512] global step 19364: loss = 4.0072 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19365: loss = 4.1297 (0.118 sec/step)\n",
            "I1003 01:02:29.819989 139845451286400 learning.py:512] global step 19365: loss = 4.1297 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19366: loss = 5.0764 (0.100 sec/step)\n",
            "I1003 01:02:29.921584 139845451286400 learning.py:512] global step 19366: loss = 5.0764 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19367: loss = 3.9915 (0.109 sec/step)\n",
            "I1003 01:02:30.031924 139845451286400 learning.py:512] global step 19367: loss = 3.9915 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19368: loss = 8.2167 (0.116 sec/step)\n",
            "I1003 01:02:30.149434 139845451286400 learning.py:512] global step 19368: loss = 8.2167 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 19369: loss = 3.8704 (0.107 sec/step)\n",
            "I1003 01:02:30.258104 139845451286400 learning.py:512] global step 19369: loss = 3.8704 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19370: loss = 3.8821 (0.097 sec/step)\n",
            "I1003 01:02:30.356461 139845451286400 learning.py:512] global step 19370: loss = 3.8821 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19371: loss = 3.8059 (0.101 sec/step)\n",
            "I1003 01:02:30.459322 139845451286400 learning.py:512] global step 19371: loss = 3.8059 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19372: loss = 4.4175 (0.093 sec/step)\n",
            "I1003 01:02:30.553968 139845451286400 learning.py:512] global step 19372: loss = 4.4175 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19373: loss = 5.4034 (0.091 sec/step)\n",
            "I1003 01:02:30.646521 139845451286400 learning.py:512] global step 19373: loss = 5.4034 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19374: loss = 3.1793 (0.105 sec/step)\n",
            "I1003 01:02:30.752703 139845451286400 learning.py:512] global step 19374: loss = 3.1793 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19375: loss = 4.0898 (0.111 sec/step)\n",
            "I1003 01:02:30.865983 139845451286400 learning.py:512] global step 19375: loss = 4.0898 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19376: loss = 3.0493 (0.099 sec/step)\n",
            "I1003 01:02:30.965861 139845451286400 learning.py:512] global step 19376: loss = 3.0493 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19377: loss = 3.8704 (0.099 sec/step)\n",
            "I1003 01:02:31.066155 139845451286400 learning.py:512] global step 19377: loss = 3.8704 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19378: loss = 4.0086 (0.094 sec/step)\n",
            "I1003 01:02:31.161556 139845451286400 learning.py:512] global step 19378: loss = 4.0086 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19379: loss = 9.3315 (0.106 sec/step)\n",
            "I1003 01:02:31.269281 139845451286400 learning.py:512] global step 19379: loss = 9.3315 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19380: loss = 4.7978 (0.110 sec/step)\n",
            "I1003 01:02:31.381212 139845451286400 learning.py:512] global step 19380: loss = 4.7978 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19381: loss = 3.9412 (0.097 sec/step)\n",
            "I1003 01:02:31.479911 139845451286400 learning.py:512] global step 19381: loss = 3.9412 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19382: loss = 6.4566 (0.102 sec/step)\n",
            "I1003 01:02:31.583082 139845451286400 learning.py:512] global step 19382: loss = 6.4566 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19383: loss = 2.6054 (0.098 sec/step)\n",
            "I1003 01:02:31.681910 139845451286400 learning.py:512] global step 19383: loss = 2.6054 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19384: loss = 6.3225 (0.117 sec/step)\n",
            "I1003 01:02:31.800272 139845451286400 learning.py:512] global step 19384: loss = 6.3225 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19385: loss = 3.1179 (0.097 sec/step)\n",
            "I1003 01:02:31.898727 139845451286400 learning.py:512] global step 19385: loss = 3.1179 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19386: loss = 3.1679 (0.107 sec/step)\n",
            "I1003 01:02:32.006788 139845451286400 learning.py:512] global step 19386: loss = 3.1679 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19387: loss = 4.1962 (0.120 sec/step)\n",
            "I1003 01:02:32.128958 139845451286400 learning.py:512] global step 19387: loss = 4.1962 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19388: loss = 5.5577 (0.118 sec/step)\n",
            "I1003 01:02:32.248335 139845451286400 learning.py:512] global step 19388: loss = 5.5577 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19389: loss = 5.0533 (0.114 sec/step)\n",
            "I1003 01:02:32.364042 139845451286400 learning.py:512] global step 19389: loss = 5.0533 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19390: loss = 2.8081 (0.111 sec/step)\n",
            "I1003 01:02:32.476755 139845451286400 learning.py:512] global step 19390: loss = 2.8081 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19391: loss = 3.9999 (0.109 sec/step)\n",
            "I1003 01:02:32.587512 139845451286400 learning.py:512] global step 19391: loss = 3.9999 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19392: loss = 3.9812 (0.113 sec/step)\n",
            "I1003 01:02:32.702166 139845451286400 learning.py:512] global step 19392: loss = 3.9812 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 19393: loss = 4.2426 (0.107 sec/step)\n",
            "I1003 01:02:32.811894 139845451286400 learning.py:512] global step 19393: loss = 4.2426 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19394: loss = 6.4159 (0.098 sec/step)\n",
            "I1003 01:02:32.912505 139845451286400 learning.py:512] global step 19394: loss = 6.4159 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19395: loss = 7.6436 (0.099 sec/step)\n",
            "I1003 01:02:33.012569 139845451286400 learning.py:512] global step 19395: loss = 7.6436 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19396: loss = 4.6654 (0.100 sec/step)\n",
            "I1003 01:02:33.113899 139845451286400 learning.py:512] global step 19396: loss = 4.6654 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19397: loss = 1.6796 (0.099 sec/step)\n",
            "I1003 01:02:33.214481 139845451286400 learning.py:512] global step 19397: loss = 1.6796 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19398: loss = 4.9879 (0.104 sec/step)\n",
            "I1003 01:02:33.320369 139845451286400 learning.py:512] global step 19398: loss = 4.9879 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19399: loss = 9.0357 (0.098 sec/step)\n",
            "I1003 01:02:33.420538 139845451286400 learning.py:512] global step 19399: loss = 9.0357 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19400: loss = 9.0098 (0.099 sec/step)\n",
            "I1003 01:02:33.520473 139845451286400 learning.py:512] global step 19400: loss = 9.0098 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19401: loss = 2.7677 (0.093 sec/step)\n",
            "I1003 01:02:33.614680 139845451286400 learning.py:512] global step 19401: loss = 2.7677 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19402: loss = 3.3571 (0.099 sec/step)\n",
            "I1003 01:02:33.715149 139845451286400 learning.py:512] global step 19402: loss = 3.3571 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19403: loss = 8.9338 (0.108 sec/step)\n",
            "I1003 01:02:33.824050 139845451286400 learning.py:512] global step 19403: loss = 8.9338 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19404: loss = 4.1207 (0.104 sec/step)\n",
            "I1003 01:02:33.929506 139845451286400 learning.py:512] global step 19404: loss = 4.1207 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19405: loss = 2.7303 (0.093 sec/step)\n",
            "I1003 01:02:34.023793 139845451286400 learning.py:512] global step 19405: loss = 2.7303 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19406: loss = 7.3597 (0.093 sec/step)\n",
            "I1003 01:02:34.117862 139845451286400 learning.py:512] global step 19406: loss = 7.3597 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19407: loss = 3.9342 (0.097 sec/step)\n",
            "I1003 01:02:34.216116 139845451286400 learning.py:512] global step 19407: loss = 3.9342 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19408: loss = 5.8675 (0.099 sec/step)\n",
            "I1003 01:02:34.316462 139845451286400 learning.py:512] global step 19408: loss = 5.8675 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19409: loss = 3.6200 (0.094 sec/step)\n",
            "I1003 01:02:34.411478 139845451286400 learning.py:512] global step 19409: loss = 3.6200 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19410: loss = 4.4425 (0.099 sec/step)\n",
            "I1003 01:02:34.511745 139845451286400 learning.py:512] global step 19410: loss = 4.4425 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19411: loss = 3.3914 (0.089 sec/step)\n",
            "I1003 01:02:34.601945 139845451286400 learning.py:512] global step 19411: loss = 3.3914 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 19412: loss = 3.2119 (0.096 sec/step)\n",
            "I1003 01:02:34.698876 139845451286400 learning.py:512] global step 19412: loss = 3.2119 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19413: loss = 5.1347 (0.106 sec/step)\n",
            "I1003 01:02:34.806251 139845451286400 learning.py:512] global step 19413: loss = 5.1347 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19414: loss = 4.3830 (0.108 sec/step)\n",
            "I1003 01:02:34.915932 139845451286400 learning.py:512] global step 19414: loss = 4.3830 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19415: loss = 6.8666 (0.097 sec/step)\n",
            "I1003 01:02:35.014273 139845451286400 learning.py:512] global step 19415: loss = 6.8666 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19416: loss = 9.3572 (0.095 sec/step)\n",
            "I1003 01:02:35.110307 139845451286400 learning.py:512] global step 19416: loss = 9.3572 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19417: loss = 2.3731 (0.092 sec/step)\n",
            "I1003 01:02:35.203551 139845451286400 learning.py:512] global step 19417: loss = 2.3731 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19418: loss = 5.8206 (0.105 sec/step)\n",
            "I1003 01:02:35.310336 139845451286400 learning.py:512] global step 19418: loss = 5.8206 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19419: loss = 5.7008 (0.099 sec/step)\n",
            "I1003 01:02:35.410385 139845451286400 learning.py:512] global step 19419: loss = 5.7008 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19420: loss = 3.5794 (0.097 sec/step)\n",
            "I1003 01:02:35.509068 139845451286400 learning.py:512] global step 19420: loss = 3.5794 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19421: loss = 4.6679 (0.097 sec/step)\n",
            "I1003 01:02:35.607315 139845451286400 learning.py:512] global step 19421: loss = 4.6679 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19422: loss = 3.7409 (0.107 sec/step)\n",
            "I1003 01:02:35.715865 139845451286400 learning.py:512] global step 19422: loss = 3.7409 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19423: loss = 2.8219 (0.102 sec/step)\n",
            "I1003 01:02:35.819368 139845451286400 learning.py:512] global step 19423: loss = 2.8219 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19424: loss = 2.6322 (0.103 sec/step)\n",
            "I1003 01:02:35.923228 139845451286400 learning.py:512] global step 19424: loss = 2.6322 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19425: loss = 8.5537 (0.132 sec/step)\n",
            "I1003 01:02:36.057094 139845451286400 learning.py:512] global step 19425: loss = 8.5537 (0.132 sec/step)\n",
            "INFO:tensorflow:global step 19426: loss = 3.4724 (0.120 sec/step)\n",
            "I1003 01:02:36.178857 139845451286400 learning.py:512] global step 19426: loss = 3.4724 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19427: loss = 2.9492 (0.122 sec/step)\n",
            "I1003 01:02:36.302211 139845451286400 learning.py:512] global step 19427: loss = 2.9492 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19428: loss = 4.1280 (0.106 sec/step)\n",
            "I1003 01:02:36.410143 139845451286400 learning.py:512] global step 19428: loss = 4.1280 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19429: loss = 3.4572 (0.119 sec/step)\n",
            "I1003 01:02:36.531024 139845451286400 learning.py:512] global step 19429: loss = 3.4572 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 19430: loss = 4.3023 (0.117 sec/step)\n",
            "I1003 01:02:36.649573 139845451286400 learning.py:512] global step 19430: loss = 4.3023 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19431: loss = 5.1422 (0.103 sec/step)\n",
            "I1003 01:02:36.753855 139845451286400 learning.py:512] global step 19431: loss = 5.1422 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19432: loss = 3.4475 (0.134 sec/step)\n",
            "I1003 01:02:36.889141 139845451286400 learning.py:512] global step 19432: loss = 3.4475 (0.134 sec/step)\n",
            "INFO:tensorflow:global step 19433: loss = 4.7039 (0.124 sec/step)\n",
            "I1003 01:02:37.014931 139845451286400 learning.py:512] global step 19433: loss = 4.7039 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 19434: loss = 4.7791 (0.112 sec/step)\n",
            "I1003 01:02:37.128101 139845451286400 learning.py:512] global step 19434: loss = 4.7791 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19435: loss = 3.3988 (0.095 sec/step)\n",
            "I1003 01:02:37.224845 139845451286400 learning.py:512] global step 19435: loss = 3.3988 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19436: loss = 2.6794 (0.106 sec/step)\n",
            "I1003 01:02:37.334790 139845451286400 learning.py:512] global step 19436: loss = 2.6794 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19437: loss = 7.2105 (0.110 sec/step)\n",
            "I1003 01:02:37.446460 139845451286400 learning.py:512] global step 19437: loss = 7.2105 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19438: loss = 5.0846 (0.101 sec/step)\n",
            "I1003 01:02:37.548905 139845451286400 learning.py:512] global step 19438: loss = 5.0846 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19439: loss = 4.8353 (0.092 sec/step)\n",
            "I1003 01:02:37.642148 139845451286400 learning.py:512] global step 19439: loss = 4.8353 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19440: loss = 5.9340 (0.100 sec/step)\n",
            "I1003 01:02:37.743162 139845451286400 learning.py:512] global step 19440: loss = 5.9340 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19441: loss = 3.6845 (0.100 sec/step)\n",
            "I1003 01:02:37.844593 139845451286400 learning.py:512] global step 19441: loss = 3.6845 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19442: loss = 3.4749 (0.118 sec/step)\n",
            "I1003 01:02:37.965221 139845451286400 learning.py:512] global step 19442: loss = 3.4749 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19443: loss = 2.4017 (0.113 sec/step)\n",
            "I1003 01:02:38.079835 139845451286400 learning.py:512] global step 19443: loss = 2.4017 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 19444: loss = 5.7439 (0.122 sec/step)\n",
            "I1003 01:02:38.203630 139845451286400 learning.py:512] global step 19444: loss = 5.7439 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19445: loss = 6.2386 (0.094 sec/step)\n",
            "I1003 01:02:38.298596 139845451286400 learning.py:512] global step 19445: loss = 6.2386 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19446: loss = 3.4303 (0.109 sec/step)\n",
            "I1003 01:02:38.408899 139845451286400 learning.py:512] global step 19446: loss = 3.4303 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19447: loss = 3.2993 (0.114 sec/step)\n",
            "I1003 01:02:38.524264 139845451286400 learning.py:512] global step 19447: loss = 3.2993 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19448: loss = 4.7311 (0.098 sec/step)\n",
            "I1003 01:02:38.623336 139845451286400 learning.py:512] global step 19448: loss = 4.7311 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19449: loss = 3.3663 (0.089 sec/step)\n",
            "I1003 01:02:38.713486 139845451286400 learning.py:512] global step 19449: loss = 3.3663 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 19450: loss = 5.9557 (0.121 sec/step)\n",
            "I1003 01:02:38.835355 139845451286400 learning.py:512] global step 19450: loss = 5.9557 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19451: loss = 3.6231 (0.132 sec/step)\n",
            "I1003 01:02:38.968725 139845451286400 learning.py:512] global step 19451: loss = 3.6231 (0.132 sec/step)\n",
            "INFO:tensorflow:global step 19452: loss = 2.6860 (0.091 sec/step)\n",
            "I1003 01:02:39.061353 139845451286400 learning.py:512] global step 19452: loss = 2.6860 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19453: loss = 3.5061 (0.102 sec/step)\n",
            "I1003 01:02:39.164388 139845451286400 learning.py:512] global step 19453: loss = 3.5061 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19454: loss = 3.0437 (0.113 sec/step)\n",
            "I1003 01:02:39.278697 139845451286400 learning.py:512] global step 19454: loss = 3.0437 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 19455: loss = 6.7979 (0.111 sec/step)\n",
            "I1003 01:02:39.391042 139845451286400 learning.py:512] global step 19455: loss = 6.7979 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19456: loss = 3.3147 (0.112 sec/step)\n",
            "I1003 01:02:39.504288 139845451286400 learning.py:512] global step 19456: loss = 3.3147 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19457: loss = 2.5264 (0.106 sec/step)\n",
            "I1003 01:02:39.611793 139845451286400 learning.py:512] global step 19457: loss = 2.5264 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19458: loss = 7.0727 (0.124 sec/step)\n",
            "I1003 01:02:39.737232 139845451286400 learning.py:512] global step 19458: loss = 7.0727 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 19459: loss = 3.1096 (0.102 sec/step)\n",
            "I1003 01:02:39.841562 139845451286400 learning.py:512] global step 19459: loss = 3.1096 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19460: loss = 4.3487 (0.110 sec/step)\n",
            "I1003 01:02:39.953532 139845451286400 learning.py:512] global step 19460: loss = 4.3487 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19461: loss = 1.9100 (0.106 sec/step)\n",
            "I1003 01:02:40.060993 139845451286400 learning.py:512] global step 19461: loss = 1.9100 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19462: loss = 5.2113 (0.107 sec/step)\n",
            "I1003 01:02:40.169531 139845451286400 learning.py:512] global step 19462: loss = 5.2113 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19463: loss = 3.5000 (0.097 sec/step)\n",
            "I1003 01:02:40.268488 139845451286400 learning.py:512] global step 19463: loss = 3.5000 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19464: loss = 2.7911 (0.096 sec/step)\n",
            "I1003 01:02:40.366266 139845451286400 learning.py:512] global step 19464: loss = 2.7911 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19465: loss = 6.9651 (0.102 sec/step)\n",
            "I1003 01:02:40.469569 139845451286400 learning.py:512] global step 19465: loss = 6.9651 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19466: loss = 2.7825 (0.102 sec/step)\n",
            "I1003 01:02:40.573334 139845451286400 learning.py:512] global step 19466: loss = 2.7825 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19467: loss = 9.8584 (0.095 sec/step)\n",
            "I1003 01:02:40.669687 139845451286400 learning.py:512] global step 19467: loss = 9.8584 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19468: loss = 2.8072 (0.105 sec/step)\n",
            "I1003 01:02:40.775725 139845451286400 learning.py:512] global step 19468: loss = 2.8072 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19469: loss = 5.4091 (0.108 sec/step)\n",
            "I1003 01:02:40.884722 139845451286400 learning.py:512] global step 19469: loss = 5.4091 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19470: loss = 2.9965 (0.111 sec/step)\n",
            "I1003 01:02:40.997168 139845451286400 learning.py:512] global step 19470: loss = 2.9965 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19471: loss = 4.6798 (0.101 sec/step)\n",
            "I1003 01:02:41.100596 139845451286400 learning.py:512] global step 19471: loss = 4.6798 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19472: loss = 6.0751 (0.094 sec/step)\n",
            "I1003 01:02:41.195510 139845451286400 learning.py:512] global step 19472: loss = 6.0751 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19473: loss = 9.6939 (0.100 sec/step)\n",
            "I1003 01:02:41.297342 139845451286400 learning.py:512] global step 19473: loss = 9.6939 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19474: loss = 2.5304 (0.090 sec/step)\n",
            "I1003 01:02:41.389079 139845451286400 learning.py:512] global step 19474: loss = 2.5304 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19475: loss = 2.9056 (0.090 sec/step)\n",
            "I1003 01:02:41.480268 139845451286400 learning.py:512] global step 19475: loss = 2.9056 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19476: loss = 5.2441 (0.112 sec/step)\n",
            "I1003 01:02:41.593619 139845451286400 learning.py:512] global step 19476: loss = 5.2441 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19477: loss = 5.7362 (0.092 sec/step)\n",
            "I1003 01:02:41.686874 139845451286400 learning.py:512] global step 19477: loss = 5.7362 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19478: loss = 2.9436 (0.113 sec/step)\n",
            "I1003 01:02:41.802765 139845451286400 learning.py:512] global step 19478: loss = 2.9436 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 19479: loss = 4.1884 (0.097 sec/step)\n",
            "I1003 01:02:41.900733 139845451286400 learning.py:512] global step 19479: loss = 4.1884 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19480: loss = 8.0362 (0.112 sec/step)\n",
            "I1003 01:02:42.015139 139845451286400 learning.py:512] global step 19480: loss = 8.0362 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19481: loss = 4.9495 (0.101 sec/step)\n",
            "I1003 01:02:42.118101 139845451286400 learning.py:512] global step 19481: loss = 4.9495 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19482: loss = 3.3732 (0.091 sec/step)\n",
            "I1003 01:02:42.210355 139845451286400 learning.py:512] global step 19482: loss = 3.3732 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19483: loss = 7.9492 (0.105 sec/step)\n",
            "I1003 01:02:42.316411 139845451286400 learning.py:512] global step 19483: loss = 7.9492 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19484: loss = 4.1311 (0.101 sec/step)\n",
            "I1003 01:02:42.418478 139845451286400 learning.py:512] global step 19484: loss = 4.1311 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19485: loss = 6.9363 (0.086 sec/step)\n",
            "I1003 01:02:42.506072 139845451286400 learning.py:512] global step 19485: loss = 6.9363 (0.086 sec/step)\n",
            "INFO:tensorflow:global step 19486: loss = 2.3379 (0.090 sec/step)\n",
            "I1003 01:02:42.597540 139845451286400 learning.py:512] global step 19486: loss = 2.3379 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19487: loss = 2.9563 (0.095 sec/step)\n",
            "I1003 01:02:42.695026 139845451286400 learning.py:512] global step 19487: loss = 2.9563 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19488: loss = 3.7060 (0.091 sec/step)\n",
            "I1003 01:02:42.787865 139845451286400 learning.py:512] global step 19488: loss = 3.7060 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19489: loss = 6.1666 (0.110 sec/step)\n",
            "I1003 01:02:42.899332 139845451286400 learning.py:512] global step 19489: loss = 6.1666 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19490: loss = 2.9243 (0.100 sec/step)\n",
            "I1003 01:02:43.000728 139845451286400 learning.py:512] global step 19490: loss = 2.9243 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19491: loss = 3.4054 (0.104 sec/step)\n",
            "I1003 01:02:43.105782 139845451286400 learning.py:512] global step 19491: loss = 3.4054 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19492: loss = 7.0335 (0.100 sec/step)\n",
            "I1003 01:02:43.207680 139845451286400 learning.py:512] global step 19492: loss = 7.0335 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19493: loss = 3.5124 (0.102 sec/step)\n",
            "I1003 01:02:43.310864 139845451286400 learning.py:512] global step 19493: loss = 3.5124 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19494: loss = 4.7568 (0.095 sec/step)\n",
            "I1003 01:02:43.406938 139845451286400 learning.py:512] global step 19494: loss = 4.7568 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19495: loss = 3.1340 (0.111 sec/step)\n",
            "I1003 01:02:43.519144 139845451286400 learning.py:512] global step 19495: loss = 3.1340 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19496: loss = 3.5479 (0.087 sec/step)\n",
            "I1003 01:02:43.607145 139845451286400 learning.py:512] global step 19496: loss = 3.5479 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 19497: loss = 4.4808 (0.096 sec/step)\n",
            "I1003 01:02:43.704319 139845451286400 learning.py:512] global step 19497: loss = 4.4808 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19498: loss = 2.0049 (0.106 sec/step)\n",
            "I1003 01:02:43.811578 139845451286400 learning.py:512] global step 19498: loss = 2.0049 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19499: loss = 3.0399 (0.096 sec/step)\n",
            "I1003 01:02:43.908867 139845451286400 learning.py:512] global step 19499: loss = 3.0399 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19500: loss = 7.2179 (0.106 sec/step)\n",
            "I1003 01:02:44.016142 139845451286400 learning.py:512] global step 19500: loss = 7.2179 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19501: loss = 3.1027 (0.107 sec/step)\n",
            "I1003 01:02:44.124657 139845451286400 learning.py:512] global step 19501: loss = 3.1027 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19502: loss = 6.1864 (0.120 sec/step)\n",
            "I1003 01:02:44.246493 139845451286400 learning.py:512] global step 19502: loss = 6.1864 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19503: loss = 2.4015 (0.108 sec/step)\n",
            "I1003 01:02:44.355923 139845451286400 learning.py:512] global step 19503: loss = 2.4015 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19504: loss = 2.9008 (0.117 sec/step)\n",
            "I1003 01:02:44.474595 139845451286400 learning.py:512] global step 19504: loss = 2.9008 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19505: loss = 3.3502 (0.115 sec/step)\n",
            "I1003 01:02:44.590928 139845451286400 learning.py:512] global step 19505: loss = 3.3502 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19506: loss = 2.9004 (0.122 sec/step)\n",
            "I1003 01:02:44.713930 139845451286400 learning.py:512] global step 19506: loss = 2.9004 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19507: loss = 2.6885 (0.125 sec/step)\n",
            "I1003 01:02:44.840914 139845451286400 learning.py:512] global step 19507: loss = 2.6885 (0.125 sec/step)\n",
            "INFO:tensorflow:global step 19508: loss = 3.7000 (0.141 sec/step)\n",
            "I1003 01:02:44.983715 139845451286400 learning.py:512] global step 19508: loss = 3.7000 (0.141 sec/step)\n",
            "INFO:tensorflow:global step 19509: loss = 2.7276 (0.100 sec/step)\n",
            "I1003 01:02:45.084997 139845451286400 learning.py:512] global step 19509: loss = 2.7276 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19510: loss = 5.7562 (0.103 sec/step)\n",
            "I1003 01:02:45.189079 139845451286400 learning.py:512] global step 19510: loss = 5.7562 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19511: loss = 2.9830 (0.112 sec/step)\n",
            "I1003 01:02:45.302641 139845451286400 learning.py:512] global step 19511: loss = 2.9830 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19512: loss = 4.1111 (0.112 sec/step)\n",
            "I1003 01:02:45.416302 139845451286400 learning.py:512] global step 19512: loss = 4.1111 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19513: loss = 2.7331 (0.114 sec/step)\n",
            "I1003 01:02:45.531766 139845451286400 learning.py:512] global step 19513: loss = 2.7331 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19514: loss = 2.2018 (0.121 sec/step)\n",
            "I1003 01:02:45.654072 139845451286400 learning.py:512] global step 19514: loss = 2.2018 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19515: loss = 2.0848 (0.120 sec/step)\n",
            "I1003 01:02:45.775655 139845451286400 learning.py:512] global step 19515: loss = 2.0848 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19516: loss = 3.2898 (0.116 sec/step)\n",
            "I1003 01:02:45.892711 139845451286400 learning.py:512] global step 19516: loss = 3.2898 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 19517: loss = 4.6360 (0.137 sec/step)\n",
            "I1003 01:02:46.031313 139845451286400 learning.py:512] global step 19517: loss = 4.6360 (0.137 sec/step)\n",
            "INFO:tensorflow:global step 19518: loss = 7.1418 (0.113 sec/step)\n",
            "I1003 01:02:46.145830 139845451286400 learning.py:512] global step 19518: loss = 7.1418 (0.113 sec/step)\n",
            "INFO:tensorflow:global step 19519: loss = 2.9507 (0.114 sec/step)\n",
            "I1003 01:02:46.261281 139845451286400 learning.py:512] global step 19519: loss = 2.9507 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19520: loss = 2.6628 (0.126 sec/step)\n",
            "I1003 01:02:46.389095 139845451286400 learning.py:512] global step 19520: loss = 2.6628 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 19521: loss = 3.7126 (0.109 sec/step)\n",
            "I1003 01:02:46.500006 139845451286400 learning.py:512] global step 19521: loss = 3.7126 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19522: loss = 4.2318 (0.134 sec/step)\n",
            "I1003 01:02:46.635871 139845451286400 learning.py:512] global step 19522: loss = 4.2318 (0.134 sec/step)\n",
            "INFO:tensorflow:global step 19523: loss = 4.7770 (0.116 sec/step)\n",
            "I1003 01:02:46.753681 139845451286400 learning.py:512] global step 19523: loss = 4.7770 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 19524: loss = 5.5911 (0.106 sec/step)\n",
            "I1003 01:02:46.861177 139845451286400 learning.py:512] global step 19524: loss = 5.5911 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19525: loss = 3.5433 (0.098 sec/step)\n",
            "I1003 01:02:46.961236 139845451286400 learning.py:512] global step 19525: loss = 3.5433 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19526: loss = 2.8254 (0.108 sec/step)\n",
            "I1003 01:02:47.070107 139845451286400 learning.py:512] global step 19526: loss = 2.8254 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19527: loss = 4.7332 (0.117 sec/step)\n",
            "I1003 01:02:47.188883 139845451286400 learning.py:512] global step 19527: loss = 4.7332 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19528: loss = 2.8351 (0.097 sec/step)\n",
            "I1003 01:02:47.287672 139845451286400 learning.py:512] global step 19528: loss = 2.8351 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19529: loss = 4.4914 (0.092 sec/step)\n",
            "I1003 01:02:47.381649 139845451286400 learning.py:512] global step 19529: loss = 4.4914 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19530: loss = 6.0056 (0.105 sec/step)\n",
            "I1003 01:02:47.488439 139845451286400 learning.py:512] global step 19530: loss = 6.0056 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19531: loss = 3.0765 (0.109 sec/step)\n",
            "I1003 01:02:47.599425 139845451286400 learning.py:512] global step 19531: loss = 3.0765 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19532: loss = 3.9617 (0.098 sec/step)\n",
            "I1003 01:02:47.698830 139845451286400 learning.py:512] global step 19532: loss = 3.9617 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19533: loss = 3.2893 (0.100 sec/step)\n",
            "I1003 01:02:47.800639 139845451286400 learning.py:512] global step 19533: loss = 3.2893 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19534: loss = 3.4313 (0.104 sec/step)\n",
            "I1003 01:02:47.906004 139845451286400 learning.py:512] global step 19534: loss = 3.4313 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19535: loss = 6.6802 (0.102 sec/step)\n",
            "I1003 01:02:48.009370 139845451286400 learning.py:512] global step 19535: loss = 6.6802 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19536: loss = 2.3112 (0.123 sec/step)\n",
            "I1003 01:02:48.133559 139845451286400 learning.py:512] global step 19536: loss = 2.3112 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 19537: loss = 4.9668 (0.108 sec/step)\n",
            "I1003 01:02:48.243075 139845451286400 learning.py:512] global step 19537: loss = 4.9668 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19538: loss = 3.2110 (0.100 sec/step)\n",
            "I1003 01:02:48.344800 139845451286400 learning.py:512] global step 19538: loss = 3.2110 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19539: loss = 2.6325 (0.098 sec/step)\n",
            "I1003 01:02:48.444556 139845451286400 learning.py:512] global step 19539: loss = 2.6325 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19540: loss = 10.1983 (0.101 sec/step)\n",
            "I1003 01:02:48.546758 139845451286400 learning.py:512] global step 19540: loss = 10.1983 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19541: loss = 4.3680 (0.099 sec/step)\n",
            "I1003 01:02:48.647598 139845451286400 learning.py:512] global step 19541: loss = 4.3680 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19542: loss = 2.5548 (0.093 sec/step)\n",
            "I1003 01:02:48.742169 139845451286400 learning.py:512] global step 19542: loss = 2.5548 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19543: loss = 2.6829 (0.091 sec/step)\n",
            "I1003 01:02:48.834763 139845451286400 learning.py:512] global step 19543: loss = 2.6829 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19544: loss = 3.4004 (0.101 sec/step)\n",
            "I1003 01:02:48.937024 139845451286400 learning.py:512] global step 19544: loss = 3.4004 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19545: loss = 3.0427 (0.114 sec/step)\n",
            "I1003 01:02:49.052100 139845451286400 learning.py:512] global step 19545: loss = 3.0427 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19546: loss = 10.5989 (0.102 sec/step)\n",
            "I1003 01:02:49.155713 139845451286400 learning.py:512] global step 19546: loss = 10.5989 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19547: loss = 3.4555 (0.091 sec/step)\n",
            "I1003 01:02:49.248672 139845451286400 learning.py:512] global step 19547: loss = 3.4555 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19548: loss = 4.9375 (0.095 sec/step)\n",
            "I1003 01:02:49.344789 139845451286400 learning.py:512] global step 19548: loss = 4.9375 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19549: loss = 4.4526 (0.092 sec/step)\n",
            "I1003 01:02:49.438633 139845451286400 learning.py:512] global step 19549: loss = 4.4526 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19550: loss = 2.0654 (0.098 sec/step)\n",
            "I1003 01:02:49.542731 139845451286400 learning.py:512] global step 19550: loss = 2.0654 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19551: loss = 3.4738 (0.096 sec/step)\n",
            "I1003 01:02:49.640557 139845451286400 learning.py:512] global step 19551: loss = 3.4738 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19552: loss = 3.1794 (0.093 sec/step)\n",
            "I1003 01:02:49.735212 139845451286400 learning.py:512] global step 19552: loss = 3.1794 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19553: loss = 4.2693 (0.101 sec/step)\n",
            "I1003 01:02:49.837835 139845451286400 learning.py:512] global step 19553: loss = 4.2693 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19554: loss = 3.1887 (0.107 sec/step)\n",
            "I1003 01:02:49.946677 139845451286400 learning.py:512] global step 19554: loss = 3.1887 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19555: loss = 2.1469 (0.108 sec/step)\n",
            "I1003 01:02:50.058259 139845451286400 learning.py:512] global step 19555: loss = 2.1469 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19556: loss = 5.5722 (0.102 sec/step)\n",
            "I1003 01:02:50.162250 139845451286400 learning.py:512] global step 19556: loss = 5.5722 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19557: loss = 7.1317 (0.102 sec/step)\n",
            "I1003 01:02:50.265922 139845451286400 learning.py:512] global step 19557: loss = 7.1317 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19558: loss = 6.0508 (0.111 sec/step)\n",
            "I1003 01:02:50.378551 139845451286400 learning.py:512] global step 19558: loss = 6.0508 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19559: loss = 3.3113 (0.096 sec/step)\n",
            "I1003 01:02:50.476027 139845451286400 learning.py:512] global step 19559: loss = 3.3113 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19560: loss = 2.7399 (0.098 sec/step)\n",
            "I1003 01:02:50.575505 139845451286400 learning.py:512] global step 19560: loss = 2.7399 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19561: loss = 3.9080 (0.109 sec/step)\n",
            "I1003 01:02:50.687552 139845451286400 learning.py:512] global step 19561: loss = 3.9080 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19562: loss = 11.2725 (0.098 sec/step)\n",
            "I1003 01:02:50.787088 139845451286400 learning.py:512] global step 19562: loss = 11.2725 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19563: loss = 2.1818 (0.091 sec/step)\n",
            "I1003 01:02:50.879586 139845451286400 learning.py:512] global step 19563: loss = 2.1818 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19564: loss = 2.3709 (0.096 sec/step)\n",
            "I1003 01:02:50.977163 139845451286400 learning.py:512] global step 19564: loss = 2.3709 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19565: loss = 6.6446 (0.131 sec/step)\n",
            "I1003 01:02:51.109614 139845451286400 learning.py:512] global step 19565: loss = 6.6446 (0.131 sec/step)\n",
            "INFO:tensorflow:global step 19566: loss = 2.6841 (0.112 sec/step)\n",
            "I1003 01:02:51.223184 139845451286400 learning.py:512] global step 19566: loss = 2.6841 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19567: loss = 2.6442 (0.097 sec/step)\n",
            "I1003 01:02:51.321864 139845451286400 learning.py:512] global step 19567: loss = 2.6442 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19568: loss = 4.6734 (0.108 sec/step)\n",
            "I1003 01:02:51.431485 139845451286400 learning.py:512] global step 19568: loss = 4.6734 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19569: loss = 3.2698 (0.100 sec/step)\n",
            "I1003 01:02:51.532836 139845451286400 learning.py:512] global step 19569: loss = 3.2698 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19570: loss = 3.9399 (0.104 sec/step)\n",
            "I1003 01:02:51.637790 139845451286400 learning.py:512] global step 19570: loss = 3.9399 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19571: loss = 3.4271 (0.095 sec/step)\n",
            "I1003 01:02:51.734221 139845451286400 learning.py:512] global step 19571: loss = 3.4271 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19572: loss = 2.0259 (0.103 sec/step)\n",
            "I1003 01:02:51.838913 139845451286400 learning.py:512] global step 19572: loss = 2.0259 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19573: loss = 13.6794 (0.098 sec/step)\n",
            "I1003 01:02:51.938581 139845451286400 learning.py:512] global step 19573: loss = 13.6794 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19574: loss = 3.2992 (0.092 sec/step)\n",
            "I1003 01:02:52.032216 139845451286400 learning.py:512] global step 19574: loss = 3.2992 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19575: loss = 3.9379 (0.101 sec/step)\n",
            "I1003 01:02:52.134684 139845451286400 learning.py:512] global step 19575: loss = 3.9379 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19576: loss = 3.5154 (0.115 sec/step)\n",
            "I1003 01:02:52.250635 139845451286400 learning.py:512] global step 19576: loss = 3.5154 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19577: loss = 4.9189 (0.090 sec/step)\n",
            "I1003 01:02:52.342016 139845451286400 learning.py:512] global step 19577: loss = 4.9189 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19578: loss = 5.5851 (0.097 sec/step)\n",
            "I1003 01:02:52.440736 139845451286400 learning.py:512] global step 19578: loss = 5.5851 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19579: loss = 3.9918 (0.102 sec/step)\n",
            "I1003 01:02:52.544188 139845451286400 learning.py:512] global step 19579: loss = 3.9918 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19580: loss = 4.0693 (0.117 sec/step)\n",
            "I1003 01:02:52.662847 139845451286400 learning.py:512] global step 19580: loss = 4.0693 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19581: loss = 6.0797 (0.099 sec/step)\n",
            "I1003 01:02:52.763557 139845451286400 learning.py:512] global step 19581: loss = 6.0797 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19582: loss = 6.1826 (0.099 sec/step)\n",
            "I1003 01:02:52.863496 139845451286400 learning.py:512] global step 19582: loss = 6.1826 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19583: loss = 1.7557 (0.115 sec/step)\n",
            "I1003 01:02:52.979702 139845451286400 learning.py:512] global step 19583: loss = 1.7557 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19584: loss = 2.2147 (0.103 sec/step)\n",
            "I1003 01:02:53.084505 139845451286400 learning.py:512] global step 19584: loss = 2.2147 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19585: loss = 3.4947 (0.118 sec/step)\n",
            "I1003 01:02:53.203668 139845451286400 learning.py:512] global step 19585: loss = 3.4947 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19586: loss = 3.4878 (0.107 sec/step)\n",
            "I1003 01:02:53.311539 139845451286400 learning.py:512] global step 19586: loss = 3.4878 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19587: loss = 8.5243 (0.100 sec/step)\n",
            "I1003 01:02:53.412997 139845451286400 learning.py:512] global step 19587: loss = 8.5243 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19588: loss = 4.5954 (0.092 sec/step)\n",
            "I1003 01:02:53.508139 139845451286400 learning.py:512] global step 19588: loss = 4.5954 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19589: loss = 3.1504 (0.095 sec/step)\n",
            "I1003 01:02:53.605161 139845451286400 learning.py:512] global step 19589: loss = 3.1504 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19590: loss = 5.8000 (0.107 sec/step)\n",
            "I1003 01:02:53.713772 139845451286400 learning.py:512] global step 19590: loss = 5.8000 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19591: loss = 7.5864 (0.098 sec/step)\n",
            "I1003 01:02:53.812702 139845451286400 learning.py:512] global step 19591: loss = 7.5864 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19592: loss = 2.6168 (0.103 sec/step)\n",
            "I1003 01:02:53.917014 139845451286400 learning.py:512] global step 19592: loss = 2.6168 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19593: loss = 2.9477 (0.098 sec/step)\n",
            "I1003 01:02:54.017576 139845451286400 learning.py:512] global step 19593: loss = 2.9477 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19594: loss = 3.4730 (0.129 sec/step)\n",
            "I1003 01:02:54.147671 139845451286400 learning.py:512] global step 19594: loss = 3.4730 (0.129 sec/step)\n",
            "INFO:tensorflow:global step 19595: loss = 4.8589 (0.105 sec/step)\n",
            "I1003 01:02:54.254133 139845451286400 learning.py:512] global step 19595: loss = 4.8589 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19596: loss = 2.7062 (0.096 sec/step)\n",
            "I1003 01:02:54.351429 139845451286400 learning.py:512] global step 19596: loss = 2.7062 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19597: loss = 1.7584 (0.102 sec/step)\n",
            "I1003 01:02:54.454859 139845451286400 learning.py:512] global step 19597: loss = 1.7584 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19598: loss = 3.7877 (0.114 sec/step)\n",
            "I1003 01:02:54.569653 139845451286400 learning.py:512] global step 19598: loss = 3.7877 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19599: loss = 4.3262 (0.092 sec/step)\n",
            "I1003 01:02:54.662707 139845451286400 learning.py:512] global step 19599: loss = 4.3262 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19600: loss = 3.0928 (0.101 sec/step)\n",
            "I1003 01:02:54.764631 139845451286400 learning.py:512] global step 19600: loss = 3.0928 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19601: loss = 3.4754 (0.104 sec/step)\n",
            "I1003 01:02:54.870371 139845451286400 learning.py:512] global step 19601: loss = 3.4754 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19602: loss = 6.3475 (0.100 sec/step)\n",
            "I1003 01:02:54.971743 139845451286400 learning.py:512] global step 19602: loss = 6.3475 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19603: loss = 3.6179 (0.099 sec/step)\n",
            "I1003 01:02:55.072266 139845451286400 learning.py:512] global step 19603: loss = 3.6179 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19604: loss = 1.9698 (0.108 sec/step)\n",
            "I1003 01:02:55.181494 139845451286400 learning.py:512] global step 19604: loss = 1.9698 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19605: loss = 2.3803 (0.110 sec/step)\n",
            "I1003 01:02:55.292979 139845451286400 learning.py:512] global step 19605: loss = 2.3803 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19606: loss = 2.2929 (0.122 sec/step)\n",
            "I1003 01:02:55.416267 139845451286400 learning.py:512] global step 19606: loss = 2.2929 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19607: loss = 2.6527 (0.110 sec/step)\n",
            "I1003 01:02:55.527582 139845451286400 learning.py:512] global step 19607: loss = 2.6527 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19608: loss = 2.7005 (0.115 sec/step)\n",
            "I1003 01:02:55.643775 139845451286400 learning.py:512] global step 19608: loss = 2.7005 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19609: loss = 6.8793 (0.106 sec/step)\n",
            "I1003 01:02:55.751619 139845451286400 learning.py:512] global step 19609: loss = 6.8793 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19610: loss = 4.7000 (0.095 sec/step)\n",
            "I1003 01:02:55.848171 139845451286400 learning.py:512] global step 19610: loss = 4.7000 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19611: loss = 6.1799 (0.091 sec/step)\n",
            "I1003 01:02:55.940955 139845451286400 learning.py:512] global step 19611: loss = 6.1799 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19612: loss = 3.2221 (0.097 sec/step)\n",
            "I1003 01:02:56.038753 139845451286400 learning.py:512] global step 19612: loss = 3.2221 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19613: loss = 3.2205 (0.094 sec/step)\n",
            "I1003 01:02:56.134599 139845451286400 learning.py:512] global step 19613: loss = 3.2205 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19614: loss = 10.1249 (0.085 sec/step)\n",
            "I1003 01:02:56.220550 139845451286400 learning.py:512] global step 19614: loss = 10.1249 (0.085 sec/step)\n",
            "INFO:tensorflow:global step 19615: loss = 2.8713 (0.107 sec/step)\n",
            "I1003 01:02:56.329307 139845451286400 learning.py:512] global step 19615: loss = 2.8713 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19616: loss = 5.9155 (0.092 sec/step)\n",
            "I1003 01:02:56.423154 139845451286400 learning.py:512] global step 19616: loss = 5.9155 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19617: loss = 3.8944 (0.097 sec/step)\n",
            "I1003 01:02:56.521210 139845451286400 learning.py:512] global step 19617: loss = 3.8944 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19618: loss = 6.1577 (0.096 sec/step)\n",
            "I1003 01:02:56.618904 139845451286400 learning.py:512] global step 19618: loss = 6.1577 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19619: loss = 5.1642 (0.099 sec/step)\n",
            "I1003 01:02:56.719321 139845451286400 learning.py:512] global step 19619: loss = 5.1642 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19620: loss = 2.8033 (0.099 sec/step)\n",
            "I1003 01:02:56.819593 139845451286400 learning.py:512] global step 19620: loss = 2.8033 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19621: loss = 7.6276 (0.095 sec/step)\n",
            "I1003 01:02:56.915938 139845451286400 learning.py:512] global step 19621: loss = 7.6276 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19622: loss = 3.2172 (0.110 sec/step)\n",
            "I1003 01:02:57.026822 139845451286400 learning.py:512] global step 19622: loss = 3.2172 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19623: loss = 4.3118 (0.106 sec/step)\n",
            "I1003 01:02:57.133760 139845451286400 learning.py:512] global step 19623: loss = 4.3118 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19624: loss = 6.3803 (0.097 sec/step)\n",
            "I1003 01:02:57.232016 139845451286400 learning.py:512] global step 19624: loss = 6.3803 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19625: loss = 5.3431 (0.098 sec/step)\n",
            "I1003 01:02:57.331109 139845451286400 learning.py:512] global step 19625: loss = 5.3431 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19626: loss = 2.3440 (0.099 sec/step)\n",
            "I1003 01:02:57.431279 139845451286400 learning.py:512] global step 19626: loss = 2.3440 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19627: loss = 3.8760 (0.089 sec/step)\n",
            "I1003 01:02:57.521230 139845451286400 learning.py:512] global step 19627: loss = 3.8760 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 19628: loss = 7.0670 (0.106 sec/step)\n",
            "I1003 01:02:57.628986 139845451286400 learning.py:512] global step 19628: loss = 7.0670 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19629: loss = 3.0021 (0.089 sec/step)\n",
            "I1003 01:02:57.719828 139845451286400 learning.py:512] global step 19629: loss = 3.0021 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 19630: loss = 3.3471 (0.105 sec/step)\n",
            "I1003 01:02:57.825841 139845451286400 learning.py:512] global step 19630: loss = 3.3471 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19631: loss = 4.5467 (0.100 sec/step)\n",
            "I1003 01:02:57.926845 139845451286400 learning.py:512] global step 19631: loss = 4.5467 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19632: loss = 3.5248 (0.107 sec/step)\n",
            "I1003 01:02:58.035234 139845451286400 learning.py:512] global step 19632: loss = 3.5248 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19633: loss = 7.0814 (0.097 sec/step)\n",
            "I1003 01:02:58.133308 139845451286400 learning.py:512] global step 19633: loss = 7.0814 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19634: loss = 7.2722 (0.123 sec/step)\n",
            "I1003 01:02:58.257662 139845451286400 learning.py:512] global step 19634: loss = 7.2722 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 19635: loss = 4.1468 (0.117 sec/step)\n",
            "I1003 01:02:58.376248 139845451286400 learning.py:512] global step 19635: loss = 4.1468 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19636: loss = 2.8648 (0.111 sec/step)\n",
            "I1003 01:02:58.489285 139845451286400 learning.py:512] global step 19636: loss = 2.8648 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19637: loss = 2.9503 (0.122 sec/step)\n",
            "I1003 01:02:58.613224 139845451286400 learning.py:512] global step 19637: loss = 2.9503 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19638: loss = 2.3271 (0.109 sec/step)\n",
            "I1003 01:02:58.724096 139845451286400 learning.py:512] global step 19638: loss = 2.3271 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19639: loss = 5.8808 (0.092 sec/step)\n",
            "I1003 01:02:58.817124 139845451286400 learning.py:512] global step 19639: loss = 5.8808 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19640: loss = 7.2260 (0.097 sec/step)\n",
            "I1003 01:02:58.915624 139845451286400 learning.py:512] global step 19640: loss = 7.2260 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19641: loss = 2.9707 (0.098 sec/step)\n",
            "I1003 01:02:59.015044 139845451286400 learning.py:512] global step 19641: loss = 2.9707 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19642: loss = 2.9188 (0.105 sec/step)\n",
            "I1003 01:02:59.122061 139845451286400 learning.py:512] global step 19642: loss = 2.9188 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19643: loss = 3.0685 (0.108 sec/step)\n",
            "I1003 01:02:59.231431 139845451286400 learning.py:512] global step 19643: loss = 3.0685 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19644: loss = 3.3387 (0.120 sec/step)\n",
            "I1003 01:02:59.354434 139845451286400 learning.py:512] global step 19644: loss = 3.3387 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19645: loss = 2.8357 (0.122 sec/step)\n",
            "I1003 01:02:59.478200 139845451286400 learning.py:512] global step 19645: loss = 2.8357 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19646: loss = 5.6984 (0.114 sec/step)\n",
            "I1003 01:02:59.594158 139845451286400 learning.py:512] global step 19646: loss = 5.6984 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19647: loss = 5.4140 (0.115 sec/step)\n",
            "I1003 01:02:59.711273 139845451286400 learning.py:512] global step 19647: loss = 5.4140 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19648: loss = 3.2500 (0.098 sec/step)\n",
            "I1003 01:02:59.810620 139845451286400 learning.py:512] global step 19648: loss = 3.2500 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19649: loss = 5.9649 (0.105 sec/step)\n",
            "I1003 01:02:59.916947 139845451286400 learning.py:512] global step 19649: loss = 5.9649 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19650: loss = 2.7418 (0.112 sec/step)\n",
            "I1003 01:03:00.030597 139845451286400 learning.py:512] global step 19650: loss = 2.7418 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19651: loss = 2.9742 (0.110 sec/step)\n",
            "I1003 01:03:00.142026 139845451286400 learning.py:512] global step 19651: loss = 2.9742 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19652: loss = 4.0529 (0.109 sec/step)\n",
            "I1003 01:03:00.252691 139845451286400 learning.py:512] global step 19652: loss = 4.0529 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19653: loss = 3.9853 (0.120 sec/step)\n",
            "I1003 01:03:00.373700 139845451286400 learning.py:512] global step 19653: loss = 3.9853 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19654: loss = 4.0929 (0.126 sec/step)\n",
            "I1003 01:03:00.501277 139845451286400 learning.py:512] global step 19654: loss = 4.0929 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 19655: loss = 3.7907 (0.121 sec/step)\n",
            "I1003 01:03:00.623523 139845451286400 learning.py:512] global step 19655: loss = 3.7907 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19656: loss = 3.1916 (0.118 sec/step)\n",
            "I1003 01:03:00.743147 139845451286400 learning.py:512] global step 19656: loss = 3.1916 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19657: loss = 3.3883 (0.090 sec/step)\n",
            "I1003 01:03:00.834236 139845451286400 learning.py:512] global step 19657: loss = 3.3883 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19658: loss = 3.1591 (0.108 sec/step)\n",
            "I1003 01:03:00.943474 139845451286400 learning.py:512] global step 19658: loss = 3.1591 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19659: loss = 3.6146 (0.106 sec/step)\n",
            "I1003 01:03:01.050488 139845451286400 learning.py:512] global step 19659: loss = 3.6146 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19660: loss = 5.6794 (0.104 sec/step)\n",
            "I1003 01:03:01.155959 139845451286400 learning.py:512] global step 19660: loss = 5.6794 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19661: loss = 3.2817 (0.094 sec/step)\n",
            "I1003 01:03:01.251696 139845451286400 learning.py:512] global step 19661: loss = 3.2817 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19662: loss = 2.4365 (0.109 sec/step)\n",
            "I1003 01:03:01.361566 139845451286400 learning.py:512] global step 19662: loss = 2.4365 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19663: loss = 3.2947 (0.107 sec/step)\n",
            "I1003 01:03:01.469887 139845451286400 learning.py:512] global step 19663: loss = 3.2947 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19664: loss = 3.9720 (0.099 sec/step)\n",
            "I1003 01:03:01.570439 139845451286400 learning.py:512] global step 19664: loss = 3.9720 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19665: loss = 3.3911 (0.092 sec/step)\n",
            "I1003 01:03:01.663463 139845451286400 learning.py:512] global step 19665: loss = 3.3911 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19666: loss = 4.0468 (0.101 sec/step)\n",
            "I1003 01:03:01.766449 139845451286400 learning.py:512] global step 19666: loss = 4.0468 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19667: loss = 2.4067 (0.106 sec/step)\n",
            "I1003 01:03:01.873483 139845451286400 learning.py:512] global step 19667: loss = 2.4067 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19668: loss = 6.1164 (0.096 sec/step)\n",
            "I1003 01:03:01.971371 139845451286400 learning.py:512] global step 19668: loss = 6.1164 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19669: loss = 4.4289 (0.101 sec/step)\n",
            "I1003 01:03:02.074269 139845451286400 learning.py:512] global step 19669: loss = 4.4289 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19670: loss = 3.3528 (0.121 sec/step)\n",
            "I1003 01:03:02.196336 139845451286400 learning.py:512] global step 19670: loss = 3.3528 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19671: loss = 5.2623 (0.086 sec/step)\n",
            "I1003 01:03:02.283417 139845451286400 learning.py:512] global step 19671: loss = 5.2623 (0.086 sec/step)\n",
            "INFO:tensorflow:global step 19672: loss = 3.7626 (0.096 sec/step)\n",
            "I1003 01:03:02.380321 139845451286400 learning.py:512] global step 19672: loss = 3.7626 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19673: loss = 2.1552 (0.102 sec/step)\n",
            "I1003 01:03:02.483490 139845451286400 learning.py:512] global step 19673: loss = 2.1552 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19674: loss = 4.3179 (0.088 sec/step)\n",
            "I1003 01:03:02.572690 139845451286400 learning.py:512] global step 19674: loss = 4.3179 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19675: loss = 2.2859 (0.100 sec/step)\n",
            "I1003 01:03:02.673581 139845451286400 learning.py:512] global step 19675: loss = 2.2859 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19676: loss = 2.3283 (0.097 sec/step)\n",
            "I1003 01:03:02.772367 139845451286400 learning.py:512] global step 19676: loss = 2.3283 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19677: loss = 4.0752 (0.092 sec/step)\n",
            "I1003 01:03:02.865707 139845451286400 learning.py:512] global step 19677: loss = 4.0752 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19678: loss = 4.6688 (0.104 sec/step)\n",
            "I1003 01:03:02.970798 139845451286400 learning.py:512] global step 19678: loss = 4.6688 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19679: loss = 2.9444 (0.106 sec/step)\n",
            "I1003 01:03:03.078198 139845451286400 learning.py:512] global step 19679: loss = 2.9444 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19680: loss = 3.0389 (0.100 sec/step)\n",
            "I1003 01:03:03.182125 139845451286400 learning.py:512] global step 19680: loss = 3.0389 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19681: loss = 3.8944 (0.097 sec/step)\n",
            "I1003 01:03:03.280125 139845451286400 learning.py:512] global step 19681: loss = 3.8944 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19682: loss = 4.1001 (0.106 sec/step)\n",
            "I1003 01:03:03.387375 139845451286400 learning.py:512] global step 19682: loss = 4.1001 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19683: loss = 3.0433 (0.106 sec/step)\n",
            "I1003 01:03:03.495122 139845451286400 learning.py:512] global step 19683: loss = 3.0433 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19684: loss = 6.9016 (0.091 sec/step)\n",
            "I1003 01:03:03.590544 139845451286400 learning.py:512] global step 19684: loss = 6.9016 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19685: loss = 2.4689 (0.107 sec/step)\n",
            "I1003 01:03:03.698486 139845451286400 learning.py:512] global step 19685: loss = 2.4689 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19686: loss = 5.7127 (0.115 sec/step)\n",
            "I1003 01:03:03.814745 139845451286400 learning.py:512] global step 19686: loss = 5.7127 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19687: loss = 3.5775 (0.094 sec/step)\n",
            "I1003 01:03:03.909883 139845451286400 learning.py:512] global step 19687: loss = 3.5775 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19688: loss = 2.8390 (0.097 sec/step)\n",
            "I1003 01:03:04.008500 139845451286400 learning.py:512] global step 19688: loss = 2.8390 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19689: loss = 3.4419 (0.101 sec/step)\n",
            "I1003 01:03:04.111050 139845451286400 learning.py:512] global step 19689: loss = 3.4419 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19690: loss = 8.4695 (0.110 sec/step)\n",
            "I1003 01:03:04.221900 139845451286400 learning.py:512] global step 19690: loss = 8.4695 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19691: loss = 2.4035 (0.100 sec/step)\n",
            "I1003 01:03:04.322885 139845451286400 learning.py:512] global step 19691: loss = 2.4035 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19692: loss = 2.4355 (0.099 sec/step)\n",
            "I1003 01:03:04.423301 139845451286400 learning.py:512] global step 19692: loss = 2.4355 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19693: loss = 3.4936 (0.104 sec/step)\n",
            "I1003 01:03:04.528636 139845451286400 learning.py:512] global step 19693: loss = 3.4936 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19694: loss = 3.5878 (0.096 sec/step)\n",
            "I1003 01:03:04.625637 139845451286400 learning.py:512] global step 19694: loss = 3.5878 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19695: loss = 5.6891 (0.100 sec/step)\n",
            "I1003 01:03:04.726867 139845451286400 learning.py:512] global step 19695: loss = 5.6891 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19696: loss = 3.3800 (0.101 sec/step)\n",
            "I1003 01:03:04.829148 139845451286400 learning.py:512] global step 19696: loss = 3.3800 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19697: loss = 2.4987 (0.097 sec/step)\n",
            "I1003 01:03:04.927443 139845451286400 learning.py:512] global step 19697: loss = 2.4987 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19698: loss = 4.0702 (0.106 sec/step)\n",
            "I1003 01:03:05.034496 139845451286400 learning.py:512] global step 19698: loss = 4.0702 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19699: loss = 2.1259 (0.104 sec/step)\n",
            "I1003 01:03:05.139895 139845451286400 learning.py:512] global step 19699: loss = 2.1259 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19700: loss = 3.2611 (0.090 sec/step)\n",
            "I1003 01:03:05.231485 139845451286400 learning.py:512] global step 19700: loss = 3.2611 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19701: loss = 3.5494 (0.106 sec/step)\n",
            "I1003 01:03:05.338839 139845451286400 learning.py:512] global step 19701: loss = 3.5494 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19702: loss = 7.2903 (0.100 sec/step)\n",
            "I1003 01:03:05.439972 139845451286400 learning.py:512] global step 19702: loss = 7.2903 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19703: loss = 2.2485 (0.102 sec/step)\n",
            "I1003 01:03:05.543629 139845451286400 learning.py:512] global step 19703: loss = 2.2485 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19704: loss = 3.2651 (0.101 sec/step)\n",
            "I1003 01:03:05.646160 139845451286400 learning.py:512] global step 19704: loss = 3.2651 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19705: loss = 2.8680 (0.092 sec/step)\n",
            "I1003 01:03:05.739579 139845451286400 learning.py:512] global step 19705: loss = 2.8680 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19706: loss = 2.8223 (0.102 sec/step)\n",
            "I1003 01:03:05.843723 139845451286400 learning.py:512] global step 19706: loss = 2.8223 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19707: loss = 3.2783 (0.107 sec/step)\n",
            "I1003 01:03:05.952277 139845451286400 learning.py:512] global step 19707: loss = 3.2783 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19708: loss = 3.7783 (0.099 sec/step)\n",
            "I1003 01:03:06.052572 139845451286400 learning.py:512] global step 19708: loss = 3.7783 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19709: loss = 2.6047 (0.095 sec/step)\n",
            "I1003 01:03:06.149174 139845451286400 learning.py:512] global step 19709: loss = 2.6047 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19710: loss = 2.9425 (0.110 sec/step)\n",
            "I1003 01:03:06.260770 139845451286400 learning.py:512] global step 19710: loss = 2.9425 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19711: loss = 4.1898 (0.097 sec/step)\n",
            "I1003 01:03:06.358964 139845451286400 learning.py:512] global step 19711: loss = 4.1898 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19712: loss = 2.6784 (0.104 sec/step)\n",
            "I1003 01:03:06.464254 139845451286400 learning.py:512] global step 19712: loss = 2.6784 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19713: loss = 8.0311 (0.093 sec/step)\n",
            "I1003 01:03:06.558350 139845451286400 learning.py:512] global step 19713: loss = 8.0311 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19714: loss = 4.9900 (0.101 sec/step)\n",
            "I1003 01:03:06.660859 139845451286400 learning.py:512] global step 19714: loss = 4.9900 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19715: loss = 7.0100 (0.093 sec/step)\n",
            "I1003 01:03:06.755121 139845451286400 learning.py:512] global step 19715: loss = 7.0100 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19716: loss = 3.2900 (0.096 sec/step)\n",
            "I1003 01:03:06.853246 139845451286400 learning.py:512] global step 19716: loss = 3.2900 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19717: loss = 4.1361 (0.105 sec/step)\n",
            "I1003 01:03:06.959513 139845451286400 learning.py:512] global step 19717: loss = 4.1361 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19718: loss = 2.5363 (0.096 sec/step)\n",
            "I1003 01:03:07.056694 139845451286400 learning.py:512] global step 19718: loss = 2.5363 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19719: loss = 2.8281 (0.106 sec/step)\n",
            "I1003 01:03:07.163867 139845451286400 learning.py:512] global step 19719: loss = 2.8281 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19720: loss = 6.4151 (0.109 sec/step)\n",
            "I1003 01:03:07.274229 139845451286400 learning.py:512] global step 19720: loss = 6.4151 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19721: loss = 2.8666 (0.093 sec/step)\n",
            "I1003 01:03:07.368551 139845451286400 learning.py:512] global step 19721: loss = 2.8666 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19722: loss = 5.7565 (0.099 sec/step)\n",
            "I1003 01:03:07.469175 139845451286400 learning.py:512] global step 19722: loss = 5.7565 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19723: loss = 6.6566 (0.106 sec/step)\n",
            "I1003 01:03:07.576644 139845451286400 learning.py:512] global step 19723: loss = 6.6566 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19724: loss = 2.4374 (0.101 sec/step)\n",
            "I1003 01:03:07.679209 139845451286400 learning.py:512] global step 19724: loss = 2.4374 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19725: loss = 3.5011 (0.097 sec/step)\n",
            "I1003 01:03:07.777496 139845451286400 learning.py:512] global step 19725: loss = 3.5011 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19726: loss = 4.4854 (0.134 sec/step)\n",
            "I1003 01:03:07.912384 139845451286400 learning.py:512] global step 19726: loss = 4.4854 (0.134 sec/step)\n",
            "INFO:tensorflow:global step 19727: loss = 6.6634 (0.110 sec/step)\n",
            "I1003 01:03:08.023562 139845451286400 learning.py:512] global step 19727: loss = 6.6634 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19728: loss = 3.0785 (0.091 sec/step)\n",
            "I1003 01:03:08.116332 139845451286400 learning.py:512] global step 19728: loss = 3.0785 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19729: loss = 4.8781 (0.096 sec/step)\n",
            "I1003 01:03:08.213775 139845451286400 learning.py:512] global step 19729: loss = 4.8781 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19730: loss = 6.7646 (0.116 sec/step)\n",
            "I1003 01:03:08.331541 139845451286400 learning.py:512] global step 19730: loss = 6.7646 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 19731: loss = 3.7271 (0.103 sec/step)\n",
            "I1003 01:03:08.435931 139845451286400 learning.py:512] global step 19731: loss = 3.7271 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19732: loss = 2.1487 (0.090 sec/step)\n",
            "I1003 01:03:08.527709 139845451286400 learning.py:512] global step 19732: loss = 2.1487 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19733: loss = 3.1886 (0.101 sec/step)\n",
            "I1003 01:03:08.630061 139845451286400 learning.py:512] global step 19733: loss = 3.1886 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19734: loss = 3.6336 (0.097 sec/step)\n",
            "I1003 01:03:08.728071 139845451286400 learning.py:512] global step 19734: loss = 3.6336 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19735: loss = 3.7225 (0.104 sec/step)\n",
            "I1003 01:03:08.833927 139845451286400 learning.py:512] global step 19735: loss = 3.7225 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19736: loss = 2.8334 (0.102 sec/step)\n",
            "I1003 01:03:08.937609 139845451286400 learning.py:512] global step 19736: loss = 2.8334 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19737: loss = 2.7727 (0.090 sec/step)\n",
            "I1003 01:03:09.029131 139845451286400 learning.py:512] global step 19737: loss = 2.7727 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19738: loss = 3.5165 (0.110 sec/step)\n",
            "I1003 01:03:09.140795 139845451286400 learning.py:512] global step 19738: loss = 3.5165 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19739: loss = 10.2967 (0.092 sec/step)\n",
            "I1003 01:03:09.234620 139845451286400 learning.py:512] global step 19739: loss = 10.2967 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19740: loss = 3.2423 (0.108 sec/step)\n",
            "I1003 01:03:09.343648 139845451286400 learning.py:512] global step 19740: loss = 3.2423 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19741: loss = 5.3478 (0.108 sec/step)\n",
            "I1003 01:03:09.452648 139845451286400 learning.py:512] global step 19741: loss = 5.3478 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19742: loss = 4.2367 (0.092 sec/step)\n",
            "I1003 01:03:09.545682 139845451286400 learning.py:512] global step 19742: loss = 4.2367 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19743: loss = 4.4030 (0.118 sec/step)\n",
            "I1003 01:03:09.664542 139845451286400 learning.py:512] global step 19743: loss = 4.4030 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19744: loss = 5.7688 (0.108 sec/step)\n",
            "I1003 01:03:09.775312 139845451286400 learning.py:512] global step 19744: loss = 5.7688 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19745: loss = 2.6075 (0.109 sec/step)\n",
            "I1003 01:03:09.885727 139845451286400 learning.py:512] global step 19745: loss = 2.6075 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19746: loss = 3.1829 (0.104 sec/step)\n",
            "I1003 01:03:09.991620 139845451286400 learning.py:512] global step 19746: loss = 3.1829 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19747: loss = 2.8633 (0.096 sec/step)\n",
            "I1003 01:03:10.089369 139845451286400 learning.py:512] global step 19747: loss = 2.8633 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19748: loss = 3.4574 (0.089 sec/step)\n",
            "I1003 01:03:10.179307 139845451286400 learning.py:512] global step 19748: loss = 3.4574 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 19749: loss = 3.8774 (0.105 sec/step)\n",
            "I1003 01:03:10.285563 139845451286400 learning.py:512] global step 19749: loss = 3.8774 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19750: loss = 7.2741 (0.095 sec/step)\n",
            "I1003 01:03:10.382306 139845451286400 learning.py:512] global step 19750: loss = 7.2741 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19751: loss = 3.6820 (0.098 sec/step)\n",
            "I1003 01:03:10.482685 139845451286400 learning.py:512] global step 19751: loss = 3.6820 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19752: loss = 7.1299 (0.105 sec/step)\n",
            "I1003 01:03:10.588902 139845451286400 learning.py:512] global step 19752: loss = 7.1299 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19753: loss = 2.6943 (0.104 sec/step)\n",
            "I1003 01:03:10.694630 139845451286400 learning.py:512] global step 19753: loss = 2.6943 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19754: loss = 4.9984 (0.093 sec/step)\n",
            "I1003 01:03:10.789100 139845451286400 learning.py:512] global step 19754: loss = 4.9984 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19755: loss = 6.8807 (0.098 sec/step)\n",
            "I1003 01:03:10.887997 139845451286400 learning.py:512] global step 19755: loss = 6.8807 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19756: loss = 5.5654 (0.112 sec/step)\n",
            "I1003 01:03:11.000993 139845451286400 learning.py:512] global step 19756: loss = 5.5654 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19757: loss = 3.5218 (0.100 sec/step)\n",
            "I1003 01:03:11.102521 139845451286400 learning.py:512] global step 19757: loss = 3.5218 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19758: loss = 8.8903 (0.097 sec/step)\n",
            "I1003 01:03:11.200901 139845451286400 learning.py:512] global step 19758: loss = 8.8903 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19759: loss = 3.0711 (0.106 sec/step)\n",
            "I1003 01:03:11.307937 139845451286400 learning.py:512] global step 19759: loss = 3.0711 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19760: loss = 4.3883 (0.101 sec/step)\n",
            "I1003 01:03:11.410061 139845451286400 learning.py:512] global step 19760: loss = 4.3883 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19761: loss = 4.2607 (0.105 sec/step)\n",
            "I1003 01:03:11.516166 139845451286400 learning.py:512] global step 19761: loss = 4.2607 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19762: loss = 3.8186 (0.097 sec/step)\n",
            "I1003 01:03:11.614552 139845451286400 learning.py:512] global step 19762: loss = 3.8186 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19763: loss = 3.1948 (0.108 sec/step)\n",
            "I1003 01:03:11.724484 139845451286400 learning.py:512] global step 19763: loss = 3.1948 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19764: loss = 2.0999 (0.102 sec/step)\n",
            "I1003 01:03:11.827791 139845451286400 learning.py:512] global step 19764: loss = 2.0999 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19765: loss = 2.8714 (0.110 sec/step)\n",
            "I1003 01:03:11.939507 139845451286400 learning.py:512] global step 19765: loss = 2.8714 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19766: loss = 4.6322 (0.111 sec/step)\n",
            "I1003 01:03:12.051502 139845451286400 learning.py:512] global step 19766: loss = 4.6322 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19767: loss = 3.8227 (0.101 sec/step)\n",
            "I1003 01:03:12.154081 139845451286400 learning.py:512] global step 19767: loss = 3.8227 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19768: loss = 5.8220 (0.096 sec/step)\n",
            "I1003 01:03:12.251604 139845451286400 learning.py:512] global step 19768: loss = 5.8220 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19769: loss = 2.6843 (0.097 sec/step)\n",
            "I1003 01:03:12.350405 139845451286400 learning.py:512] global step 19769: loss = 2.6843 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19770: loss = 5.6663 (0.104 sec/step)\n",
            "I1003 01:03:12.455392 139845451286400 learning.py:512] global step 19770: loss = 5.6663 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19771: loss = 3.2928 (0.088 sec/step)\n",
            "I1003 01:03:12.545639 139845451286400 learning.py:512] global step 19771: loss = 3.2928 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19772: loss = 6.8253 (0.095 sec/step)\n",
            "I1003 01:03:12.643411 139845451286400 learning.py:512] global step 19772: loss = 6.8253 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19773: loss = 3.5177 (0.097 sec/step)\n",
            "I1003 01:03:12.742712 139845451286400 learning.py:512] global step 19773: loss = 3.5177 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19774: loss = 2.7756 (0.101 sec/step)\n",
            "I1003 01:03:12.845552 139845451286400 learning.py:512] global step 19774: loss = 2.7756 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19775: loss = 3.0482 (0.096 sec/step)\n",
            "I1003 01:03:12.942539 139845451286400 learning.py:512] global step 19775: loss = 3.0482 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19776: loss = 3.2054 (0.096 sec/step)\n",
            "I1003 01:03:13.040401 139845451286400 learning.py:512] global step 19776: loss = 3.2054 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19777: loss = 5.7177 (0.096 sec/step)\n",
            "I1003 01:03:13.137659 139845451286400 learning.py:512] global step 19777: loss = 5.7177 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19778: loss = 3.1141 (0.109 sec/step)\n",
            "I1003 01:03:13.248219 139845451286400 learning.py:512] global step 19778: loss = 3.1141 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19779: loss = 3.6038 (0.120 sec/step)\n",
            "I1003 01:03:13.369481 139845451286400 learning.py:512] global step 19779: loss = 3.6038 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19780: loss = 4.8372 (0.122 sec/step)\n",
            "I1003 01:03:13.493291 139845451286400 learning.py:512] global step 19780: loss = 4.8372 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19781: loss = 2.9172 (0.120 sec/step)\n",
            "I1003 01:03:13.614569 139845451286400 learning.py:512] global step 19781: loss = 2.9172 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19782: loss = 3.5399 (0.123 sec/step)\n",
            "I1003 01:03:13.738554 139845451286400 learning.py:512] global step 19782: loss = 3.5399 (0.123 sec/step)\n",
            "INFO:tensorflow:global step 19783: loss = 6.2147 (0.101 sec/step)\n",
            "I1003 01:03:13.840532 139845451286400 learning.py:512] global step 19783: loss = 6.2147 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19784: loss = 4.8151 (0.094 sec/step)\n",
            "I1003 01:03:13.935645 139845451286400 learning.py:512] global step 19784: loss = 4.8151 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19785: loss = 4.8496 (0.108 sec/step)\n",
            "I1003 01:03:14.045460 139845451286400 learning.py:512] global step 19785: loss = 4.8496 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19786: loss = 2.9724 (0.112 sec/step)\n",
            "I1003 01:03:14.158524 139845451286400 learning.py:512] global step 19786: loss = 2.9724 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19787: loss = 3.0230 (0.118 sec/step)\n",
            "I1003 01:03:14.278148 139845451286400 learning.py:512] global step 19787: loss = 3.0230 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19788: loss = 3.8670 (0.120 sec/step)\n",
            "I1003 01:03:14.399886 139845451286400 learning.py:512] global step 19788: loss = 3.8670 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19789: loss = 6.9047 (0.111 sec/step)\n",
            "I1003 01:03:14.512627 139845451286400 learning.py:512] global step 19789: loss = 6.9047 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19790: loss = 3.5048 (0.116 sec/step)\n",
            "I1003 01:03:14.630367 139845451286400 learning.py:512] global step 19790: loss = 3.5048 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 19791: loss = 4.1363 (0.128 sec/step)\n",
            "I1003 01:03:14.759489 139845451286400 learning.py:512] global step 19791: loss = 4.1363 (0.128 sec/step)\n",
            "INFO:tensorflow:global step 19792: loss = 7.8409 (0.107 sec/step)\n",
            "I1003 01:03:14.868082 139845451286400 learning.py:512] global step 19792: loss = 7.8409 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19793: loss = 6.5072 (0.117 sec/step)\n",
            "I1003 01:03:14.986336 139845451286400 learning.py:512] global step 19793: loss = 6.5072 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19794: loss = 6.0917 (0.108 sec/step)\n",
            "I1003 01:03:15.095880 139845451286400 learning.py:512] global step 19794: loss = 6.0917 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19795: loss = 4.3349 (0.092 sec/step)\n",
            "I1003 01:03:15.189216 139845451286400 learning.py:512] global step 19795: loss = 4.3349 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19796: loss = 3.9128 (0.106 sec/step)\n",
            "I1003 01:03:15.297151 139845451286400 learning.py:512] global step 19796: loss = 3.9128 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19797: loss = 2.1581 (0.114 sec/step)\n",
            "I1003 01:03:15.412863 139845451286400 learning.py:512] global step 19797: loss = 2.1581 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19798: loss = 2.5714 (0.095 sec/step)\n",
            "I1003 01:03:15.509597 139845451286400 learning.py:512] global step 19798: loss = 2.5714 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19799: loss = 6.3736 (0.090 sec/step)\n",
            "I1003 01:03:15.600709 139845451286400 learning.py:512] global step 19799: loss = 6.3736 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19800: loss = 3.0434 (0.103 sec/step)\n",
            "I1003 01:03:15.709059 139845451286400 learning.py:512] global step 19800: loss = 3.0434 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19801: loss = 6.5411 (0.104 sec/step)\n",
            "I1003 01:03:15.814316 139845451286400 learning.py:512] global step 19801: loss = 6.5411 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19802: loss = 1.9716 (0.093 sec/step)\n",
            "I1003 01:03:15.909890 139845451286400 learning.py:512] global step 19802: loss = 1.9716 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19803: loss = 9.0171 (0.103 sec/step)\n",
            "I1003 01:03:16.014170 139845451286400 learning.py:512] global step 19803: loss = 9.0171 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19804: loss = 2.8237 (0.099 sec/step)\n",
            "I1003 01:03:16.114527 139845451286400 learning.py:512] global step 19804: loss = 2.8237 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19805: loss = 3.1194 (0.099 sec/step)\n",
            "I1003 01:03:16.215787 139845451286400 learning.py:512] global step 19805: loss = 3.1194 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19806: loss = 9.0691 (0.106 sec/step)\n",
            "I1003 01:03:16.323265 139845451286400 learning.py:512] global step 19806: loss = 9.0691 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19807: loss = 3.0794 (0.105 sec/step)\n",
            "I1003 01:03:16.429587 139845451286400 learning.py:512] global step 19807: loss = 3.0794 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19808: loss = 9.8279 (0.096 sec/step)\n",
            "I1003 01:03:16.527604 139845451286400 learning.py:512] global step 19808: loss = 9.8279 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19809: loss = 5.0376 (0.099 sec/step)\n",
            "I1003 01:03:16.627593 139845451286400 learning.py:512] global step 19809: loss = 5.0376 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19810: loss = 3.9258 (0.102 sec/step)\n",
            "I1003 01:03:16.731037 139845451286400 learning.py:512] global step 19810: loss = 3.9258 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19811: loss = 4.4594 (0.100 sec/step)\n",
            "I1003 01:03:16.832513 139845451286400 learning.py:512] global step 19811: loss = 4.4594 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19812: loss = 7.5133 (0.087 sec/step)\n",
            "I1003 01:03:16.920681 139845451286400 learning.py:512] global step 19812: loss = 7.5133 (0.087 sec/step)\n",
            "INFO:tensorflow:global step 19813: loss = 2.9749 (0.106 sec/step)\n",
            "I1003 01:03:17.028057 139845451286400 learning.py:512] global step 19813: loss = 2.9749 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19814: loss = 3.4625 (0.099 sec/step)\n",
            "I1003 01:03:17.130121 139845451286400 learning.py:512] global step 19814: loss = 3.4625 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19815: loss = 3.1338 (0.099 sec/step)\n",
            "I1003 01:03:17.233362 139845451286400 learning.py:512] global step 19815: loss = 3.1338 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19816: loss = 2.8085 (0.105 sec/step)\n",
            "I1003 01:03:17.340613 139845451286400 learning.py:512] global step 19816: loss = 2.8085 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19817: loss = 3.6750 (0.124 sec/step)\n",
            "I1003 01:03:17.465801 139845451286400 learning.py:512] global step 19817: loss = 3.6750 (0.124 sec/step)\n",
            "INFO:tensorflow:global step 19818: loss = 5.8291 (0.122 sec/step)\n",
            "I1003 01:03:17.589025 139845451286400 learning.py:512] global step 19818: loss = 5.8291 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19819: loss = 3.6810 (0.112 sec/step)\n",
            "I1003 01:03:17.702790 139845451286400 learning.py:512] global step 19819: loss = 3.6810 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19820: loss = 3.6528 (0.103 sec/step)\n",
            "I1003 01:03:17.806707 139845451286400 learning.py:512] global step 19820: loss = 3.6528 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19821: loss = 3.6476 (0.099 sec/step)\n",
            "I1003 01:03:17.906939 139845451286400 learning.py:512] global step 19821: loss = 3.6476 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19822: loss = 5.2111 (0.102 sec/step)\n",
            "I1003 01:03:18.009824 139845451286400 learning.py:512] global step 19822: loss = 5.2111 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19823: loss = 3.1993 (0.096 sec/step)\n",
            "I1003 01:03:18.106698 139845451286400 learning.py:512] global step 19823: loss = 3.1993 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19824: loss = 3.5905 (0.110 sec/step)\n",
            "I1003 01:03:18.218349 139845451286400 learning.py:512] global step 19824: loss = 3.5905 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19825: loss = 3.3278 (0.098 sec/step)\n",
            "I1003 01:03:18.318092 139845451286400 learning.py:512] global step 19825: loss = 3.3278 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19826: loss = 6.1221 (0.108 sec/step)\n",
            "I1003 01:03:18.427485 139845451286400 learning.py:512] global step 19826: loss = 6.1221 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19827: loss = 3.6573 (0.101 sec/step)\n",
            "I1003 01:03:18.529386 139845451286400 learning.py:512] global step 19827: loss = 3.6573 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19828: loss = 4.9839 (0.102 sec/step)\n",
            "I1003 01:03:18.633376 139845451286400 learning.py:512] global step 19828: loss = 4.9839 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19829: loss = 2.0436 (0.093 sec/step)\n",
            "I1003 01:03:18.727326 139845451286400 learning.py:512] global step 19829: loss = 2.0436 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19830: loss = 8.6928 (0.106 sec/step)\n",
            "I1003 01:03:18.834843 139845451286400 learning.py:512] global step 19830: loss = 8.6928 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19831: loss = 5.5699 (0.097 sec/step)\n",
            "I1003 01:03:18.933390 139845451286400 learning.py:512] global step 19831: loss = 5.5699 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19832: loss = 6.2283 (0.103 sec/step)\n",
            "I1003 01:03:19.038084 139845451286400 learning.py:512] global step 19832: loss = 6.2283 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19833: loss = 3.7631 (0.100 sec/step)\n",
            "I1003 01:03:19.139917 139845451286400 learning.py:512] global step 19833: loss = 3.7631 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19834: loss = 4.3666 (0.110 sec/step)\n",
            "I1003 01:03:19.251600 139845451286400 learning.py:512] global step 19834: loss = 4.3666 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19835: loss = 4.9454 (0.102 sec/step)\n",
            "I1003 01:03:19.354538 139845451286400 learning.py:512] global step 19835: loss = 4.9454 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19836: loss = 8.3067 (0.100 sec/step)\n",
            "I1003 01:03:19.455642 139845451286400 learning.py:512] global step 19836: loss = 8.3067 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19837: loss = 4.9183 (0.098 sec/step)\n",
            "I1003 01:03:19.555384 139845451286400 learning.py:512] global step 19837: loss = 4.9183 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19838: loss = 3.2878 (0.097 sec/step)\n",
            "I1003 01:03:19.653711 139845451286400 learning.py:512] global step 19838: loss = 3.2878 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19839: loss = 3.1191 (0.097 sec/step)\n",
            "I1003 01:03:19.751847 139845451286400 learning.py:512] global step 19839: loss = 3.1191 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19840: loss = 5.6024 (0.104 sec/step)\n",
            "I1003 01:03:19.857625 139845451286400 learning.py:512] global step 19840: loss = 5.6024 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19841: loss = 2.5103 (0.102 sec/step)\n",
            "I1003 01:03:19.960999 139845451286400 learning.py:512] global step 19841: loss = 2.5103 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19842: loss = 4.8300 (0.121 sec/step)\n",
            "I1003 01:03:20.083586 139845451286400 learning.py:512] global step 19842: loss = 4.8300 (0.121 sec/step)\n",
            "INFO:tensorflow:global step 19843: loss = 4.4322 (0.129 sec/step)\n",
            "I1003 01:03:20.214604 139845451286400 learning.py:512] global step 19843: loss = 4.4322 (0.129 sec/step)\n",
            "INFO:tensorflow:global step 19844: loss = 4.0024 (0.115 sec/step)\n",
            "I1003 01:03:20.330721 139845451286400 learning.py:512] global step 19844: loss = 4.0024 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19845: loss = 2.7519 (0.109 sec/step)\n",
            "I1003 01:03:20.440642 139845451286400 learning.py:512] global step 19845: loss = 2.7519 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19846: loss = 2.2981 (0.128 sec/step)\n",
            "I1003 01:03:20.570406 139845451286400 learning.py:512] global step 19846: loss = 2.2981 (0.128 sec/step)\n",
            "INFO:tensorflow:global step 19847: loss = 2.8501 (0.107 sec/step)\n",
            "I1003 01:03:20.678452 139845451286400 learning.py:512] global step 19847: loss = 2.8501 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19848: loss = 2.3750 (0.101 sec/step)\n",
            "I1003 01:03:20.781050 139845451286400 learning.py:512] global step 19848: loss = 2.3750 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19849: loss = 2.5760 (0.105 sec/step)\n",
            "I1003 01:03:20.887891 139845451286400 learning.py:512] global step 19849: loss = 2.5760 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19850: loss = 4.2949 (0.102 sec/step)\n",
            "I1003 01:03:20.991699 139845451286400 learning.py:512] global step 19850: loss = 4.2949 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19851: loss = 4.6886 (0.117 sec/step)\n",
            "I1003 01:03:21.110625 139845451286400 learning.py:512] global step 19851: loss = 4.6886 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19852: loss = 4.0875 (0.103 sec/step)\n",
            "I1003 01:03:21.214761 139845451286400 learning.py:512] global step 19852: loss = 4.0875 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19853: loss = 3.6248 (0.105 sec/step)\n",
            "I1003 01:03:21.321706 139845451286400 learning.py:512] global step 19853: loss = 3.6248 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19854: loss = 2.3700 (0.108 sec/step)\n",
            "I1003 01:03:21.431638 139845451286400 learning.py:512] global step 19854: loss = 2.3700 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19855: loss = 8.0104 (0.117 sec/step)\n",
            "I1003 01:03:21.549945 139845451286400 learning.py:512] global step 19855: loss = 8.0104 (0.117 sec/step)\n",
            "INFO:tensorflow:global step 19856: loss = 4.6146 (0.127 sec/step)\n",
            "I1003 01:03:21.678506 139845451286400 learning.py:512] global step 19856: loss = 4.6146 (0.127 sec/step)\n",
            "INFO:tensorflow:global step 19857: loss = 4.9928 (0.109 sec/step)\n",
            "I1003 01:03:21.789069 139845451286400 learning.py:512] global step 19857: loss = 4.9928 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19858: loss = 3.0862 (0.106 sec/step)\n",
            "I1003 01:03:21.896739 139845451286400 learning.py:512] global step 19858: loss = 3.0862 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19859: loss = 2.0336 (0.101 sec/step)\n",
            "I1003 01:03:21.998614 139845451286400 learning.py:512] global step 19859: loss = 2.0336 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19860: loss = 8.1388 (0.111 sec/step)\n",
            "I1003 01:03:22.110784 139845451286400 learning.py:512] global step 19860: loss = 8.1388 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19861: loss = 3.8356 (0.110 sec/step)\n",
            "I1003 01:03:22.222094 139845451286400 learning.py:512] global step 19861: loss = 3.8356 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19862: loss = 4.7098 (0.120 sec/step)\n",
            "I1003 01:03:22.344127 139845451286400 learning.py:512] global step 19862: loss = 4.7098 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19863: loss = 3.8200 (0.109 sec/step)\n",
            "I1003 01:03:22.454359 139845451286400 learning.py:512] global step 19863: loss = 3.8200 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19864: loss = 2.0329 (0.132 sec/step)\n",
            "I1003 01:03:22.588028 139845451286400 learning.py:512] global step 19864: loss = 2.0329 (0.132 sec/step)\n",
            "INFO:tensorflow:global step 19865: loss = 3.0019 (0.125 sec/step)\n",
            "I1003 01:03:22.714493 139845451286400 learning.py:512] global step 19865: loss = 3.0019 (0.125 sec/step)\n",
            "INFO:tensorflow:global step 19866: loss = 4.7137 (0.106 sec/step)\n",
            "I1003 01:03:22.822198 139845451286400 learning.py:512] global step 19866: loss = 4.7137 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19867: loss = 9.1793 (0.110 sec/step)\n",
            "I1003 01:03:22.933593 139845451286400 learning.py:512] global step 19867: loss = 9.1793 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19868: loss = 2.9579 (0.100 sec/step)\n",
            "I1003 01:03:23.034971 139845451286400 learning.py:512] global step 19868: loss = 2.9579 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19869: loss = 3.6854 (0.091 sec/step)\n",
            "I1003 01:03:23.127246 139845451286400 learning.py:512] global step 19869: loss = 3.6854 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19870: loss = 3.7268 (0.112 sec/step)\n",
            "I1003 01:03:23.240632 139845451286400 learning.py:512] global step 19870: loss = 3.7268 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19871: loss = 6.5408 (0.119 sec/step)\n",
            "I1003 01:03:23.361007 139845451286400 learning.py:512] global step 19871: loss = 6.5408 (0.119 sec/step)\n",
            "INFO:tensorflow:global step 19872: loss = 4.5533 (0.107 sec/step)\n",
            "I1003 01:03:23.469420 139845451286400 learning.py:512] global step 19872: loss = 4.5533 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19873: loss = 1.8845 (0.118 sec/step)\n",
            "I1003 01:03:23.588770 139845451286400 learning.py:512] global step 19873: loss = 1.8845 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19874: loss = 3.5720 (0.118 sec/step)\n",
            "I1003 01:03:23.708187 139845451286400 learning.py:512] global step 19874: loss = 3.5720 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19875: loss = 2.4552 (0.098 sec/step)\n",
            "I1003 01:03:23.807759 139845451286400 learning.py:512] global step 19875: loss = 2.4552 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19876: loss = 3.7016 (0.109 sec/step)\n",
            "I1003 01:03:23.918307 139845451286400 learning.py:512] global step 19876: loss = 3.7016 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19877: loss = 5.8002 (0.093 sec/step)\n",
            "I1003 01:03:24.012598 139845451286400 learning.py:512] global step 19877: loss = 5.8002 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19878: loss = 2.9170 (0.097 sec/step)\n",
            "I1003 01:03:24.111198 139845451286400 learning.py:512] global step 19878: loss = 2.9170 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19879: loss = 3.8366 (0.101 sec/step)\n",
            "I1003 01:03:24.213993 139845451286400 learning.py:512] global step 19879: loss = 3.8366 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19880: loss = 2.5748 (0.096 sec/step)\n",
            "I1003 01:03:24.311924 139845451286400 learning.py:512] global step 19880: loss = 2.5748 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19881: loss = 3.0864 (0.102 sec/step)\n",
            "I1003 01:03:24.415467 139845451286400 learning.py:512] global step 19881: loss = 3.0864 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19882: loss = 3.5383 (0.110 sec/step)\n",
            "I1003 01:03:24.526278 139845451286400 learning.py:512] global step 19882: loss = 3.5383 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19883: loss = 3.3027 (0.101 sec/step)\n",
            "I1003 01:03:24.628850 139845451286400 learning.py:512] global step 19883: loss = 3.3027 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19884: loss = 3.3368 (0.106 sec/step)\n",
            "I1003 01:03:24.736429 139845451286400 learning.py:512] global step 19884: loss = 3.3368 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19885: loss = 5.1718 (0.104 sec/step)\n",
            "I1003 01:03:24.841578 139845451286400 learning.py:512] global step 19885: loss = 5.1718 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19886: loss = 3.7068 (0.118 sec/step)\n",
            "I1003 01:03:24.961030 139845451286400 learning.py:512] global step 19886: loss = 3.7068 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19887: loss = 1.8576 (0.102 sec/step)\n",
            "I1003 01:03:25.063850 139845451286400 learning.py:512] global step 19887: loss = 1.8576 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19888: loss = 4.3699 (0.091 sec/step)\n",
            "I1003 01:03:25.156610 139845451286400 learning.py:512] global step 19888: loss = 4.3699 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19889: loss = 3.9142 (0.100 sec/step)\n",
            "I1003 01:03:25.257485 139845451286400 learning.py:512] global step 19889: loss = 3.9142 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19890: loss = 4.4768 (0.102 sec/step)\n",
            "I1003 01:03:25.361285 139845451286400 learning.py:512] global step 19890: loss = 4.4768 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19891: loss = 2.4944 (0.099 sec/step)\n",
            "I1003 01:03:25.461861 139845451286400 learning.py:512] global step 19891: loss = 2.4944 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19892: loss = 4.0395 (0.107 sec/step)\n",
            "I1003 01:03:25.569933 139845451286400 learning.py:512] global step 19892: loss = 4.0395 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19893: loss = 2.0244 (0.103 sec/step)\n",
            "I1003 01:03:25.673925 139845451286400 learning.py:512] global step 19893: loss = 2.0244 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19894: loss = 5.6951 (0.101 sec/step)\n",
            "I1003 01:03:25.776571 139845451286400 learning.py:512] global step 19894: loss = 5.6951 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19895: loss = 2.9538 (0.104 sec/step)\n",
            "I1003 01:03:25.881682 139845451286400 learning.py:512] global step 19895: loss = 2.9538 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19896: loss = 4.9442 (0.107 sec/step)\n",
            "I1003 01:03:25.989507 139845451286400 learning.py:512] global step 19896: loss = 4.9442 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19897: loss = 2.5004 (0.095 sec/step)\n",
            "I1003 01:03:26.085929 139845451286400 learning.py:512] global step 19897: loss = 2.5004 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19898: loss = 2.4745 (0.095 sec/step)\n",
            "I1003 01:03:26.182420 139845451286400 learning.py:512] global step 19898: loss = 2.4745 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19899: loss = 3.2427 (0.108 sec/step)\n",
            "I1003 01:03:26.291715 139845451286400 learning.py:512] global step 19899: loss = 3.2427 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19900: loss = 2.8608 (0.090 sec/step)\n",
            "I1003 01:03:26.383222 139845451286400 learning.py:512] global step 19900: loss = 2.8608 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19901: loss = 4.1875 (0.095 sec/step)\n",
            "I1003 01:03:26.479111 139845451286400 learning.py:512] global step 19901: loss = 4.1875 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19902: loss = 2.7117 (0.103 sec/step)\n",
            "I1003 01:03:26.583602 139845451286400 learning.py:512] global step 19902: loss = 2.7117 (0.103 sec/step)\n",
            "INFO:tensorflow:global step 19903: loss = 2.8016 (0.100 sec/step)\n",
            "I1003 01:03:26.685103 139845451286400 learning.py:512] global step 19903: loss = 2.8016 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19904: loss = 2.9379 (0.107 sec/step)\n",
            "I1003 01:03:26.793910 139845451286400 learning.py:512] global step 19904: loss = 2.9379 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19905: loss = 2.9143 (0.101 sec/step)\n",
            "I1003 01:03:26.896060 139845451286400 learning.py:512] global step 19905: loss = 2.9143 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19906: loss = 4.1628 (0.110 sec/step)\n",
            "I1003 01:03:27.007173 139845451286400 learning.py:512] global step 19906: loss = 4.1628 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19907: loss = 3.9109 (0.118 sec/step)\n",
            "I1003 01:03:27.127087 139845451286400 learning.py:512] global step 19907: loss = 3.9109 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19908: loss = 5.6815 (0.120 sec/step)\n",
            "I1003 01:03:27.248599 139845451286400 learning.py:512] global step 19908: loss = 5.6815 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19909: loss = 7.3047 (0.108 sec/step)\n",
            "I1003 01:03:27.358681 139845451286400 learning.py:512] global step 19909: loss = 7.3047 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19910: loss = 3.2326 (0.122 sec/step)\n",
            "I1003 01:03:27.481674 139845451286400 learning.py:512] global step 19910: loss = 3.2326 (0.122 sec/step)\n",
            "INFO:tensorflow:global step 19911: loss = 2.0518 (0.133 sec/step)\n",
            "I1003 01:03:27.616063 139845451286400 learning.py:512] global step 19911: loss = 2.0518 (0.133 sec/step)\n",
            "INFO:tensorflow:global step 19912: loss = 2.7330 (0.120 sec/step)\n",
            "I1003 01:03:27.737454 139845451286400 learning.py:512] global step 19912: loss = 2.7330 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19913: loss = 2.5884 (0.105 sec/step)\n",
            "I1003 01:03:27.843844 139845451286400 learning.py:512] global step 19913: loss = 2.5884 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19914: loss = 3.3064 (0.088 sec/step)\n",
            "I1003 01:03:27.933627 139845451286400 learning.py:512] global step 19914: loss = 3.3064 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19915: loss = 2.0800 (0.098 sec/step)\n",
            "I1003 01:03:28.032781 139845451286400 learning.py:512] global step 19915: loss = 2.0800 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19916: loss = 5.3104 (0.098 sec/step)\n",
            "I1003 01:03:28.131751 139845451286400 learning.py:512] global step 19916: loss = 5.3104 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19917: loss = 4.9976 (0.105 sec/step)\n",
            "I1003 01:03:28.237707 139845451286400 learning.py:512] global step 19917: loss = 4.9976 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19918: loss = 2.2184 (0.112 sec/step)\n",
            "I1003 01:03:28.351406 139845451286400 learning.py:512] global step 19918: loss = 2.2184 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19919: loss = 5.7481 (0.114 sec/step)\n",
            "I1003 01:03:28.470691 139845451286400 learning.py:512] global step 19919: loss = 5.7481 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19920: loss = 4.0000 (0.132 sec/step)\n",
            "I1003 01:03:28.603735 139845451286400 learning.py:512] global step 19920: loss = 4.0000 (0.132 sec/step)\n",
            "INFO:tensorflow:global step 19921: loss = 5.8178 (0.128 sec/step)\n",
            "I1003 01:03:28.733397 139845451286400 learning.py:512] global step 19921: loss = 5.8178 (0.128 sec/step)\n",
            "INFO:tensorflow:global step 19922: loss = 3.1186 (0.095 sec/step)\n",
            "I1003 01:03:28.829897 139845451286400 learning.py:512] global step 19922: loss = 3.1186 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19923: loss = 3.0502 (0.098 sec/step)\n",
            "I1003 01:03:28.929520 139845451286400 learning.py:512] global step 19923: loss = 3.0502 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19924: loss = 5.1325 (0.109 sec/step)\n",
            "I1003 01:03:29.039973 139845451286400 learning.py:512] global step 19924: loss = 5.1325 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19925: loss = 2.9265 (0.116 sec/step)\n",
            "I1003 01:03:29.156967 139845451286400 learning.py:512] global step 19925: loss = 2.9265 (0.116 sec/step)\n",
            "INFO:tensorflow:global step 19926: loss = 4.2851 (0.106 sec/step)\n",
            "I1003 01:03:29.264092 139845451286400 learning.py:512] global step 19926: loss = 4.2851 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19927: loss = 3.1133 (0.092 sec/step)\n",
            "I1003 01:03:29.357692 139845451286400 learning.py:512] global step 19927: loss = 3.1133 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19928: loss = 5.7124 (0.112 sec/step)\n",
            "I1003 01:03:29.471332 139845451286400 learning.py:512] global step 19928: loss = 5.7124 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 19929: loss = 3.6494 (0.099 sec/step)\n",
            "I1003 01:03:29.577778 139845451286400 learning.py:512] global step 19929: loss = 3.6494 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19930: loss = 6.9633 (0.088 sec/step)\n",
            "I1003 01:03:29.667055 139845451286400 learning.py:512] global step 19930: loss = 6.9633 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19931: loss = 4.4416 (0.106 sec/step)\n",
            "I1003 01:03:29.774521 139845451286400 learning.py:512] global step 19931: loss = 4.4416 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19932: loss = 1.8231 (0.091 sec/step)\n",
            "I1003 01:03:29.869148 139845451286400 learning.py:512] global step 19932: loss = 1.8231 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19933: loss = 3.1957 (0.098 sec/step)\n",
            "I1003 01:03:29.968961 139845451286400 learning.py:512] global step 19933: loss = 3.1957 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19934: loss = 5.9807 (0.114 sec/step)\n",
            "I1003 01:03:30.083966 139845451286400 learning.py:512] global step 19934: loss = 5.9807 (0.114 sec/step)\n",
            "INFO:tensorflow:global step 19935: loss = 5.7242 (0.099 sec/step)\n",
            "I1003 01:03:30.183877 139845451286400 learning.py:512] global step 19935: loss = 5.7242 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19936: loss = 5.8827 (0.097 sec/step)\n",
            "I1003 01:03:30.281863 139845451286400 learning.py:512] global step 19936: loss = 5.8827 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19937: loss = 5.1539 (0.098 sec/step)\n",
            "I1003 01:03:30.381107 139845451286400 learning.py:512] global step 19937: loss = 5.1539 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19938: loss = 3.7379 (0.101 sec/step)\n",
            "I1003 01:03:30.483367 139845451286400 learning.py:512] global step 19938: loss = 3.7379 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19939: loss = 1.9495 (0.104 sec/step)\n",
            "I1003 01:03:30.588680 139845451286400 learning.py:512] global step 19939: loss = 1.9495 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19940: loss = 4.1555 (0.092 sec/step)\n",
            "I1003 01:03:30.685773 139845451286400 learning.py:512] global step 19940: loss = 4.1555 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19941: loss = 4.5382 (0.099 sec/step)\n",
            "I1003 01:03:30.786216 139845451286400 learning.py:512] global step 19941: loss = 4.5382 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19942: loss = 5.4282 (0.108 sec/step)\n",
            "I1003 01:03:30.895200 139845451286400 learning.py:512] global step 19942: loss = 5.4282 (0.108 sec/step)\n",
            "INFO:tensorflow:global step 19943: loss = 3.8898 (0.101 sec/step)\n",
            "I1003 01:03:30.997459 139845451286400 learning.py:512] global step 19943: loss = 3.8898 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19944: loss = 4.1237 (0.106 sec/step)\n",
            "I1003 01:03:31.104433 139845451286400 learning.py:512] global step 19944: loss = 4.1237 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19945: loss = 3.4778 (0.099 sec/step)\n",
            "I1003 01:03:31.205299 139845451286400 learning.py:512] global step 19945: loss = 3.4778 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19946: loss = 3.0247 (0.090 sec/step)\n",
            "I1003 01:03:31.297118 139845451286400 learning.py:512] global step 19946: loss = 3.0247 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19947: loss = 3.5809 (0.088 sec/step)\n",
            "I1003 01:03:31.386242 139845451286400 learning.py:512] global step 19947: loss = 3.5809 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19948: loss = 1.7729 (0.105 sec/step)\n",
            "I1003 01:03:31.492288 139845451286400 learning.py:512] global step 19948: loss = 1.7729 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19949: loss = 4.0547 (0.107 sec/step)\n",
            "I1003 01:03:31.602016 139845451286400 learning.py:512] global step 19949: loss = 4.0547 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19950: loss = 6.7221 (0.100 sec/step)\n",
            "I1003 01:03:31.703638 139845451286400 learning.py:512] global step 19950: loss = 6.7221 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19951: loss = 4.0923 (0.109 sec/step)\n",
            "I1003 01:03:31.814601 139845451286400 learning.py:512] global step 19951: loss = 4.0923 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19952: loss = 7.8498 (0.097 sec/step)\n",
            "I1003 01:03:31.912526 139845451286400 learning.py:512] global step 19952: loss = 7.8498 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19953: loss = 2.2791 (0.096 sec/step)\n",
            "I1003 01:03:32.010354 139845451286400 learning.py:512] global step 19953: loss = 2.2791 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19954: loss = 2.8333 (0.115 sec/step)\n",
            "I1003 01:03:32.126718 139845451286400 learning.py:512] global step 19954: loss = 2.8333 (0.115 sec/step)\n",
            "INFO:tensorflow:global step 19955: loss = 3.7761 (0.097 sec/step)\n",
            "I1003 01:03:32.225264 139845451286400 learning.py:512] global step 19955: loss = 3.7761 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19956: loss = 3.0907 (0.090 sec/step)\n",
            "I1003 01:03:32.316492 139845451286400 learning.py:512] global step 19956: loss = 3.0907 (0.090 sec/step)\n",
            "INFO:tensorflow:global step 19957: loss = 3.2352 (0.089 sec/step)\n",
            "I1003 01:03:32.407048 139845451286400 learning.py:512] global step 19957: loss = 3.2352 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 19958: loss = 2.1527 (0.096 sec/step)\n",
            "I1003 01:03:32.504667 139845451286400 learning.py:512] global step 19958: loss = 2.1527 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19959: loss = 3.3446 (0.106 sec/step)\n",
            "I1003 01:03:32.612223 139845451286400 learning.py:512] global step 19959: loss = 3.3446 (0.106 sec/step)\n",
            "INFO:tensorflow:global step 19960: loss = 3.8306 (0.096 sec/step)\n",
            "I1003 01:03:32.714593 139845451286400 learning.py:512] global step 19960: loss = 3.8306 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19961: loss = 4.4116 (0.096 sec/step)\n",
            "I1003 01:03:32.812071 139845451286400 learning.py:512] global step 19961: loss = 4.4116 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19962: loss = 6.0269 (0.111 sec/step)\n",
            "I1003 01:03:32.924275 139845451286400 learning.py:512] global step 19962: loss = 6.0269 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19963: loss = 9.1130 (0.092 sec/step)\n",
            "I1003 01:03:33.018257 139845451286400 learning.py:512] global step 19963: loss = 9.1130 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19964: loss = 3.5464 (0.105 sec/step)\n",
            "I1003 01:03:33.124340 139845451286400 learning.py:512] global step 19964: loss = 3.5464 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19965: loss = 3.1401 (0.110 sec/step)\n",
            "I1003 01:03:33.235713 139845451286400 learning.py:512] global step 19965: loss = 3.1401 (0.110 sec/step)\n",
            "INFO:tensorflow:global step 19966: loss = 2.7131 (0.105 sec/step)\n",
            "I1003 01:03:33.341912 139845451286400 learning.py:512] global step 19966: loss = 2.7131 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19967: loss = 4.0736 (0.098 sec/step)\n",
            "I1003 01:03:33.441019 139845451286400 learning.py:512] global step 19967: loss = 4.0736 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19968: loss = 3.1997 (0.100 sec/step)\n",
            "I1003 01:03:33.542837 139845451286400 learning.py:512] global step 19968: loss = 3.1997 (0.100 sec/step)\n",
            "INFO:tensorflow:global step 19969: loss = 3.1463 (0.095 sec/step)\n",
            "I1003 01:03:33.639047 139845451286400 learning.py:512] global step 19969: loss = 3.1463 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19970: loss = 3.7583 (0.092 sec/step)\n",
            "I1003 01:03:33.732498 139845451286400 learning.py:512] global step 19970: loss = 3.7583 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19971: loss = 3.0487 (0.094 sec/step)\n",
            "I1003 01:03:33.828292 139845451286400 learning.py:512] global step 19971: loss = 3.0487 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19972: loss = 3.0707 (0.099 sec/step)\n",
            "I1003 01:03:33.928677 139845451286400 learning.py:512] global step 19972: loss = 3.0707 (0.099 sec/step)\n",
            "INFO:tensorflow:global step 19973: loss = 3.6312 (0.096 sec/step)\n",
            "I1003 01:03:34.026353 139845451286400 learning.py:512] global step 19973: loss = 3.6312 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19974: loss = 4.4788 (0.111 sec/step)\n",
            "I1003 01:03:34.138977 139845451286400 learning.py:512] global step 19974: loss = 4.4788 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19975: loss = 5.0056 (0.111 sec/step)\n",
            "I1003 01:03:34.251405 139845451286400 learning.py:512] global step 19975: loss = 5.0056 (0.111 sec/step)\n",
            "INFO:tensorflow:global step 19976: loss = 3.8038 (0.104 sec/step)\n",
            "I1003 01:03:34.356978 139845451286400 learning.py:512] global step 19976: loss = 3.8038 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19977: loss = 4.2774 (0.118 sec/step)\n",
            "I1003 01:03:34.476654 139845451286400 learning.py:512] global step 19977: loss = 4.2774 (0.118 sec/step)\n",
            "INFO:tensorflow:global step 19978: loss = 6.1633 (0.125 sec/step)\n",
            "I1003 01:03:34.603591 139845451286400 learning.py:512] global step 19978: loss = 6.1633 (0.125 sec/step)\n",
            "INFO:tensorflow:global step 19979: loss = 5.2172 (0.120 sec/step)\n",
            "I1003 01:03:34.725329 139845451286400 learning.py:512] global step 19979: loss = 5.2172 (0.120 sec/step)\n",
            "INFO:tensorflow:global step 19980: loss = 4.5481 (0.096 sec/step)\n",
            "I1003 01:03:34.822878 139845451286400 learning.py:512] global step 19980: loss = 4.5481 (0.096 sec/step)\n",
            "INFO:tensorflow:global step 19981: loss = 2.3705 (0.104 sec/step)\n",
            "I1003 01:03:34.928259 139845451286400 learning.py:512] global step 19981: loss = 2.3705 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19982: loss = 4.9193 (0.102 sec/step)\n",
            "I1003 01:03:35.031687 139845451286400 learning.py:512] global step 19982: loss = 4.9193 (0.102 sec/step)\n",
            "INFO:tensorflow:global step 19983: loss = 3.1199 (0.107 sec/step)\n",
            "I1003 01:03:35.140336 139845451286400 learning.py:512] global step 19983: loss = 3.1199 (0.107 sec/step)\n",
            "INFO:tensorflow:global step 19984: loss = 2.9602 (0.097 sec/step)\n",
            "I1003 01:03:35.239268 139845451286400 learning.py:512] global step 19984: loss = 2.9602 (0.097 sec/step)\n",
            "INFO:tensorflow:global step 19985: loss = 2.8678 (0.104 sec/step)\n",
            "I1003 01:03:35.344337 139845451286400 learning.py:512] global step 19985: loss = 2.8678 (0.104 sec/step)\n",
            "INFO:tensorflow:global step 19986: loss = 2.6935 (0.094 sec/step)\n",
            "I1003 01:03:35.440158 139845451286400 learning.py:512] global step 19986: loss = 2.6935 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19987: loss = 2.7396 (0.091 sec/step)\n",
            "I1003 01:03:35.532496 139845451286400 learning.py:512] global step 19987: loss = 2.7396 (0.091 sec/step)\n",
            "INFO:tensorflow:global step 19988: loss = 3.2833 (0.101 sec/step)\n",
            "I1003 01:03:35.634664 139845451286400 learning.py:512] global step 19988: loss = 3.2833 (0.101 sec/step)\n",
            "INFO:tensorflow:global step 19989: loss = 1.6813 (0.109 sec/step)\n",
            "I1003 01:03:35.744910 139845451286400 learning.py:512] global step 19989: loss = 1.6813 (0.109 sec/step)\n",
            "INFO:tensorflow:global step 19990: loss = 11.9085 (0.105 sec/step)\n",
            "I1003 01:03:35.851168 139845451286400 learning.py:512] global step 19990: loss = 11.9085 (0.105 sec/step)\n",
            "INFO:tensorflow:global step 19991: loss = 2.8916 (0.088 sec/step)\n",
            "I1003 01:03:35.940667 139845451286400 learning.py:512] global step 19991: loss = 2.8916 (0.088 sec/step)\n",
            "INFO:tensorflow:global step 19992: loss = 2.3211 (0.092 sec/step)\n",
            "I1003 01:03:36.034337 139845451286400 learning.py:512] global step 19992: loss = 2.3211 (0.092 sec/step)\n",
            "INFO:tensorflow:global step 19993: loss = 2.4678 (0.126 sec/step)\n",
            "I1003 01:03:36.161971 139845451286400 learning.py:512] global step 19993: loss = 2.4678 (0.126 sec/step)\n",
            "INFO:tensorflow:global step 19994: loss = 2.1958 (0.098 sec/step)\n",
            "I1003 01:03:36.261187 139845451286400 learning.py:512] global step 19994: loss = 2.1958 (0.098 sec/step)\n",
            "INFO:tensorflow:global step 19995: loss = 3.9393 (0.094 sec/step)\n",
            "I1003 01:03:36.356657 139845451286400 learning.py:512] global step 19995: loss = 3.9393 (0.094 sec/step)\n",
            "INFO:tensorflow:global step 19996: loss = 3.0879 (0.093 sec/step)\n",
            "I1003 01:03:36.450853 139845451286400 learning.py:512] global step 19996: loss = 3.0879 (0.093 sec/step)\n",
            "INFO:tensorflow:global step 19997: loss = 4.8135 (0.095 sec/step)\n",
            "I1003 01:03:36.546994 139845451286400 learning.py:512] global step 19997: loss = 4.8135 (0.095 sec/step)\n",
            "INFO:tensorflow:global step 19998: loss = 5.0408 (0.089 sec/step)\n",
            "I1003 01:03:36.637271 139845451286400 learning.py:512] global step 19998: loss = 5.0408 (0.089 sec/step)\n",
            "INFO:tensorflow:global step 19999: loss = 4.7676 (0.112 sec/step)\n",
            "I1003 01:03:36.750825 139845451286400 learning.py:512] global step 19999: loss = 4.7676 (0.112 sec/step)\n",
            "INFO:tensorflow:global step 20000: loss = 5.4708 (0.091 sec/step)\n",
            "I1003 01:03:36.843612 139845451286400 learning.py:512] global step 20000: loss = 5.4708 (0.091 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "I1003 01:03:36.844340 139845451286400 learning.py:769] Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "I1003 01:03:36.844527 139845451286400 learning.py:777] Finished training! Saving model to disk.\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSiDI3NVlECN"
      },
      "source": [
        "Конвертируем результат обучения в модель, которую можно использовать\n",
        " \n",
        "```\n",
        "--pipeline_config_path /content/training_demo/training/ssdlite_mobilenet_v2_coco.config  # путь к конфигу\n",
        "--trained_checkpoint_prefix /content/training_demo/training/model.ckpt-[CHECKPOINT_NUMBER] # путь к чекпоинту, который мы хотим конвертировать.\n",
        "--output_directory /content/training_demo/training/output_inference_graph_v1.pb\n",
        "имя конвертированной модели\n",
        "```\n",
        " \n",
        "Номер чекпоинта [CHECKPOINT_NUMBER], можно посмотреть в папке content/training_demo/training/. **ПОСЛЕ** обучения там должны появиться файлы типа model.ckpt-1440.index, model.ckpt-1440.meta. 1440 - [CHECKPOINT_NUMBER].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss3j0XSPaAIl",
        "outputId": "acac26d9-9409-49fb-c5e9-f36cc229cbe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/models/research/object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path /content/training_demo/training/ssdlite_mobilenet_v2_coco.config --trained_checkpoint_prefix /content/training_demo/training/model.ckpt-11252 --output_directory /content/training_demo/training/output_inference_graph_v1.pb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1003 01:13:11.009673 140622009345920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:13:13.085424 140622009345920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:13:13.120382 140622009345920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:13:13.154079 140622009345920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:13:13.188252 140622009345920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:13:13.221747 140622009345920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:13:13.254875 140622009345920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1003 01:13:13.578551 140622009345920 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W1003 01:13:13.868519 140622009345920 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W1003 01:13:13.871417 140622009345920 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W1003 01:13:13.871953 140622009345920 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "137 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/3.72m params)\n",
            "  BoxPredictor_0 (--/93.33k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/62.22k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (3x3x576x12, 62.21k/62.21k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/31.11k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (3x3x576x6, 31.10k/31.10k params)\n",
            "  BoxPredictor_1 (--/414.76k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/276.50k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (3x3x1280x24, 276.48k/276.48k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/138.25k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (3x3x1280x12, 138.24k/138.24k params)\n",
            "  BoxPredictor_2 (--/165.92k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/110.62k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (3x3x512x24, 110.59k/110.59k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/55.31k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (3x3x512x12, 55.30k/55.30k params)\n",
            "  BoxPredictor_3 (--/82.98k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/55.32k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (3x3x256x24, 55.30k/55.30k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/27.66k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (3x3x256x12, 27.65k/27.65k params)\n",
            "  BoxPredictor_4 (--/82.98k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/55.32k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (3x3x256x24, 55.30k/55.30k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/27.66k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (3x3x256x12, 27.65k/27.65k params)\n",
            "  BoxPredictor_5 (--/41.51k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/27.67k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (3x3x128x24, 27.65k/27.65k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/13.84k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (3x3x128x12, 13.82k/13.82k params)\n",
            "  FeatureExtractor (--/2.84m params)\n",
            "    FeatureExtractor/MobilenetV2 (--/2.84m params)\n",
            "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "\n",
            "======================End of Report==========================\n",
            "137 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/13.71k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2020-10-03 01:13:15.681769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-03 01:13:15.715952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:15.716513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-03 01:13:15.716826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:13:15.718556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-03 01:13:15.720244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-03 01:13:15.720589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-03 01:13:15.722684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-03 01:13:15.723577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-03 01:13:15.727627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-03 01:13:15.727794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:15.728404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:15.728928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-03 01:13:15.734599: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-10-03 01:13:15.734843: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18a0f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-03 01:13:15.734871: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-03 01:13:15.841823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:15.842471: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18a1100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-03 01:13:15.842501: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-03 01:13:15.842669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:15.843222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-03 01:13:15.843291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:13:15.843320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-03 01:13:15.843342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-03 01:13:15.843366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-03 01:13:15.843385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-03 01:13:15.843403: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-03 01:13:15.843422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-03 01:13:15.843492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:15.844056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:15.844527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-03 01:13:15.844591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:13:15.845701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-03 01:13:15.845727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-03 01:13:15.845737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-03 01:13:15.845873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:15.846412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:15.846917: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-03 01:13:15.846955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/training_demo/training/model.ckpt-11252\n",
            "I1003 01:13:15.848572 140622009345920 saver.py:1284] Restoring parameters from /content/training_demo/training/model.ckpt-11252\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W1003 01:13:17.419878 140622009345920 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-10-03 01:13:17.885945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:17.886538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-03 01:13:17.886620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:13:17.886646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-03 01:13:17.886668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-03 01:13:17.886691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-03 01:13:17.886711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-03 01:13:17.886731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-03 01:13:17.886752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-03 01:13:17.886857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:17.887392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:17.887879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-03 01:13:17.887920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-03 01:13:17.887934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-03 01:13:17.887943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-03 01:13:17.888030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:17.888553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:17.889050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/training_demo/training/model.ckpt-11252\n",
            "I1003 01:13:17.890261 140622009345920 saver.py:1284] Restoring parameters from /content/training_demo/training/model.ckpt-11252\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1003 01:13:18.486966 140622009345920 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1003 01:13:18.487225 140622009345920 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 344 variables.\n",
            "I1003 01:13:18.830192 140622009345920 graph_util_impl.py:334] Froze 344 variables.\n",
            "INFO:tensorflow:Converted 344 variables to const ops.\n",
            "I1003 01:13:18.896210 140622009345920 graph_util_impl.py:394] Converted 344 variables to const ops.\n",
            "2020-10-03 01:13:19.011971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:19.012536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-03 01:13:19.012633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:13:19.012661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-03 01:13:19.012686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-03 01:13:19.012718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-03 01:13:19.012744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-03 01:13:19.012767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-03 01:13:19.012789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-03 01:13:19.012896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:19.013429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:19.013913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-03 01:13:19.013955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-03 01:13:19.013969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-03 01:13:19.013979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-03 01:13:19.014073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:19.014600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:13:19.015096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W1003 01:13:19.501108 140622009345920 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I1003 01:13:19.501785 140622009345920 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I1003 01:13:19.501941 140622009345920 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/training_demo/training/output_inference_graph_v1.pb/saved_model/saved_model.pb\n",
            "I1003 01:13:19.727215 140622009345920 builder_impl.py:425] SavedModel written to: /content/training_demo/training/output_inference_graph_v1.pb/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /content/training_demo/training/output_inference_graph_v1.pb/pipeline.config\n",
            "I1003 01:13:19.750756 140622009345920 config_util.py:254] Writing pipeline config file to /content/training_demo/training/output_inference_graph_v1.pb/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvDJjYfemn5l"
      },
      "source": [
        "Импортируем зависимости и визулаизируем работу обученной модели. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA3GQHdibTyP"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/models/research/object_detection/')\n",
        "sys.path.append('/content/models/research/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z4y7nw0e59t"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yizund9UlBk",
        "outputId": "7f21892e-2bd7-4d3f-b1df-5fced3fe223d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "PATH_TO_MODEL = \"/content/training_demo/training/output_inference_graph_v1.pb/frozen_inference_graph.pb\"\n",
        "PATH_TO_LABELS = \"/content/training_demo/annotations/label_map.pbtxt\"\n",
        "\n",
        "PATH_TO_IMAGE = \"/content/training_demo/images/test/00010.jpg\"\n",
        "\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "# Load a model\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_MODEL, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "# Load labels\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Detection\n",
        "with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "\n",
        "      image = Image.open(PATH_TO_IMAGE)\n",
        "      \n",
        "      # Convert image to numpy array\n",
        "      (im_width, im_height) = image.size    \n",
        "      image_np = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)      \n",
        "    \n",
        "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "      \n",
        "      # Extract image tensor\n",
        "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "      \n",
        "      # Extract detection boxes\n",
        "      boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "      \n",
        "      # Extract detection scores\n",
        "      scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "      \n",
        "      # Extract detection classes\n",
        "      classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "      \n",
        "      # Extract number of detectionsd\n",
        "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "      \n",
        "      # Actual detection.\n",
        "      (boxes, scores, classes, num_detections) = sess.run(\n",
        "          [boxes, scores, classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "     \n",
        "      # Visualization of the results of a detection.\n",
        "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np,\n",
        "          np.squeeze(boxes),\n",
        "          np.squeeze(classes).astype(np.int32),\n",
        "          np.squeeze(scores),\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          line_thickness=4,\n",
        "          min_score_thresh = 0.3\n",
        "          )\n",
        "     \n",
        "      IMAGE_SIZE = (18, 12)\n",
        "      plt.figure(figsize=IMAGE_SIZE)\n",
        "      plt.imshow(image_np)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMa3GTxPKwtO"
      },
      "source": [
        "Далее конвертируем в модель совместимую с tflite_convert. \n",
        "Параметры такие же как и в export_inference_graph.py выше.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oYaiKhwYO3p",
        "outputId": "03bdf263-0745-4035-9485-f92c9c8f1884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py --pipeline_config_path /content/training_demo/training/ssdlite_mobilenet_v2_coco.config --trained_checkpoint_prefix /content/training_demo/training/model.ckpt-11252 --output_directory /content/training_demo/training/output_inference_graph_tf_lite_v1.pb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1003 01:41:39.559293 140237885048704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:41:41.608940 140237885048704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:41:41.636768 140237885048704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:41:41.664447 140237885048704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:41:41.692630 140237885048704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:41:41.718805 140237885048704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1003 01:41:41.745288 140237885048704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "2020-10-03 01:41:41.783220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-03 01:41:41.788148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:41.788648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-03 01:41:41.788970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:41:41.791237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-03 01:41:41.799705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-03 01:41:41.800102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-03 01:41:41.802086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-03 01:41:41.811035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-03 01:41:41.818737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-03 01:41:41.818866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:41.819389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:41.819841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-03 01:41:41.825053: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-10-03 01:41:41.825245: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b3af40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-03 01:41:41.825280: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-03 01:41:41.925532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:41.926169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b3ad80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-03 01:41:41.926199: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-03 01:41:41.926360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:41.927016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-03 01:41:41.927091: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:41:41.927116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-03 01:41:41.927136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-03 01:41:41.927156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-03 01:41:41.927180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-03 01:41:41.927199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-03 01:41:41.927218: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-03 01:41:41.927292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:41.927994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:41.928502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-03 01:41:41.928607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:41:41.929738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-03 01:41:41.929774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-03 01:41:41.929788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-03 01:41:41.929910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:41.930466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:41.930941: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-03 01:41:41.930983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12071 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W1003 01:41:42.400732 140237885048704 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-10-03 01:41:42.800077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:42.800591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-03 01:41:42.800667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:41:42.800695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-03 01:41:42.800717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-03 01:41:42.800742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-03 01:41:42.800765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-03 01:41:42.800785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-03 01:41:42.800805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-03 01:41:42.800911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:42.801420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:42.801864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-03 01:41:42.801908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-03 01:41:42.801922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-03 01:41:42.801931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-03 01:41:42.802020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:42.802608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:41:42.803135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12071 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/training_demo/training/model.ckpt-11252\n",
            "I1003 01:41:42.804265 140237885048704 saver.py:1284] Restoring parameters from /content/training_demo/training/model.ckpt-11252\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1003 01:41:43.824297 140237885048704 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1003 01:41:43.824568 140237885048704 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 344 variables.\n",
            "I1003 01:41:44.094574 140237885048704 graph_util_impl.py:334] Froze 344 variables.\n",
            "INFO:tensorflow:Converted 344 variables to const ops.\n",
            "I1003 01:41:44.137778 140237885048704 graph_util_impl.py:394] Converted 344 variables to const ops.\n",
            "2020-10-03 01:41:44.215148: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp_4KQFmLkPk"
      },
      "source": [
        "Конвертируем модель в формат tflite:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_bJwvu3Y87E",
        "outputId": "1dfefe2e-9af5-42fc-9de0-b5efc2387a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        }
      },
      "source": [
        "!tflite_convert --output_file=/content/training_demo/training/model_q.tflite  --graph_def_file=/content/training_demo/training/output_inference_graph_tf_lite_v1.pb/tflite_graph.pb --input_arrays=normalized_input_image_tensor  --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --input_shapes=1,300,300,3 --enable_select_tf_ops --allow_custom_ops  --inference_input_type=QUANTIZED_UINT8 --inference_type=FLOAT --mean_values=128 --std_dev_values=128"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-03 01:48:24.939675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-03 01:48:24.944027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:48:24.944528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-03 01:48:24.944761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:48:24.946449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-03 01:48:24.948062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-03 01:48:24.948361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-03 01:48:24.955402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-03 01:48:24.958488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-03 01:48:24.964059: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-03 01:48:24.964165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:48:24.964670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:48:24.965134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-03 01:48:24.970138: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-10-03 01:48:24.970351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f86a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-03 01:48:24.970382: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-03 01:48:25.058991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:48:25.059607: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f86f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-03 01:48:25.059637: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-03 01:48:25.059799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:48:25.060278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-03 01:48:25.060329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:48:25.060348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-03 01:48:25.060366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-03 01:48:25.060385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-03 01:48:25.060405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-03 01:48:25.060422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-03 01:48:25.060439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-03 01:48:25.060501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:48:25.061019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:48:25.061451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-03 01:48:25.061502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-03 01:48:25.062386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-03 01:48:25.062411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-03 01:48:25.062420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-03 01:48:25.062512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:48:25.063019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-03 01:48:25.063504: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-03 01:48:25.063542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12071 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4neVqnrynWNf"
      },
      "source": [
        "Архивируем папку с результатами обучения и заливаем её в Google Drive:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZgoHYyolAPU",
        "outputId": "0fcfa055-70d3-4cac-9be4-d2313480b0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        }
      },
      "source": [
        "!zip -r ./training_demo/training.zip ./training_demo/training/"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: training_demo/training/ (stored 0%)\n",
            "  adding: training_demo/training/model.ckpt-16997.data-00000-of-00001 (deflated 6%)\n",
            "  adding: training_demo/training/model.ckpt-0.meta (deflated 94%)\n",
            "  adding: training_demo/training/model.ckpt-16997.index (deflated 72%)\n",
            "  adding: training_demo/training/model.ckpt-20000.index (deflated 72%)\n",
            "  adding: training_demo/training/model.ckpt-20000.data-00000-of-00001 (deflated 6%)\n",
            "  adding: training_demo/training/model.ckpt-16997.meta (deflated 94%)\n",
            "  adding: training_demo/training/ssdlite_mobilenet_v2_coco.config (deflated 69%)\n",
            "  adding: training_demo/training/model.ckpt-5528.data-00000-of-00001 (deflated 6%)\n",
            "  adding: training_demo/training/model.ckpt-11252.data-00000-of-00001 (deflated 6%)\n",
            "  adding: training_demo/training/checkpoint (deflated 73%)\n",
            "  adding: training_demo/training/model.ckpt-20000.meta (deflated 94%)\n",
            "  adding: training_demo/training/output_inference_graph_tf_lite_v1.pb/ (stored 0%)\n",
            "  adding: training_demo/training/output_inference_graph_tf_lite_v1.pb/tflite_graph.pb (deflated 8%)\n",
            "  adding: training_demo/training/output_inference_graph_tf_lite_v1.pb/tflite_graph.pbtxt (deflated 56%)\n",
            "  adding: training_demo/training/model.ckpt-0.data-00000-of-00001 (deflated 54%)\n",
            "  adding: training_demo/training/model.ckpt-5528.index (deflated 72%)\n",
            "  adding: training_demo/training/events.out.tfevents.1601684899.7e0a4bef7af8 (deflated 91%)\n",
            "  adding: training_demo/training/pipeline.config (deflated 69%)\n",
            "  adding: training_demo/training/model_q.tflite (deflated 7%)\n",
            "  adding: training_demo/training/model.ckpt-11252.index (deflated 72%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/ (stored 0%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/saved_model/ (stored 0%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/saved_model/saved_model.pb (deflated 11%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/saved_model/variables/ (stored 0%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/checkpoint (deflated 42%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/frozen_inference_graph.pb (deflated 10%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/pipeline.config (deflated 69%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/model.ckpt.index (deflated 69%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/model.ckpt.meta (deflated 93%)\n",
            "  adding: training_demo/training/output_inference_graph_v1.pb/model.ckpt.data-00000-of-00001 (deflated 7%)\n",
            "  adding: training_demo/training/model.ckpt-11252.meta (deflated 94%)\n",
            "  adding: training_demo/training/model.ckpt-5528.meta (deflated 94%)\n",
            "  adding: training_demo/training/model.ckpt-0.index (deflated 76%)\n",
            "  adding: training_demo/training/graph.pbtxt (deflated 97%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U1WTUTr_3eP"
      },
      "source": [
        "training_result = drive.CreateFile({'title': 'training_result.zip'})\n",
        "training_result.SetContentFile('training_demo/training.zip')\n",
        "#training_result.Upload()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfrRGX4bkjVU"
      },
      "source": [
        "Если возникнет ошибка:\n",
        "```\n",
        "InvalidConfigError: Invalid client secrets file ('Error opening file', 'client_secrets.json', 'No such file or directory', 2)\n",
        "```\n",
        "нужно повторно авторизоваться"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq2Ykbz9eo2W"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}